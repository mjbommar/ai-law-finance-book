% ============================================================================
% 12-conclusion.tex
% Conclusion: Architecture as Foundation
% Part of: Chapter 07 - Agents Part II: How to Design an Agent
% ============================================================================

\section{Conclusion}
\label{sec:agents2-conclusion}

Understanding agent architecture does not require becoming a developer. The goal is meaningful participation in decisions that affect your practice, your clients, and your professional responsibilities.

With architectural literacy, you can evaluate vendor claims with precision. When demonstrations look impressive, you know what questions to ask: What triggered the run? How was intent validated? What data sources were accessed? What approval gates exist? How is isolation enforced? What happens when confidence drops? Impressive outputs do not guarantee sound architecture; architectural literacy lets you probe beneath the surface.

You can specify requirements in terms that technical teams understand. Rather than vague requests for ``AI that helps with research,'' you can describe what you need: perception tools for specific databases, action controls with appropriate approval gates, memory systems with client isolation, and escalation triggers for low-confidence situations. Shared vocabulary bridges the gap between professional requirements and technical implementation.

You can demand governance artifacts, not governance promises. If a vendor cannot demonstrate what the agent accessed, what it did, and why it stopped, the system is not ready for regulated practice. The governance surface requirements from \Cref{sec:agents2-governance-surface}---structured logging, override mechanisms, state snapshots, least privilege enforcement, reliable escalation---are your checklist for what must be demonstrable before deployment.

And you can participate meaningfully in governance design. Governance policy depends on architectural infrastructure; controls must be built in rather than bolted on, and design choices determine what oversight is possible.

% ----------------------------------------------------------------------------
% Calibration and Judgment
% ----------------------------------------------------------------------------

\subsection{Tradeoffs Require Judgment}
\label{sec:agents2-tradeoffs-judgment}

Every architectural capability involves tradeoffs. Richer memory improves context but increases latency and cost. Aggressive escalation improves safety but reduces autonomy and throughput. Tighter approval gates reduce risk but slow execution. More sophisticated planning handles complexity but consumes more resources and introduces more potential failure points. There are no universally correct answers---only choices that must be calibrated to your context, your risk tolerance, and your professional obligations.

Current limitations make this calibration essential. Today's agents perform well on constrained, well-defined tasks but struggle as complexity and duration increase. The ``reliability cliff'' discussed in \Cref{sec:agents2-reliability} is real: success rates tend to degrade as tasks grow longer and more open-ended. Rather than avoiding agentic systems, these limitations argue for scoping them appropriately, adding checkpoints, and designing for human oversight.

For now, agents are best treated as capable assistants that amplify human judgment. The value lies in augmentation: agents handle the routine so professionals can focus on the consequential, with controls that keep humans in the loop where judgment matters.

As technology improves, the tradeoffs will shift. But the ten architectural questions will remain, and the framework you have learned will stay useful even as implementations evolve.

% ----------------------------------------------------------------------------
% Bridge to Governing Agents
% ----------------------------------------------------------------------------

\subsection{From Architecture to Governance}
\label{sec:agents2-to-governance}

This chapter has addressed how to design agents. The natural next question is how to govern them.

Architecture enables governance without determining governance. The governance surface provides the technical means---logging, overrides, state management, privileges, escalation---but policy determines how those means are used. How should approval thresholds be set? Who is accountable when an agent errs? What documentation must be maintained? How do professional duties translate into system requirements? Policy, regulation, and professional responsibility must answer these questions.

\href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}}, the next chapter in this series, addresses these questions directly. It provides a five-layer regulatory framework spanning foundational law, professional obligations, sector-specific regulation, AI-specific requirements, and voluntary frameworks. It offers a dimensional approach to calibrating controls rather than one-size-fits-all checklists, grounded in the architectural understanding you have now developed.

You are equipped to engage with those governance frameworks because you understand what the architecture can and cannot make observable and enforceable: what logging captures and what it misses, what escalation protocols can enforce and what they cannot, and what memory isolation protects and what additional controls it requires. Governance sits atop the architectural foundation this chapter has built.

% ----------------------------------------------------------------------------
% Closing
% ----------------------------------------------------------------------------

\subsection{Agents, Understood}
\label{sec:agents2-arch-understood}

Agents are not magic. They are triggers and channels, intent extraction and constraint validation, perception tools and action controls, memory systems and planning patterns, termination conditions and escalation protocols, delegation architectures and governance surfaces. They are the structural capabilities that any system---human or artificial---requires to do real cognitive work.

These capabilities are now visible to you. You can see past an interface to the architecture beneath, evaluate claims with informed skepticism, and specify requirements that bridge professional needs and technical implementation.

Architectural literacy makes you a capable evaluator, a precise specifier, and an informed participant in decisions about technology that affects your practice. As agents become more prevalent in legal and financial work, that literacy becomes increasingly valuable.

You now have the foundation to evaluate, specify, deploy, and govern agentic systems with the same rigor you apply to the professional teams these systems are meant to augment. The work of understanding agents continues in \href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}}, where we address what controls are required, how to calibrate them, and who bears responsibility.

% =============================================================================
% Evidence Record Schema — Structured Outputs and Tools
% Purpose: Canonical record for claims: source, quote, span, date, jurisdiction
% Label: sec:llmC-evidence
% =============================================================================

\section{Building Audit Trails: Evidence Records and Provenance}
\label{sec:llmC-evidence}

As AI systems move from experimental prototypes to production deployments in legal and financial environments, the question shifts from ``what can the AI do?'' to ``can we prove what the AI did, why it did it, and on what basis?'' Every claim, recommendation, or action generated by an AI agent must be traceable to its source evidence and decision logic. This requirement is not merely technical—it is fundamental to legal defensibility, regulatory compliance, and organizational accountability.

The \keyterm{Canonical Evidence Record} is a standardized, schema-driven log that serves as the definitive proof of an AI system's operation. It captures the complete chain of reasoning: who requested the action, what context was provided, what hazards were identified, which tools were called, what evidence supported the conclusion, and how the output was validated. This section explores why evidence records matter, defines the canonical schema, integrates industry standards for provenance, and demonstrates how to implement tamper-evident audit trails.

% -----------------------------------------------------------------------------
\subsection{Why Evidence Records Matter}
\label{sec:llmC-evidence-why}

In traditional software systems, outputs are deterministic and traceable through code paths. An SQL query returns specific rows based on defined logic; a calculation follows a fixed formula. Large Language Models, by contrast, are probabilistic systems. Given the same input, they may produce different outputs across runs. This stochastic nature poses profound challenges for domains where every decision must be justified and auditable.

\begin{keybox}[title={Evidence Requirements}]
\begin{itemize}
  \item \textbf{Legal Defensibility}: In litigation or regulatory proceedings, you must be able to reconstruct exactly what information the AI accessed, what reasoning it applied, and what sources it relied upon. Without complete records, the AI's conclusions are merely assertions—impossible to verify or defend.
  \item \textbf{Audit Requirements}: Financial services firms face stringent audit requirements under regulations like SOX, Dodd-Frank, and Basel III. Auditors must trace every material decision to its supporting evidence. AI-generated recommendations for loan approvals, trading strategies, or risk assessments require the same standard.
  \item \textbf{Regulatory Compliance}: The EU AI Act, NIST AI Risk Management Framework (AI RMF), and sector-specific regulations (HIPAA for healthcare, GLBA for financial privacy) mandate transparency, explainability, and accountability. Evidence records provide the documentation layer that demonstrates compliance with these requirements.
  \item \textbf{Operational Forensics}: When an AI system produces an incorrect or unexpected result, detailed evidence records enable root cause analysis. Was the source data outdated? Did the model misinterpret a citation? Did a tool call fail silently? Without structured logs, these questions are unanswerable.
\end{itemize}
\end{keybox}

Consider a mortgage approval scenario. An AI agent reviews an applicant's financial history, retrieves credit scores, evaluates current lending policies, and issues a recommendation. If this decision is later challenged—by the applicant, a regulator, or in litigation—the organization must produce a complete audit trail: who the applicant was, what data was accessed, which policies were consulted, how risk was classified, and what validation checks were performed. The evidence record is the artifact that makes this reconstruction possible.

As one governance framework notes, ``you open the logs and find... nothing... Your credibility vanishes instantly.'' In highly regulated environments, the absence of evidence records is not merely embarrassing—it exposes the organization to liability, regulatory sanctions, and reputational damage.

% -----------------------------------------------------------------------------
\subsection{The Canonical Evidence Record Schema}
\label{sec:llmC-evidence-schema}

\clearpage% Force page break before large definitionbox

A \keyterm{Canonical Evidence Record} is a structured data object that accompanies every significant AI action or claim. It serves as both a technical artifact (enabling debugging and monitoring) and a legal document (supporting audit and compliance). The schema must balance completeness with practicality: capturing enough detail for forensic reconstruction without creating unmanageable data volumes.

\begin{definitionbox}[title={Schema: Context/Risk}]
The canonical schema comprises the following required and recommended fields. This first part covers identity, context, and risk classification.

\textbf{Identity and Context}
\begin{itemize}
  \item \textbf{actor}: The AI agent identity (name, version) and the human or system user who initiated the request (user ID, session ID, organization).
  \item \textbf{timestamp}: ISO 8601 timestamp with timezone (e.g., \texttt{2025-12-21T07:10:42-05:00}). For multi-step processes, include start and end times.
  \item \textbf{correlationId}: A unique identifier linking all events in a single transaction or conversation. Enables tracing across distributed systems and microservices.
  \item \textbf{context}: The complete input state, including:
    \begin{itemize}
      \item User prompt or query
      \item Retrieved documents or data (with citation IDs)
      \item System instructions or configuration
      \item Session history (for conversational agents)
    \end{itemize}
\end{itemize}

\textbf{Hazard Classification and Risk}
\begin{itemize}
  \item \textbf{hazard}: A structured classification of potential risks identified during processing:
    \begin{itemize}
      \item \texttt{PII\_Detected}: Personally Identifiable Information found in input or output
      \item \texttt{Financial\_Advice}: Output constitutes investment or financial guidance
      \item \texttt{Legal\_Interpretation}: Output interprets law or regulation
      \item \texttt{High\_Uncertainty}: Low confidence or ambiguous source data
      \item \texttt{Regulatory\_Scope}: Subject to specific regulations (HIPAA, GDPR, etc.)
    \end{itemize}
  \item \textbf{privilege}: Data classification level (public, internal, confidential, privileged).
  \item \textbf{jurisdiction}: Applicable legal jurisdiction (e.g., \texttt{US-NY}, \texttt{EU}, \texttt{UK}). For financial or regulatory content, include sector flags (e.g., \texttt{GLBA}, \texttt{MiFID II}).
\end{itemize}
\end{definitionbox}

\clearpage% Force page break before Part 2

\begin{definitionbox}[title={Schema: Actions}]
This second part covers action execution and validation.

\textbf{Action and Tool Execution}
\begin{itemize}
  \item \textbf{action}: The specific operation performed:
    \begin{itemize}
      \item \texttt{tool\_call}: External function invoked (name, version, arguments, return value)
      \item \texttt{retrieval}: Documents retrieved (source IDs, relevance scores, chunk indices)
      \item \texttt{generation}: Text generated by the model (including reasoning chain if applicable)
    \end{itemize}
  \item \textbf{validation\_result}: Outcome of guardrail checks:
    \begin{itemize}
      \item Schema validation (did output conform to required structure?)
      \item Content filters (PII scrubber, hallucination detector, toxicity classifier)
      \item Business rules (policy compliance, authorization checks)
    \end{itemize}
\end{itemize}
\end{definitionbox}

\begin{definitionbox}[title={Schema: Evidence/Model}]
This third part covers evidence provenance and model parameters.

\textbf{Evidence and Provenance}
\begin{itemize}
  \item \textbf{source}: Stable identifier for each referenced source (URL, DOI, internal document ID, database query).
  \item \textbf{locator}: Precise location within the source (page number, paragraph, section, table row, timestamp for audio/video).
  \item \textbf{quote}: Exact verbatim text or data extracted from the source. Truncate if long, but preserve enough for verification.
  \item \textbf{date}: Publication, effective, or retrieval date of the source material. Critical for time-sensitive content (laws, financial data, news).
  \item \textbf{hash}: Cryptographic hash (SHA-256 or stronger) of the source content. Enables tamper detection: if the source is later altered, the hash mismatch proves modification.
\end{itemize}

\textbf{Model and Parameters}
\begin{itemize}
  \item \textbf{model}: Full model identifier (name, version, provider). Example: \texttt{GPT-5-2025-06-15}, \texttt{Claude-Opus-4.5}.
  \item \textbf{parameters}: Sampling configuration (temperature, top\_p, seed, max\_tokens). These settings affect output variability and reproducibility.
  \item \textbf{tokens}: Input and output token counts (for cost tracking and rate limit monitoring).
\end{itemize}
\end{definitionbox}

This schema is intentionally comprehensive. Not every field will be populated for every event—simple retrieval may omit tool calls, while read-only queries may not require hazard classification. However, the schema must be \emph{capable} of capturing any field that might be needed for forensic reconstruction or compliance demonstration.

\begin{highlightbox}[title={Mortgage Agent Example}]
\footnotesize
\begin{verbatim}
{
  "correlationId": "mtg-2025-12-21-abc123",
  "timestamp": "2025-12-21T14:32:18-05:00",
  "actor": {
    "agent": "MortgageUnderwritingAgent-v3.2",
    "user": "analyst-jane.doe@bank.example",
    "organization": "ExampleBank-Underwriting"
  },
  "context": {
    "prompt": "Evaluate applicant ID 987654 for $250k mortgage",
    "retrieved_docs": ["policy-2025-Q4", "credit-report-987654"],
    "session_id": "sess-2025-1221-045"
  },
  "hazard": ["Financial_Advice", "PII_Detected"],
  "privilege": "confidential",
  "jurisdiction": "US-NY",
  "action": {
    "type": "tool_call",
    "tool": "retrieveCreditScore",
    "version": "2.1.0",
    "arguments": {"applicant_id": 987654},
    "result": {"score": 720, "source": "Equifax"}
  },
  "validation_result": {
    "schema_valid": true,
    "pii_scrubbed": false,
    "policy_compliant": true
  },
  "evidence": [
    {
      "source": "https://bank.example/policy/underwriting-2025-Q4",
      "locator": {"page": 5, "section": "3.2"},
      "quote": "Applicants with credit scores >=700 qualify for...",
      "date": "2025-10-01",
      "hash": "sha256:a3f5b8c..."
    }
  ],
  "model": {
    "name": "GPT-5-2025-06-15",
    "temperature": 0.1,
    "top_p": 0.9,
    "seed": 42
  },
  "tokens": {"input": 1200, "output": 350}
}
\end{verbatim}
\end{highlightbox}

This record captures the complete decision chain: the analyst's query, the applicant identity, the credit score retrieval, the policy consulted, the hazard classification (financial advice involving PII), and the validation results. Years later, if this approval is questioned, the organization can produce this record to demonstrate the exact basis for the decision.

% -----------------------------------------------------------------------------
\subsection{W3C PROV-O Integration: Interoperable Provenance}
\label{sec:llmC-evidence-provo}

While the canonical evidence record provides a rich, domain-specific schema, organizations often need to integrate AI audit trails with broader data lineage and governance systems. The \keyterm{W3C PROV-O} (Provenance Ontology) provides a global standard for representing provenance as a knowledge graph, enabling interoperability across heterogeneous systems.

PROV-O models provenance through three core concepts:
\begin{itemize}
  \item \textbf{Entities}: Data artifacts (documents, embeddings, model outputs, database records).
  \item \textbf{Activities}: Processes that create, modify, or consume entities (ingestion jobs, inference runs, tool executions).
  \item \textbf{Agents}: Systems or people responsible for activities (model instances, users, organizations).
\end{itemize}

Relationships connect these concepts: \texttt{wasGeneratedBy} links an output entity to the activity that created it; \texttt{used} links an activity to its input entities; \texttt{wasAttributedTo} links an entity to the agent responsible for it. By mapping AI evidence records to PROV-O, we create a queryable graph of the entire AI supply chain.

\begin{highlightbox}[title={PROV-O Mapping Example}]
For the mortgage approval example above:
\begin{itemize}
  \item \textbf{Entity}: \texttt{mtg-decision-abc123} (the approval recommendation)
  \item \textbf{Activity}: \texttt{inference-run-abc123} (the agent execution)
  \item \textbf{Agent}: \texttt{MortgageUnderwritingAgent-v3.2}, \texttt{analyst-jane.doe}
\end{itemize}

Relationships:
\begin{itemize}
  \item \texttt{mtg-decision-abc123 wasGeneratedBy inference-run-abc123}
  \item \texttt{inference-run-abc123 used credit-report-987654}
  \item \texttt{inference-run-abc123 used policy-2025-Q4}
  \item \texttt{mtg-decision-abc123 wasAttributedTo MortgageUnderwritingAgent-v3.2}
  \item \texttt{inference-run-abc123 wasAssociatedWith analyst-jane.doe}
\end{itemize}

This graph enables queries like:
\begin{itemize}
  \item ``Which documents contributed to this specific decision?''
  \item ``Show me all decisions made by this agent version.''
  \item ``Trace the lineage of this data artifact back to its source.''
\end{itemize}
\end{highlightbox}

Integrating with PROV-O requires additional tooling—mapping the canonical evidence record JSON to RDF triples, ingesting them into a triplestore (such as Apache Jena or Stardog), and providing SPARQL query interfaces for auditors. However, the payoff is substantial: a unified provenance graph that spans data ingestion, model training, inference, and downstream applications. This is particularly valuable for organizations subject to cross-border regulations or multi-agency oversight, where different regulators may query the same underlying data using standardized provenance queries.

% -----------------------------------------------------------------------------
\subsection{Canonical Data Model: Universal Format for Audit Analytics}
\label{sec:llmC-evidence-cdm}

The \keyterm{Canonical Data Model} (CDM) concept extends beyond individual evidence records to the entire audit infrastructure. Different AI systems—built on LangChain, AutoGen, custom frameworks, or vendor platforms—generate logs in idiosyncratic formats. Without a CDM, every new agent deployment requires custom analytics code, making it impossible to build centralized monitoring or compliance dashboards.

A CDM acts as a ``universal translator'' for AI audit data. All agents, regardless of implementation, emit records conforming to the canonical schema. Audit analytics, compliance checks, and monitoring tools consume this standardized format. When a new regulation requires tracking a specific field (e.g., the EU AI Act mandates recording user consent for certain high-risk applications), organizations add the field to the CDM schema, and all agents automatically begin reporting it—no custom code per-agent.

\begin{keybox}[title={CDM Benefits}]
\begin{itemize}
  \item \textbf{Decoupling}: Audit logic is independent of agent implementation. Switch from LangChain to a custom framework without rewriting compliance checks.
  \item \textbf{Aggregation}: Centralized dashboards aggregate evidence records across all agents, providing organization-wide visibility into AI operations.
  \item \textbf{Policy Enforcement}: Business rules and guardrails operate on the canonical schema. ``No agent may process PII without explicit consent'' is enforced uniformly, regardless of the underlying tech stack.
  \item \textbf{Regulatory Reporting}: Automated generation of compliance reports (e.g., NIST AI RMF documentation, EU AI Act transparency reports) by querying the canonical record store.
\end{itemize}
\end{keybox}

Implementation typically involves:
\begin{enumerate}
  \item \textbf{Schema Registry}: A versioned repository of the canonical schema (JSON Schema, Avro, Protobuf). All agents reference the registry to ensure they emit conformant records.
  \item \textbf{Validation Layer}: Before evidence records are stored, they pass through a validation service that checks schema conformance, rejects malformed records, and logs validation errors.
  \item \textbf{Storage Backend}: An append-only, tamper-evident store (discussed in Section~\ref{sec:llmC-evidence-immutable}). Common choices include time-series databases (InfluxDB, TimescaleDB), event stores (Kafka with log compaction), or blockchain-based ledgers for highest assurance.
  \item \textbf{Query and Analytics}: SQL or time-series query interfaces, plus pre-built dashboards (Grafana, Tableau) that visualize trends, detect anomalies, and generate audit reports.
\end{enumerate}

The CDM is not static—it evolves as regulations change and new agent capabilities emerge. Version management is critical: when the schema is updated (e.g., adding a field for AI-generated content watermarking), older agents may continue emitting v1 records while newer agents emit v2. The validation layer must handle multiple schema versions gracefully, and analytics tools must account for schema evolution.

% -----------------------------------------------------------------------------
\subsection{Security and Immutability: Tamper-Evident Logs}
\label{sec:llmC-evidence-immutable}

Evidence records have value only if they are trustworthy. A log that can be silently altered or deleted is not evidence—it is merely a mutable database. To serve as legal and regulatory evidence, records must be \keyterm{tamper-evident}: any modification leaves detectable traces.

\begin{definitionbox}[title={Tamper-Evident Log Properties}]
A tamper-evident log provides the following guarantees:
\begin{itemize}
  \item \textbf{Append-Only}: Records can be added but never modified or deleted. Each record receives a monotonically increasing sequence number.
  \item \textbf{Cryptographic Hashing}: Each record is hashed (SHA-256 or stronger). The hash is stored with the record, and successive records include the hash of the previous record, creating a hash chain (similar to blockchain).
  \item \textbf{Auditable Integrity}: Given a record at sequence $n$, an auditor can verify that it has not been altered by recomputing its hash and checking that all subsequent records still chain correctly. Any tampering breaks the chain.
  \item \textbf{Time-Stamping}: Optionally, records are cryptographically time-stamped by a trusted third-party (RFC 3161 timestamping). This proves that the record existed at a specific point in time, preventing backdating attacks.
\end{itemize}
\end{definitionbox}

Several architectural patterns support tamper-evident logging:

\begin{itemize}
  \item \textbf{Merkle Trees}: Records are organized into a Merkle tree, where each leaf is a record hash and each internal node is the hash of its children. The root hash summarizes the entire log. Publishing the root hash (e.g., to a blockchain or public ledger) allows anyone to verify log integrity.
  \item \textbf{Certificate Transparency Logs}: Inspired by web PKI, append-only logs can be operated by third parties and audited independently. Google's Trillian project provides an open-source implementation.
  \item \textbf{Blockchain and Distributed Ledgers}: For highest assurance, records can be committed to a blockchain (public or permissioned). This provides decentralized verification: no single party can alter the log without detection.
  \item \textbf{Write-Once Storage}: Cloud providers offer WORM (Write Once, Read Many) storage modes (e.g., AWS S3 Object Lock, Azure Immutable Blob Storage). Records written to these backends cannot be deleted or overwritten, even by privileged administrators.
\end{itemize}

\begin{cautionbox}[title={Security vs. Practicality}]
While blockchain-based or distributed ledger approaches provide maximum assurance, they introduce operational complexity and cost. For many organizations, a pragmatic approach suffices:
\begin{itemize}
  \item Use a time-series database with append-only semantics and role-based access controls.
  \item Hash each record and store the hash chain in a separate, restricted database.
  \item Periodically publish root hashes to an external verifier (public blockchain, notary service).
  \item Implement strict access controls: only the logging service can write records; auditors have read-only access; no one can delete.
\end{itemize}

This ``defense in depth'' approach combines cryptographic integrity, access controls, and external verification to create high confidence in log authenticity without requiring a full blockchain deployment.
\end{cautionbox}

% -----------------------------------------------------------------------------
\subsection{Practical Example: Mortgage Approval AI Trace}
\label{sec:llmC-evidence-example}

To illustrate the complete evidence record chain, consider an AI agent assisting with mortgage underwriting. The agent must evaluate an applicant's creditworthiness, consult internal lending policies, and issue a recommendation—all while maintaining a complete audit trail.

\textbf{Step 1: User Request}
\begin{itemize}
  \item Analyst Jane Doe submits: ``Evaluate applicant ID 987654 for a \$250,000 mortgage.''
  \item The system generates \texttt{correlationId: mtg-2025-12-21-abc123} and logs the initial request with timestamp, user identity, and context.
\end{itemize}

\textbf{Step 2: Credit Score Retrieval (Tool Call)}
\begin{itemize}
  \item The agent determines it needs the applicant's credit score. It calls \texttt{retrieveCreditScore(987654)}.
  \item An evidence record is created:
    \begin{itemize}
      \item \texttt{action.type: tool\_call}
      \item \texttt{action.tool: retrieveCreditScore v2.1.0}
      \item \texttt{action.arguments: \{applicant\_id: 987654\}}
      \item \texttt{action.result: \{score: 720, source: "Equifax"\}}
      \item \texttt{hazard: ["PII\_Detected"]}
      \item \texttt{timestamp: 2025-12-21T14:32:20-05:00}
    \end{itemize}
  \item The record is hashed and appended to the tamper-evident log.
\end{itemize}

\textbf{Step 3: Policy Retrieval (RAG)}
\begin{itemize}
  \item The agent retrieves the current underwriting policy: ``policy-2025-Q4.''
  \item It searches the vector index, retrieves the relevant section (page 5, section 3.2), and records:
    \begin{itemize}
      \item \texttt{action.type: retrieval}
      \item \texttt{evidence.source: bank.example/policy/underwriting-Q4}
      \item \texttt{evidence.locator: \{page: 5, section: "3.2"\}}
      \item \texttt{evidence.quote: "Scores >=700 qualify..."}
      \item \texttt{evidence.date: 2025-10-01}
      \item \texttt{evidence.hash: sha256:a3f5b8c...}
    \end{itemize}
\end{itemize}

\textbf{Step 4: Risk Classification}
\begin{itemize}
  \item The agent classifies the applicant as ``medium risk'' based on credit score, debt-to-income ratio, and policy rules.
  \item This intermediate reasoning step is logged:
    \begin{itemize}
      \item \texttt{action.type: generation}
      \item \texttt{action.reasoning: "Score 720 OK. DTI 35\% OK."}
      \item \texttt{hazard: ["Financial\_Advice"]}
    \end{itemize}
\end{itemize}

\textbf{Step 5: Validation and Output}
\begin{itemize}
  \item The agent generates a recommendation: ``Approve with standard rate (6.5\%).''
  \item Before returning to the analyst, the output passes through validation:
    \begin{itemize}
      \item Schema check: Confirms JSON output conforms to required structure.
      \item PII scrubber: Verifies no unmasked SSNs or account numbers in the output.
      \item Policy compliance: Confirms recommendation aligns with retrieved policy.
    \end{itemize}
  \item Final evidence record:
    \begin{itemize}
      \item \texttt{validation: \{schema: true, pii: true, policy: true\}}
      \item \texttt{action.type: generation}
      \item \texttt{action.output: "Approve with standard rate (6.5\%)"}
      \item \texttt{model: \{name: "GPT-5", temp: 0.1, seed: 42\}}
      \item \texttt{tokens: \{input: 1200, output: 350\}}
      \item \texttt{timestamp: 2025-12-21T14:32:45-05:00}
    \end{itemize}
\end{itemize}

\textbf{Audit Reconstruction}
Six months later, the applicant disputes the approval rate, claiming it should have been lower based on promotional offers. The audit team queries the evidence record store:

\begin{verbatim}
SELECT * FROM evidence_records
WHERE correlationId = 'mtg-2025-12-21-abc123'
\end{verbatim}

They retrieve the complete chain: the initial request, the credit score (720), the policy version in effect (2025-Q4), the exact policy text quoted, the classification logic, and the validation results. The cryptographic hash of the policy document confirms it has not been altered. The time-stamped log entries prove the approval occurred on December 21, 2025, using the policy effective October 1, 2025—before the disputed promotional offers took effect on January 1, 2026.

This reconstruction is possible only because the system maintained a complete, tamper-evident evidence record chain. Without it, the organization would have no defensible basis for the decision.

% -----------------------------------------------------------------------------
\subsection{Best Practices and Pitfalls}
\label{sec:llmC-evidence-practices}

Implementing evidence records requires careful architectural planning. Common pitfalls include:

\begin{itemize}
  \item \textbf{Incomplete Context Capture}: Logging the output but not the input or retrieved documents. Always capture the full state: prompt, retrieved sources, tool results, and intermediate reasoning.
  \item \textbf{Missing Hazard Classification}: Failing to tag records with risk indicators (PII, financial advice, legal interpretation). This metadata is essential for targeted audits and regulatory reporting.
  \item \textbf{Mutable Logs}: Storing evidence records in a standard database without access controls or tamper-evidence. Logs must be append-only and cryptographically protected.
  \item \textbf{Excessive Verbosity}: Logging every token and intermediate step can create unmanageable data volumes. Balance granularity with storage cost: log all tool calls and final outputs, but consider sampling or summarizing intermediate reasoning steps.
  \item \textbf{Inadequate Retention Policies}: Deleting logs too early. Legal and regulatory retention requirements (often 7-10 years for financial records) must inform log lifecycle management. Implement automated archival to cold storage, but never delete prematurely.
\end{itemize}

\begin{keybox}[title={Best Practices}]
\begin{enumerate}
  \item \textbf{Schema-First Design}: Define the canonical schema before deploying agents. Use a schema registry and validation layer to enforce conformance.
  \item \textbf{Correlate Everything}: Every action must include a \texttt{correlationId} linking it to the initiating request. This enables end-to-end tracing across distributed systems.
  \item \textbf{Hash All Sources}: For every retrieved document or tool result, compute and store a cryptographic hash. This proves the content has not been altered post-hoc.
  \item \textbf{Time-Stamp Immediately}: Log records must be timestamped at creation time, not batch-logged later. Use high-precision timestamps (microsecond or better) and include timezone.
  \item \textbf{Separate Storage from Application}: Evidence records should be written to a dedicated logging service, not the application database. This isolation prevents accidental deletion and enforces access controls.
  \item \textbf{Automate Compliance Reporting}: Build analytics pipelines that query the canonical record store to generate compliance artifacts (e.g., NIST AI RMF documentation, EU AI Act transparency reports).
  \item \textbf{Test for Integrity}: Regularly audit a sample of evidence records—recompute hashes, verify chains, attempt unauthorized modifications—to ensure tamper-evidence mechanisms are working.
\end{enumerate}
\end{keybox}

% -----------------------------------------------------------------------------
\subsection{Synthesis: Evidence as Infrastructure}
\label{sec:llmC-evidence-synthesis}

The Canonical Evidence Record transforms AI audit logging from an afterthought into foundational infrastructure. By standardizing how evidence is captured, structured, and stored, organizations create a ``flight data recorder'' for every AI decision. This record serves multiple audiences:
\begin{itemize}
  \item \textbf{Legal teams} use evidence records to defend AI-generated decisions in litigation.
  \item \textbf{Auditors} rely on evidence records to verify compliance with financial and privacy regulations.
  \item \textbf{Regulators} (NIST AI RMF assessors, EU AI Act enforcement bodies) inspect evidence records to confirm transparency and accountability.
  \item \textbf{Engineers} debug and improve AI systems by tracing failures to specific inputs, retrieved sources, or tool calls.
\end{itemize}

The integration with W3C PROV-O and Canonical Data Models elevates evidence records from isolated logs to components of a comprehensive data governance architecture. Tamper-evident storage ensures that these records remain trustworthy over the multi-year lifecycles typical of legal and financial workflows.

As AI agents become more autonomous—making decisions, executing transactions, and providing advice previously reserved for human experts—the evidence record becomes the primary artifact of accountability. It answers the critical question: ``How did this AI reach this conclusion?'' In domains where mistakes are costly and accountability is paramount, the answer to that question is not optional—it is the difference between a defensible AI system and a liability.

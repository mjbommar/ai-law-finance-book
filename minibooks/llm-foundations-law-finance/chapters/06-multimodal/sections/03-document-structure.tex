% =============================================================================
% Document Structure â€” Multimodal Fundamentals
% Purpose: Preserve layout, headings, figure/table IDs
% Label: sec:llmD2-structure
% =============================================================================

\section{Document Structure and Layout}
\label{sec:llmD2-structure}

The primary bottleneck in enterprise document workflows is the Portable Document Format (PDF). Standard text extraction tools treat a PDF as a stream of text characters, often destroying the semantic structure of tables, multi-column layouts, and headers. This ``PDF problem'' results in systems that can retrieve text but cannot understand the relationship between a data point in a table cell and its row/column headers---a critical failure mode for legal and financial analysis.

\subsection{The Spectrum of Document Parsing Strategies}
\label{sec:llmD2-parsing-strategies}

Modern document parsing spans a spectrum from simple text extraction to sophisticated visual understanding:

\begin{definitionbox}[title={Document Parsing Strategies}]
\begin{description}
  \item[Text Stream (Legacy)] Extract characters via libraries like \texttt{pypdf}. Fast and cheap, but destroys tables, columns, and reading order.
  \item[Heuristic Parsing] Rule-based approaches using whitespace and line detection (e.g., \texttt{pdfplumber}). Better table support but brittle on borderless or complex tables.
  \item[Layout Models (AI)] Neural models like \keyterm{LayoutLM} or \keyterm{DocLayout-YOLO} that identify structural elements through bounding boxes. Identifies headers versus body text but requires GPU resources.
  \item[Vision-First (VLM)] Screenshot pages and process through vision-language models like GPT-4V. ``Human-like'' understanding of layout but slow, expensive, and limited by context windows.
\end{description}
\end{definitionbox}

\subsection{Layout Analysis Models}
\label{sec:llmD2-layout-models}

To solve the PDF problem, modern pipelines employ \keyterm{layout analysis models} that treat the document page as an image---or a hybrid of image and text box coordinates---to identify visual blocks: headers, paragraphs, tables, and figures.

\paragraph{LayoutLM and Successors.} Microsoft's LayoutLM family combines text understanding with spatial awareness. The model receives both the OCR text and the bounding box coordinates for each text segment, allowing it to learn the relationship between content and position. LayoutLMv3 and subsequent models add visual features from the document image itself, enabling recognition of logos, signatures, and other non-textual elements.

\paragraph{DocLayout-YOLO.} For high-throughput pipelines, object detection architectures like YOLO (``You Only Look Once'') have been adapted for document layout analysis. DocLayout-YOLO processes document images in a single forward pass, detecting and classifying regions as headers, paragraphs, tables, figures, or footnotes. This approach trades some accuracy for significantly faster processing.

\paragraph{Azure Document Intelligence.} Microsoft's cloud service provides pre-trained models for common document types (invoices, receipts, contracts) and allows custom model training for specialized formats. The service returns structured JSON with identified fields, tables, and key-value pairs, along with confidence scores and bounding polygons.

\subsection{Preserving Structure for Downstream Use}
\label{sec:llmD2-structure-preservation}

Regardless of the parsing approach, the goal is to preserve sufficient structure for downstream tasks:

\begin{highlightbox}[title={Structure Preservation Checklist}]
\begin{itemize}
  \item \textbf{Reading order}: Reconstruct the logical sequence for multi-column layouts.
  \item \textbf{Hierarchy}: Preserve heading levels, section numbering, and nested lists.
  \item \textbf{Object identifiers}: Retain figure/table numbers and their captions.
  \item \textbf{Page references}: Record page numbers for precise citations.
  \item \textbf{Footnotes/endnotes}: Link footnote markers to their content.
  \item \textbf{Cross-references}: Preserve internal document links where possible.
\end{itemize}
\end{highlightbox}

For legal filings and financial disclosures, page numbers and exhibit references are essential for citation. A contract review system that cannot identify ``Section 4.2(a)'' or ``Exhibit B'' loses the precision that practitioners require.

\subsection{Chunking Strategies for Retrieval}
\label{sec:llmD2-chunking}

Once structure is identified, documents must be divided into chunks for embedding and retrieval. This section extends the retrieval fundamentals from Chapter~2 (\Cref{sec:llmB-rag}) to multimodal documents where layout and visual structure inform the chunking strategy.

Naive approaches split by token count, but structure-aware chunking yields better results:

\begin{keybox}[title={Structure-Aware Chunking}]
\begin{description}
  \item[Semantic boundaries] Split at section headings rather than arbitrary token counts.
  \item[Table isolation] Keep tables as atomic units with their captions.
  \item[Contextual overlap] Include section headers in each chunk for context.
  \item[Metadata preservation] Attach page numbers, section paths, and document identifiers to each chunk.
\end{description}
\end{keybox}

For financial documents, a common pattern is to extract tables into a separate structured index while chunking the narrative text. This allows the retrieval system to search both modalities and combine results during synthesis.

\subsection{OCR Quality and Preprocessing}
\label{sec:llmD2-ocr-quality}

When documents arrive as scanned images rather than digital PDFs, OCR quality becomes the critical bottleneck. Poor OCR produces cascading errors through the entire pipeline.

\paragraph{Resolution Requirements.}
Scan quality directly impacts OCR accuracy:

\begin{itemize}
  \item \textbf{300 DPI}: Minimum for standard printed text.
  \item \textbf{600 DPI}: Recommended for fine print, footnotes, and legal documents.
  \item \textbf{Grayscale vs. binary}: Grayscale preserves more information for challenging documents.
  \item \textbf{Color}: Required when color carries semantic meaning (redlines, highlights).
\end{itemize}

\paragraph{Preprocessing Pipeline.}
Before OCR, apply image enhancement:

\begin{enumerate}
  \item \textbf{Deskewing}: Correct rotation from scanner misalignment.
  \item \textbf{Denoising}: Remove speckles and artifacts.
  \item \textbf{Contrast enhancement}: Improve readability of faded text.
  \item \textbf{Binarization}: Convert to black-and-white with adaptive thresholding for text regions.
  \item \textbf{Border removal}: Eliminate scanner edges and margins.
\end{enumerate}

\paragraph{Multi-Language Documents.}
International legal and financial documents may contain multiple languages. OCR engines handle this through:

\begin{itemize}
  \item Language detection per page or region.
  \item Multi-language model loading for mixed-language pages.
  \item Script-specific preprocessing (e.g., right-to-left text handling).
\end{itemize}

\subsection{Form and Template Extraction}
\label{sec:llmD2-forms}

Structured forms---tax returns, loan applications, regulatory filings---require field-level extraction rather than full-text processing.

\paragraph{Field Detection Approaches.}
\begin{description}
  \item[Template matching] Define field locations for known form templates. Fast but brittle to layout variations.
  \item[Key-value extraction] Use AI to identify label-value pairs without predefined templates. More flexible but requires validation.
  \item[Checkbox/radio detection] Identify selection states in multi-choice fields.
  \item[Table extraction] Parse tabular regions within forms.
\end{description}

\paragraph{Named Entity Recognition in Forms.}
Once text is extracted from fields, NER identifies:

\begin{itemize}
  \item Names of individuals and organizations
  \item Dates and temporal expressions
  \item Monetary amounts and percentages
  \item Addresses and contact information
  \item Account numbers and identifiers
\end{itemize}

\begin{highlightbox}[title={Loan Application Processing}]
A mortgage application processor might:
\begin{enumerate}
  \item Classify the document as a specific form type (1003, 1008, etc.).
  \item Extract borrower information fields (name, SSN, income).
  \item Parse employment history tables.
  \item Validate field consistency (do incomes sum correctly?).
  \item Flag fields with low confidence for human review.
\end{enumerate}
\end{highlightbox}

\subsection{Complex Layout Challenges}
\label{sec:llmD2-complex-layouts}

Legal and financial documents often feature complex layouts that defeat simple extraction:

\paragraph{Multi-Column Layouts.}
Newspapers, academic journals, and some legal briefs use multiple columns. Extraction must:

\begin{itemize}
  \item Detect column boundaries.
  \item Determine reading order (down then across, or across then down).
  \item Handle text that spans columns (headlines, pull quotes).
  \item Preserve column-specific context (footnotes belong to their column's text).
\end{itemize}

\paragraph{Footnotes and Endnotes.}
Legal documents heavily use footnotes for citations and qualifications. Extraction should:

\begin{itemize}
  \item Detect footnote markers in body text.
  \item Locate corresponding footnote content (often at page bottom or document end).
  \item Link markers to content for downstream processing.
  \item Preserve the footnote/body relationship in chunking.
\end{itemize}

\paragraph{Marginal Annotations.}
Contracts and legal filings may include:

\begin{itemize}
  \item Handwritten margin notes and initials.
  \item Printed section numbers in margins.
  \item Change tracking marks (strikethrough, insertions).
  \item Bates stamps and exhibit markers.
\end{itemize}

\paragraph{Embedded Objects.}
Documents may contain:

\begin{itemize}
  \item Attached exhibits as embedded PDFs.
  \item Images and photographs inline with text.
  \item Signatures and stamps.
  \item QR codes and barcodes with encoded information.
\end{itemize}

\begin{keybox}[title={Complex Layout Processing}]
\begin{itemize}
  \item Use layout analysis models to segment before extraction.
  \item Preserve document hierarchy (sections, subsections, paragraphs).
  \item Maintain links between footnote markers and content.
  \item Extract embedded objects to separate processing pipelines.
  \item Log extraction confidence for quality assurance.
\end{itemize}
\end{keybox}


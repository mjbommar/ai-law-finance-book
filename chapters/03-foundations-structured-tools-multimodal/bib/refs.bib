% =============================================================================
% Bibliography for Chapter 03: Structured Outputs, Tools, and Multimodal
% =============================================================================

% ============================================================================
% FOUNDATIONAL PAPERS
% ============================================================================

@article{vaswani2017attention,
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title = {Attention Is All You Need},
  journal = {Proceedings of NeurIPS 2017},
  year = {2017},
  eprint = {1706.03762},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/1706.03762},
  urldate = {2025-12-21},
  note = {Seminal paper introducing the Transformer architecture. Foundational for understanding LLM mechanics.}
}

% ============================================================================
% STRUCTURED OUTPUTS AND SCHEMAS
% ============================================================================

@online{openai2024structured,
  author = {{OpenAI}},
  title = {Introducing Structured Outputs in the {API}},
  year = {2024},
  month = {8},
  url = {https://openai.com/index/introducing-structured-outputs-in-the-api/},
  urldate = {2025-12-21},
  note = {Announces JSON Schema enforcement in the OpenAI API; reports that GPT-4 with strict schema mode achieved 100\% compliance on internal tests, versus <40\% with prompt format instructions. Essential for understanding how function calling ensures output structure.}
}

@article{shorten2024structuredrag,
  author = {Connor Shorten and others},
  title = {{StructuredRAG}: {JSON} Response Formatting with Large Language Models},
  journal = {arXiv preprint},
  year = {2024},
  eprint = {2408.11061},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2408.11061},
  urldate = {2025-12-21},
  note = {Benchmarks LLMs on structured output tasks, finding an average 82.5\% success but 0--100\% variance across tasks; highlights need for schema-following improvements.}
}

@online{jsonschema2020,
  author = {Austin Wright and Henry Andrews and Ben Hutton and Greg Dennis},
  title = {{JSON Schema}: A Media Type for Describing {JSON} Documents (Draft 2020-12)},
  year = {2022},
  month = {6},
  url = {https://json-schema.org/draft/2020-12},
  urldate = {2025-12-21},
  note = {Standards document for JSON Schema. Defines the JSON Schema vocabulary for validating JSON structures, including object properties, data types, and format constraints. Essential reference for designing and implementing schemas for structured LLM outputs.}
}

@online{pydantic2024,
  author = {{Pydantic}},
  title = {Pydantic Documentation},
  year = {2024},
  url = {https://docs.pydantic.dev/latest/},
  urldate = {2025-12-21},
  note = {Official documentation for Pydantic, the Python data validation library using type hints. Essential for implementing schema validation for LLM outputs in Python.}
}

@online{brenndoerfer2024constrained,
  author = {Michael Brenndoerfer},
  title = {Constrained Decoding: Grammar-Guided Generation for Structured {LLM} Output},
  year = {2024},
  url = {https://mbrenndoerfer.com/writing/constrained-decoding-structured-llm-output},
  urldate = {2025-12-21},
  note = {Technical analysis of FSM-based constrained decoding mechanisms that enforce structure at the logit level. Explains how constrained generation guarantees syntactic correctness.}
}

@article{beurerkellner2024constrained,
  author = {Luca Beurer-Kellner and Marc Fischer and Martin Vechev},
  title = {Guiding {LLMs} The Right Way: Fast, Non-Invasive Constrained Generation},
  journal = {arXiv preprint},
  year = {2024},
  eprint = {2403.06988},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2403.06988},
  urldate = {2025-12-21},
  note = {Research on efficient constrained decoding algorithms that compile schemas into FSMs and Tries for O(1) valid token lookup per generation step.}
}

% ============================================================================
% TOOL USE AND FUNCTION CALLING
% ============================================================================

@article{schick2023toolformer,
  author = {Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
  title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  journal = {arXiv preprint},
  year = {2023},
  eprint = {2302.04761},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2302.04761},
  urldate = {2025-12-21},
  note = {Demonstrates an LLM that self-learns to call APIs like calculators and search, yielding better performance on arithmetic and QA without increasing model size. Key paper for understanding when and how LLMs decide to use tools.}
}

@online{openai2024functioncalling,
  author = {{OpenAI}},
  title = {Function Calling},
  year = {2024},
  url = {https://platform.openai.com/docs/guides/function-calling},
  urldate = {2025-12-21},
  note = {Official OpenAI documentation on function calling API. Explains how to define tools with JSON Schema parameters and handle multi-turn function call workflows.}
}

@online{owasp2024llmtop10,
  author = {{OWASP Foundation}},
  title = {{OWASP} Top 10 for Large Language Model Applications},
  year = {2024},
  url = {https://owasp.org/www-project-top-10-for-large-language-model-applications/},
  urldate = {2025-12-21},
  note = {Security framework identifying critical vulnerabilities in LLM applications, including Excessive Agency (LLM08) and Insecure Plugin Design (LLM07). Essential for secure tool integration.}
}

@online{runbear2024openapi,
  author = {{Runbear}},
  title = {{OpenAPI} Function Calling},
  year = {2024},
  url = {https://docs.runbear.io/integrations/apps/openai-assistants/api-calling-openapi},
  urldate = {2025-12-21},
  note = {Technical guide on using OpenAPI Specification (OAS) to automatically generate tool definitions for LLM function calling. Explains OAS parsing and integration.}
}

% ============================================================================
% NEURO-SYMBOLIC REASONING
% ============================================================================

@article{gao2023pal,
  author = {Luyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig},
  title = {{PAL}: Program-aided Language Models},
  journal = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  year = {2023},
  eprint = {2211.10435},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2211.10435},
  urldate = {2025-12-21},
  note = {Introduces Program-Aided Language Models where the LLM generates Python programs to solve problems, delegating computation to a runtime. Achieves state-of-the-art results on GSM8K math benchmark.}
}

@online{li2024chainofcode,
  author = {Chengshu Li and Jacky Liang and Andy Zeng and Xinyun Chen and Karol Hausman and Dorsa Sadigh and Sergey Levine and Li Fei-Fei and Fei Xia and Brian Ichter},
  title = {Chain of Code: Reasoning with a Language Model-Augmented Code Emulator},
  year = {2024},
  url = {https://chain-of-code.github.io/},
  urldate = {2025-12-21},
  note = {Proposes Chain of Code (CoC) which uses an LMulator to execute hybrid code containing both executable Python and semantic pseudocode. Achieves 84\% on BIG-Bench Hard, a 12\% gain over Chain of Thought.}
}

% ============================================================================
% RETRIEVAL-AUGMENTED GENERATION (RAG)
% ============================================================================

@article{lewis2020rag,
  author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  title = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  journal = {Proceedings of NeurIPS 2020},
  year = {2020},
  eprint = {2005.11401},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2005.11401},
  urldate = {2025-12-21},
  note = {Seminal paper introducing RAG framework combining parametric (model) and non-parametric (external retrieval) memory for QA tasks. Shows improved factual accuracy and ability to provide sources.}
}

@online{nvidia2025rag,
  author = {Rick Merritt},
  title = {What Is Retrieval-Augmented Generation aka {RAG}},
  year = {2025},
  month = {1},
  organization = {NVIDIA Blog},
  url = {https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/},
  urldate = {2025-12-21},
  note = {Accessible overview of RAG with legal analogy (judge sending clerk to library); emphasizes that RAG provides cited sources to build user trust and reduces hallucinations.}
}

@online{smith2024chunking,
  author = {Ben Smith and Anton Troynikov},
  title = {Evaluating Chunking Strategies for Retrieval},
  year = {2024},
  organization = {Chroma Research},
  url = {https://research.trychroma.com/evaluating-chunking},
  urldate = {2025-12-21},
  note = {Empirical study showing that chunking method significantly impacts retrieval efficacy -- up to 9\% difference in recall between strategies. Discusses token-level evaluation for AI retrieval systems.}
}

@online{weaviate2024chunking,
  author = {{Weaviate}},
  title = {Chunking Strategies to Improve Your {RAG} Performance},
  year = {2024},
  url = {https://weaviate.io/blog/chunking-strategies-for-rag},
  urldate = {2025-12-21},
  note = {Practical guide to chunking strategies for RAG, including semantic chunking, fixed-size with overlap, and sentence-based approaches.}
}

% ============================================================================
% MULTIMODAL PROCESSING
% ============================================================================

@article{xu2020layoutlm,
  author = {Yiheng Xu and Minghao Li and Lei Cui and Shaohan Huang and Furu Wei and Ming Zhou},
  title = {{LayoutLM}: Pre-training of Text and Layout for Document Image Understanding},
  journal = {Proceedings of ACM KDD 2020},
  year = {2020},
  eprint = {1912.13318},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/1912.13318},
  urldate = {2025-12-21},
  note = {Introduces a multimodal transformer that incorporates text and layout information for documents. Achieves state-of-the-art on form understanding tasks by combining visual and textual features. Important for handling PDFs and scanned documents with AI.}
}

@article{wang2024chainoftable,
  author = {Zilong Wang and Hao Zhang and Chun-Liang Li and Julian Martin Eisenschlos and Vincent Perot and Zifeng Wang and Lesly Miculicich and Yasuhisa Fujii and Jingbo Shang and Chen-Yu Lee and Tomas Pfister},
  title = {Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding},
  journal = {Proceedings of ICLR 2024},
  year = {2024},
  eprint = {2401.04398},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2401.04398},
  urldate = {2025-12-21},
  note = {Framework for reasoning over tables by dynamically planning operations to navigate and transform tables. Mimics how analysts work with spreadsheets for better table QA.}
}

@online{radford2022whisper,
  author = {Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  year = {2022},
  organization = {OpenAI},
  eprint = {2212.04356},
  archivePrefix = {arXiv},
  url = {https://arxiv.org/abs/2212.04356},
  urldate = {2025-12-21},
  note = {Introduces Whisper, a state-of-the-art speech-to-text model trained on 680,000 hours of multilingual data. Essential for audio ingestion in multimodal RAG pipelines.}
}

@online{azure2024docintel,
  author = {{Microsoft Azure}},
  title = {Azure {AI} Document Intelligence: Layout Model},
  year = {2024},
  url = {https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept/retrieval-augmented-generation},
  urldate = {2025-12-21},
  note = {Documentation for Azure's layout analysis models for document parsing in RAG systems. Explains how to extract structured information from PDFs, tables, and forms.}
}

% ============================================================================
% GOVERNANCE, AUDIT, AND SECURITY
% ============================================================================

@online{nist2024airm,
  author = {{National Institute of Standards and Technology}},
  title = {{AI} Risk Management Framework ({AI RMF})},
  year = {2024},
  url = {https://airc.nist.gov/airmf-resources/playbook/},
  urldate = {2025-12-21},
  note = {Official NIST framework for identifying, assessing, and managing AI risks. Provides governance guidance for responsible AI deployment in regulated environments.}
}

@online{paloalto2024owasp,
  author = {{Palo Alto Networks}},
  title = {{OWASP} Top 10 {LLM} Security Risks with Mitigation},
  year = {2024},
  url = {https://www.paloaltonetworks.com/resources/infographics/llm-applications-owasp-10},
  urldate = {2025-12-21},
  note = {Visual guide to OWASP Top 10 for LLM applications with practical mitigation strategies for each vulnerability category.}
}

@online{w3cprov2013,
  author = {{W3C}},
  title = {{PROV-O}: The {PROV} Ontology},
  year = {2013},
  url = {https://www.w3.org/TR/prov-o/},
  urldate = {2025-12-21},
  note = {W3C standard for representing provenance information. Defines entities, activities, and agents for tracking data lineage and transformation history. Essential for audit trails in AI systems.}
}

@online{presidio2024,
  author = {{Microsoft}},
  title = {Presidio: Context-aware, Pluggable and Customizable Data Protection and {PII} Anonymization},
  year = {2024},
  url = {https://github.com/microsoft/presidio},
  urldate = {2025-12-21},
  note = {Open-source framework for detecting and redacting PII in text and structured data. Uses NLP and pattern matching for context-aware anonymization. Essential for protecting sensitive data in RAG systems.}
}

@online{bronsdon2025governance,
  author = {Chris Bronsdon},
  title = {Compliance and Governance for {AI} Agents},
  year = {2025},
  month = {9},
  organization = {Galileo.ai Blog},
  url = {https://galileo.ai/blog/ai-agent-compliance-governance-audit-trails-risk-management},
  urldate = {2025-12-21},
  note = {Covers building audit trails and governance into AI agent deployments. Recommends detailed, tamper-evident logs capturing inputs, tool calls, outputs, with security measures. Provides real-world context for traceability and risk management.}
}

@online{edwards2025audit,
  author = {Sarah Edwards},
  title = {Legal {AI} Audit Trails: Designing for Traceability},
  year = {2025},
  month = {4},
  organization = {Law.co Blog},
  url = {https://law.co/blog/legal-ai-audit-trails-designing-for-traceability},
  urldate = {2025-12-21},
  note = {Discusses why transparency and traceability are vital in legal AI. Advises logging decisions, data, and human oversight to satisfy courts and regulators. Complements technical guidance with legal perspective on audit trails.}
}

% ============================================================================
% RELIABILITY AND OPTIMIZATION
% ============================================================================

@online{microsoft2024circuitbreaker,
  author = {{Microsoft Azure}},
  title = {Circuit Breaker Pattern},
  year = {2024},
  url = {https://learn.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker},
  urldate = {2025-12-21},
  note = {Azure Architecture Center guide to implementing circuit breaker pattern for preventing cascading failures in distributed systems. Essential for reliable LLM agent deployments.}
}

@online{portkey2024retries,
  author = {{Portkey.ai}},
  title = {Retries, Fallbacks, and Circuit Breakers in {LLM} Apps: What to Use When},
  year = {2024},
  url = {https://portkey.ai/blog/retries-fallbacks-and-circuit-breakers-in-llm-apps/},
  urldate = {2025-12-21},
  note = {Practical guide to error handling patterns in LLM applications. Explains when to use retries with exponential backoff vs. circuit breakers vs. fallback strategies.}
}

@online{langchain2025speedup,
  author = {{LangChain}},
  title = {How Do I Speed Up My {AI} Agent?},
  year = {2025},
  url = {https://blog.langchain.com/how-do-i-speed-up-my-agent/},
  urldate = {2025-12-21},
  note = {Engineering guide to optimizing LLM agent latency through parallelization, token reduction, and streaming. Includes benchmarks and implementation examples.}
}

% ============================================================================
% ADDITIONAL REFERENCES
% ============================================================================

@online{c2pa2024,
  author = {{Content Authenticity Initiative}},
  title = {Content Credentials Overview},
  year = {2024},
  url = {https://contentauthenticity.org/},
  urldate = {2025-12-21},
  note = {Coalition for Content Provenance and Authenticity (C2PA) standard for cryptographically signing digital media. Provides tamper-evident metadata for AI-generated content verification.}
}

@online{elastic2024pdfparsing,
  author = {{Elastic Search Labs}},
  title = {From {PDF} Tables to Insights: An Alternative Approach for Parsing {PDFs} in {RAG}},
  year = {2024},
  url = {https://www.elastic.co/search-labs/blog/alternative-approach-for-parsing-pdfs-in-rag},
  urldate = {2025-12-21},
  note = {Technical analysis of PDF parsing strategies for RAG, comparing text extraction, heuristic parsing, layout models, and vision-first approaches.}
}

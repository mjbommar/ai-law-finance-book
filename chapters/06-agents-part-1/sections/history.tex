\section{A Historical Journey: Defining Agents Across Seven Decades}
\label{sec:history}

\textit{You now have practical tools for recognizing agents. This section provides optional historical context---tracing how the concept evolved across seven decades and multiple disciplines. Understanding this evolution helps explain why definitions vary so widely today and why the six-property framework emerged as it did. If you're satisfied with the practical rubric, you can skip to Section~\ref{sec:furtherlearning}.}

\vspace{0.5em}

The concept of \keyterm{agency} has evolved dramatically since the mid-20th century, shaped by philosophical inquiry, economic theory, legal doctrine, and technological capability. This section traces agent definitions chronologically, revealing how each level of the hierarchy from Section~\ref{sec:intro} emerged historically: philosophical and legal foundations addressed general agency (Level 1), the computer science revolution instantiated these concepts in software (Level 2), and the LLM era added flexible reasoning powered by AI (Level 3). Figure~\ref{fig:timeline} provides a visual overview of key milestones.

\begin{highlightbox}
\textbf{On Etymology and Ancient Polysemy.} The semantic complexity surrounding ``agent'' has ancient roots. The Latin root \textit{agō}, from which \textit{agent} derives, had multiple meanings in classical Latin. With numerous distinct senses in Lewis \& Short's classical dictionary, ranging from ``driving cattle'' to ``pleading a case,'' contemporary definitional debates echo longstanding ambiguity \parencite{LewisShort1879}.
\end{highlightbox}

\input{figures/timeline}

\subsection{Philosophical and Legal Foundations (1957--1969)}

The postwar period witnessed foundational philosophical work on action theory alongside the maturation of legal doctrine concerning agency relationships. These developments occurred independently yet addressed complementary questions: philosophy examined how intention relates to action and how we attribute actions to agents, while law formalized the conditions under which one party acts on behalf of another.

Three landmark works from this period established conceptual foundations that continue to shape agent definitions across disciplines. Anscombe provided a framework for understanding intentional action as distinct from mere behavior. Davidson connected mental states causally to actions, offering a naturalistic account of agency. The legal Restatement formalized the delegation relationship at the core of practical agency arrangements. Each addressed different aspects of the same underlying question: what makes an entity an agent?

These foundations set up core tensions that would animate later debates: the relationship between mental states and observable behavior, the balance between autonomy and control in delegated relationships, and the explanatory role of reasons versus causes. As computational systems began to exhibit action-like behavior, these philosophical and legal frameworks provided conceptual resources for interpreting artificial agency.

\begin{definitionbox}[importance=low,title={\textbf{1957: Intention}}]
G.E.M. Anscombe's \textit{Intention} established that actions are \keyterm{intentional} ``under a description'' and known through practical knowledge \parencite{anscombe1957intention}. This introduced the idea that intention plays a basic explanatory role: we understand actions by understanding the reasons under which agents perform them.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1958: Legal Agency}}]
The \textit{Restatement (Second) of Agency} defined \keyterm{agency relationship}: a principal manifests assent that an agent shall act on the principal's behalf and subject to control \parencite{restatement1958agency}. This emphasizes delegation, fiduciary relation, and control—concepts relevant when discussing AI systems acting on behalf of humans.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1963: Causal Theory of Action}}]
Donald Davidson's ``Actions, Reasons, and Causes'' defended the \keyterm{causal theory of action}, arguing that intentional actions are explained by an agent's primary reason (belief–desire pair) that causally produces the action \parencite{davidson1963actions}. This framework connected mental states to observable behavior.
\end{definitionbox}

These three works established complementary foundations for thinking about agency. Philosophy offered frameworks for intention and the causal structure of action, while law formalized delegation and control in principal–agent relationships. Together, they highlighted elements that would need to be addressed as the concept of agency expanded beyond human actors: intentionality, causal efficacy, goal-directedness, and the capacity to act on behalf of another. When researchers began implementing computational agents in subsequent decades, they inherited both the conceptual resources and the unresolved tensions from this period.

\noindent\textcolor{border-neutral}{\rule{\textwidth}{1.5pt}}
\vspace{0.5em}

\subsection{Economic and Social Theory (1970--1989)}

The 1970s and 1980s witnessed agency concepts migrating from philosophy and law into the social sciences. Economics, sociology, and psychology each adapted the core ideas to their disciplinary concerns, generating new frameworks for understanding human behavior in organizations, social structures, and economic relationships. This period produced a remarkably diverse set of perspectives on agency, from Milgram's minimalist ``agentic state'' where individuals function as mere instruments, to Bandura's rich conception of human agency with intentionality, forethought, and self-regulation.

A key theme across these developments was the spectrum of autonomy. Economic models formalized principal-agent relationships as contracts with delegated decision-making but misaligned incentives, focusing on control mechanisms and information asymmetries. Sociological theories emphasized agents' capacity to act independently within structural constraints. Cognitive science explored how minds might be composed of simpler agents, while philosophy developed practical frameworks for planning and prediction. By the end of this period, researchers had articulated both the minimal conditions for agency (following another's directives) and the maximal human capacities (self-reflective goal pursuit).

These social science perspectives proved directly influential for computational implementations in the 1990s. Bratman's BDI framework became a dominant architecture for intelligent agents. Dennett's intentional stance provided a pragmatic criterion for when to treat systems as agents. Bandura's enumeration of human agency properties became a checklist for artificial systems. The diversity of definitions reflected different disciplinary needs, but collectively they mapped out the conceptual terrain that computer scientists would navigate when implementing computational agents.

\begin{definitionbox}[importance=low,title={\textbf{1974: The Agentic State}}]
Stanley Milgram's \textit{Obedience to Authority} introduced the ``\keyterm{agentic state}''---individuals seeing themselves as instruments carrying out another's wishes \parencite{milgram1974obedience}. This anchors one end of the autonomy spectrum: agents as pure delegates without independent judgment.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1976: Principal-Agent Economics}}]
Jensen and Meckling's ``Theory of the Firm'' formalized the \keyterm{principal-agent relationship}, defining it as a contract where principals engage agents with delegated decision-making authority \parencite{jensen1976theory}. This established vocabulary of agency costs, information asymmetry, and incentive alignment.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1984: Structuration Theory}}]
Anthony Giddens framed agency as the capacity to make a difference and intervene in the world \parencite{giddens1984constitution}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1986: Society of Mind}}]
Marvin Minsky's \textit{Society of Mind} popularized the idea of mind as a society of simple ``agents'' whose interactions generate intelligence, introducing the \keyterm{multi-agent system} metaphor \parencite{minsky1986society}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1987: Planning Theory}}]
Michael Bratman's \textit{Intention, Plans, and Practical Reason} developed a planning theory emphasizing partial plans structuring practical reasoning \parencite{bratman1987intention}. This introduced the Belief-Desire-Intention (BDI) framework that became foundational for intelligent agent architectures.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1987: The Intentional Stance}}]
Daniel Dennett's \textit{The Intentional Stance} argued we can treat entities as agents when attributing beliefs and desires yields reliable predictions---providing a pragmatic criterion for agency \parencite{dennett1987intentional}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1989: Human Agency}}]
Albert Bandura synthesized psychological research, defining human agency through intentionality, forethought, self-regulation, and self-reflectiveness---properties increasingly sought in artificial systems \parencite{bandura1989human}.
\end{definitionbox}

These seven definitional works from 1974--1989 collectively established a spectrum of agency from minimal delegation to full autonomy. At one extreme, Milgram's agentic state described humans functioning as mere instruments with no independent judgment. At the other, Bandura enumerated the rich capacities of human agency: forming intentions, planning ahead, monitoring and regulating behavior, and reflecting on one's own efficacy. Between these poles, economic models formalized the incentive problems in delegated decision-making, sociological theories examined how agents navigate structural constraints, and philosophical frameworks provided practical tools for prediction and planning.

This diversity reflected genuine differences in disciplinary focus---economics concerned with contracting problems, psychology with cognitive capacities, sociology with social structures. But the frameworks proved complementary rather than contradictory. The BDI architecture from Bratman's planning theory, the intentional stance from Dennett's pragmatic philosophy, and the property lists from Bandura's psychology would all become standard tools for designing and analyzing computational agents. The 1990s explosion of agent-oriented computing inherited this rich conceptual toolkit, translating social science insights into software architectures.

\noindent\textcolor{border-neutral}{\rule{\textwidth}{1.5pt}}
\vspace{0.5em}

\subsection{The Computer Science Revolution (1990--1999)}

The 1990s saw a proliferation of work on computational agents, driven by the convergence of distributed systems, AI research, and the rapid growth of the internet. Previous decades had provided rich conceptual frameworks—intention, planning, autonomy, perception–action cycles—but these primarily described human or abstract theoretical entities. The 1990s marked a clear shift: researchers implemented these concepts directly in software, creating systems designed from the ground up as agents rather than as traditional programs.

This transition from human to computational agency required translating philosophical and social science concepts into executable architectures. How should beliefs and intentions be represented in code? What makes a software system autonomous rather than merely reactive? When do local interactions among simple agents produce emergent behavior? The decade produced multiple answers to these questions, each emphasizing different aspects of agency: mental states (BDI architectures), observable properties (autonomy, reactivity, proactivity), functional roles (perception–action), computational paradigms (reinforcement learning), and emergence from interaction (complex adaptive systems, agent-based modeling).

The proliferation of definitions reflected both vitality and fragmentation. Researchers drew selectively from the prior decades' conceptual toolkit, implementing what could be formalized and computed. The result was a rich ecosystem of agent types serving different purposes: software agents assisting users, intelligent agents in multi-agent systems, autonomous agents pursuing goals in environments, adaptive agents learning through experience. By decade's end, agent-oriented computing had established itself as a distinct paradigm with its own conferences, journals, and textbooks.

\begin{definitionbox}[importance=low,title={\textbf{1991--1993: Agent-Oriented Programming}}]
Yoav Shoham's AGENT0 and ``Agent-Oriented Programming'' implemented agents as computational entities characterized in mentalistic terms (beliefs, commitments, obligations) \parencite{shoham1993aop}. This established \keyterm{agent-oriented programming} as distinct from object-oriented programming and was closely related to the BDI (Belief-Desire-Intention) architecture.
\end{definitionbox}

\paragraph{1994--1995: Three Foundational Perspectives}
Pattie Maes envisioned adaptive, long-lived software assistants that learn user preferences \parencite{maes1994agents}. Three major 1995 works captured distinct facets:

\begin{definitionbox}[importance=low,title={\textbf{1995: Intelligent Agents}}]
Wooldridge \& Jennings: \textbf{Intelligent agents} exhibit autonomy, reactivity, proactivity, and social ability \parencite{wooldridge1995intelligent}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1995: Perception–Action Agents}}]
Russell \& Norvig: An \textbf{agent} perceives its environment through sensors and acts through actuators \parencite{russellnorvig1995ai}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1995: Complex Adaptive Systems}}]
Holland: \textbf{Complex adaptive system agents} exhibit local interactions under simple rules that produce emergent behavior \parencite{holland1995cas}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1996: Autonomous Agents}}]
Franklin and Graesser distinguished \keyterm{autonomous agents} as entities situated within an environment that sense and act over time in pursuit of their own agendas \parencite{franklin-graesser-1997}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1996: Agent-Based Modeling}}]
Epstein and Axtell's \textit{Growing Artificial Societies} established agent-based modeling (ABM), defining agents as autonomous heterogeneous individuals whose local interactions produce emergent macro patterns \parencite{epstein1996growing}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1998: Reinforcement Learning}}]
Sutton and Barto's \textit{Reinforcement Learning} defined agents maximizing cumulative reward through environmental interaction, establishing the \keyterm{RL framework} \parencite{suttonbarto1998rl}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1999: Multi-Agent Systems}}]
Edited volumes by Gerhard Weiss and Jacques Ferber consolidated \keyterm{multi-agent systems (MAS)}, defining agents as autonomous problem-solving entities that cooperate, compete, and negotiate to achieve individual and collective goals \parencite{weiss1999mas,ferber1999mas}.
\end{definitionbox}

The 1990s produced several major definitional frameworks, each capturing different facets of agency. Three complementary 1995 perspectives became particularly influential: Wooldridge and Jennings' property-based view (autonomy, reactivity, proactivity, social ability), Russell and Norvig's functional view (perception and action), and Holland's emergence-based view (simple rules producing complex behavior). These were not competing definitions but rather different levels of description—properties agents should exhibit, functional roles they should fill, and mechanisms by which agency emerges.

The decade also established two influential computational paradigms. Agent-based modeling demonstrated how simple local rules could generate macro-level social phenomena, providing a powerful tool for social science. Reinforcement learning formalized agents as reward maximizers learning through environmental interaction, a framework that proved durable and scalable. By 1999, multi-agent systems had matured into a distinct field with established textbooks, reference works, and architectural patterns. These 1990s frameworks would shape agent definitions for the next two decades, until large language models introduced qualitatively new capabilities.

\noindent\textcolor{border-neutral}{\rule{\textwidth}{1.5pt}}
\vspace{0.5em}

\subsection{Consolidation and Formalization (2000--2019)}

The early 21st century marked a period of consolidation rather than conceptual revolution. Following the 1990s explosion of agent definitions and implementations, the field matured through textbooks that trained new generations of researchers, reference works that synthesized accumulated knowledge, and successful demonstrations that validated the frameworks at scale. The dot-com boom and bust, the rise of Web 2.0, mobile computing, and eventually the deep learning revolution all occurred during this period, yet they produced remarkably few new definitional frameworks for agency itself.

Two early definitional contributions framed the era's concerns. Kauffman raised fundamental questions about the relationship between physical and virtual agency, proposing thermodynamic criteria that most software agents clearly failed to meet. Jennings, Sycara, and Wooldridge formalized agent-oriented software engineering, translating the 1990s research insights into practical development methodologies. Beyond these, the period's major developments were consolidative: textbooks like Wooldridge's \textit{Introduction to MultiAgent Systems} and Epstein's \textit{Generative Social Science} codified best practices, legal updates like the Restatement (Third) of Agency maintained doctrinal continuity, and reference works like the Stanford Encyclopedia entries provided authoritative syntheses.

The period's most dramatic developments came not from new definitions but from demonstrations of existing frameworks at unprecedented scale. Deep reinforcement learning combined neural networks with the RL framework established by Sutton and Barto in 1998, achieving superhuman performance first in Atari games and then notably with AlphaGo's victories over world champions. These successes validated that the 1990s conceptual frameworks could scale to complex domains, but they did not fundamentally redefine what agents are. By 2019, the field had mature definitions, established textbooks, and powerful demonstrations—but also growing awareness that large language models might catalyze the next definitional shift.

\begin{definitionbox}[importance=low,title={\textbf{2000: Physical Agency}}]
Stuart Kauffman's \textit{Investigations} proposed thermodynamic criteria: natural autonomous agents must reproduce and perform thermodynamic work cycles, highlighting tensions between embodied and virtual agency \parencite{kauffman2000investigations}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{1998 Roadmap: Agent Definition Consensus}}]
Jennings, Sycara, and Wooldridge's 1998 research roadmap synthesized the agent research community's consensus: an agent is ``an encapsulated computer system that is situated in some environment, and that is capable of flexible, autonomous action in that environment in order to meet its design objectives'' \parencite{jennings1998roadmap,wooldridge1995intelligent}. As a historical definition from computer science, they used ``system'' to mean a computational entity. This definition grounded agent-oriented software engineering (AOSE) work throughout the 2000s.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{2006: Restatement (Third) of Agency}}]
The \textit{Restatement (Third) of Agency} updated legal doctrine while retaining core concepts of fiduciary duty and delegated authority \parencite{restatement2006agency}.
\end{definitionbox}

\paragraph{Textbooks and Consolidation}
Wooldridge's \textit{Introduction to Multi\-Agent Systems} \parencite{wooldridge2009introduction} and Bonabeau's agent-based modeling syntheses \parencite{bonabeau2002abm} trained the next generation. Epstein's \textit{Generative Social Science} articulated ABM's explanatory program: explaining phenomena through simple rule-based actors whose local interactions generate macro patterns \parencite{epstein2006generative}. Stanford Encyclopedia entries on ``Agency'' and ``Action'' provided philosophical syntheses \parencite{sep-agency,sep-action}. By 2020, Russell and Norvig's 4th edition of AIMA had refined agent definitions incorporating ML progress \parencite{russellnorvig2020aima}.

\paragraph{Deep Reinforcement Learning Demonstrations}
Deep RL combined neural networks with RL frameworks, achieving superhuman performance in complex domains. DeepMind's DQN mastered Atari games from raw pixels \parencite{mnih2015humanlevel}, and AlphaGo defeated world champions at Go \parencite{silver2016alphago}, demonstrating that learned agents could exceed human capabilities in domains previously considered intractable. These successes validated the RL agent framework at unprecedented scale and complexity.

The 2000--2019 consolidation period produced remarkably little definitional innovation compared to the 1990s explosion. Kauffman's thermodynamic criteria highlighted the still-unresolved tension between physical and virtual agency---a question that remains contentious as purely software-based LLM agents proliferate. Jennings and colleagues' software engineering formalization helped practitioners but didn't redefine agency itself. Otherwise, the period's contributions were consolidative: textbooks trained practitioners, demonstrations validated frameworks at scale, and reference works synthesized accumulated knowledge.

This relative stability reflected the 1990s frameworks' success—they fit the period's technological capabilities. Deep RL showed that agents learning through environmental interaction could achieve superhuman performance in complex domains, validating Sutton and Barto's 1998 framework rather than replacing it. The stage was set, however, for disruption. Large language models' capacity for flexible reasoning, few-shot learning, and natural language understanding would soon enable agent architectures qualitatively different from the hand-coded systems of previous decades.

\noindent\textcolor{border-neutral}{\rule{\textwidth}{1.5pt}}
\vspace{0.5em}

\subsection{The LLM Era (2020--2025)}

Large language models brought capabilities that catalyzed a new wave of agent definitions. GPT-3's release in 2020 demonstrated few-shot learning and flexible reasoning at scale. ChatGPT's public launch in 2022 made conversational AI mainstream. But the definitional shift came not from language modeling itself, but from discovering that LLMs could orchestrate tool use, maintain working memory, and iteratively refine approaches to achieve complex goals. This combination—flexible reasoning plus tool use—enabled agent architectures qualitatively different from previous decades' hand-coded systems.

The key insight emerged in 2022: LLMs could implement the classical perception–action cycle not through programmer-specified rules but through learned parameters. The ReAct pattern (Reasoning and Acting) demonstrated LLMs interleaving chain-of-thought reasoning with tool use, iteratively planning, acting, and observing until goals were achieved. This simple pattern proved general, spurring implementations across research labs and commercial frameworks. Unlike previous decades' diversity of agent architectures, the LLM era quickly converged on a dominant pattern: an LLM iteratively calling tools, observing results, updating state, and choosing next actions.

This architectural convergence reflects several factors: the flexibility of LLMs as general-purpose reasoners, the natural fit between language models and tool APIs, and the economic incentives driving rapid commercialization. Where 1990s agent definitions emerged from academic research programs over a decade, LLM agent definitions coalesced in months through practitioner experimentation and commercial deployment. The speed of convergence is unprecedented, though whether this pattern will prove as durable as the 1990s frameworks remains to be seen.

\begin{definitionbox}[importance=low,title={\textbf{2022: The LLM-as-Agent Pattern}}]
Yao et al.'s ``ReAct: Synergizing Reasoning and Acting in Language Models'' showed that LLMs can interleave chain-of-thought reasoning with tool use, iteratively planning, acting, and observing to achieve goals \parencite{yao2022react}. This catalyzed the ``\keyterm{LLM-as-agent}'' pattern in contemporary practice. As Simon Willison concisely puts it: ``an LLM agent runs tools in a loop to achieve a goal'' \parencite{willison-2025-agents-definition}.
\end{definitionbox}

Framework documentation adopted this pattern explicitly. LangChain defines agents as entities that use LLMs to iteratively call tools until a stop condition is met \parencite{langchain-agents-docs}. OpenAI's Agents SDK similarly describes agents as LLMs configured with instructions and tools, operating in loops where the LLM decides which tools to call based on iterative feedback \parencite{openai-agents-sdk}. This convergence across academic research and commercial frameworks reflects rapid standardization around a single architectural pattern.

\begin{definitionbox}[importance=low,title={\textbf{2023: Generative Agents}}]
Park et al.'s ``Generative Agents'' showcased LLM-powered agents simulating believable human behaviors over long horizons via memory, planning, and reflection, popularizing sandboxed LLM agents in society simulations \parencite{park2023generative}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{2023: The Rise of LLM Agents}}]
Xi et al.'s survey ``The Rise and Potential of Large Language Model Based Agents'' documented the emerging architectural consensus: entities using LLMs to iteratively call tools, observe results, and adapt until goals are achieved \parencite{xi2023rise}.
\end{definitionbox}

\begin{definitionbox}[importance=low,title={\textbf{2024--2025: Commercial Frameworks}}]
LangChain defines agents as entities using LLMs to iteratively call tools until a stop condition is met \parencite{langchain-agents-docs}. OpenAI's Agents SDK describes agents as LLMs configured with instructions and tools, operating in loops where the LLM decides which tools to call based on iterative feedback \parencite{openai-agents-sdk}. This convergence represents an emerging architectural consensus across research and commercial frameworks.
\end{definitionbox}

The LLM era's definitional landscape differs from previous periods. Rather than multiple competing frameworks addressing different facets of agency, the field quickly converged on a single architectural pattern: LLMs orchestrating tools in iterative loops. ReAct established the template in 2022, and within months implementations proliferated across academia and industry. Park's generative agents demonstrated the pattern's applicability to social simulation, while commercial frameworks embedded it as default infrastructure.

What is genuinely new remains debated. Skeptics note that the perception–action cycle, goal-directed behavior, and tool use all appeared in 1990s definitions—the LLM era implements these through learned parameters rather than programmer-specified logic. Proponents argue that flexible reasoning over natural language representations enables qualitatively different agentic capabilities. A plausible resolution is that LLMs shifted where decision-making knowledge resides (from code to weights) without fundamentally changing the functional architecture of agency. Regardless, the speed of convergence—from research demonstration to industry standard in under three years—marks the LLM era as distinctive in the seven-decade history of agent definitions.

\subsection{Historical Patterns}

\begin{keybox}[title={\textbf{Five Patterns Across Seven Decades}}]
Five patterns emerge:

\paragraph{Broadening entity frames}
Early definitions focused on humans or human–AI relationships. By the 1990s, purely computational agents became common. The LLM era introduced hybrid framings: humans provided goals, AI systems executed multi-step tasks.

\paragraph{Increasing autonomy}
Definitions migrated from delegated proxies (1958) through perception–action systems (1995) to self\-/directed tool orchestrators (2025). The locus of decision\-/making shifted progressively toward the agent, reflecting evolving expectations of autonomy.

\par\paragraph{From mental states to observable behavior}
Philosophical definitions emphasized intention and reasoning. Computer science implemented these as mentalistic constructs. Contemporary definitions focus on observable capabilities—tool use, iterative problem solving, task completion.

\paragraph{``Tools-in-a-loop'' convergence}
The AI engineering community has converged toward iterative tool orchestration patterns, documented in practitioner accounts \parencite{willison-2025-agents-definition} and academic surveys \parencite{xi2023rise}. This reflects technological maturity (LLMs capable of reliable tool use), research foundations (ReAct and related frameworks), and market pressures (customers evaluating empirical capabilities). While not yet a formal standard, this architectural pattern dominates contemporary implementations.

\paragraph{From hand-coded to learned behavior}
Early agents used explicit rules and plans specified by programmers. Deep RL demonstrated agents learning behaviors through environmental interaction. LLMs shifted the architectural locus of planning and orchestration from programmer-specified logic to learned parameters, changing where decision-making knowledge resides rather than the fundamental agentic capabilities.

\vspace{0.5em}
\textit{These patterns help explain why contemporary definitions vary: they reflect different points in this evolutionary trajectory and different disciplinary emphases.}
\end{keybox}

The next section examines how different disciplines approached agency, revealing persistent tensions and complementary insights.

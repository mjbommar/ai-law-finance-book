\section{Conclusion}
\label{sec:conclusion}

This paper traced the evolution of ``\keyterm{agent}'' as a concept across seven decades and eight disciplines, revealing both remarkable convergence and persistent tensions. We conclude by reflecting on implications for research, practice, and policy.

\subsection{What We Have Learned}

\begin{keybox}{Five Key Learnings from Seven Decades of Agency Research}
\paragraph{Agency is multifaceted, not monolithic}
Philosophy emphasizes \keyterm{intentionality} and reasons. Psychology focuses on \keyterm{self-regulation} and control. Law centers on \keyterm{delegated authority} and \keyterm{fiduciary duty}. Economics analyzes \keyterm{incentive alignment}. Cognitive science explores \keyterm{mental architecture}. Complex systems highlights \keyterm{emergence} from local rules. Computer science formalizes protocols and coordination. AI defines \keyterm{perception-action loops} and \keyterm{tool orchestration}. Each perspective illuminates different facets; none captures the whole.

\paragraph{Historical evolution shows broadening and sharpening}
Early definitions focused on humans (Anscombe, Bandura) or human-AI relationships (Restatement, Jensen \& Meckling). The 1990s computational revolution broadened \keyterm{entity frames} to include pure machines (Russell \& Norvig, Franklin \& Graesser). The \keyterm{LLM era} has simultaneously sharpened around ``tools-in-a-loop'' while introducing hybrid framings where humans provide goals and oversight while AI executes multi-step tasks.

\paragraph{Analytical dimensions provide organizing principles}
The \keyterm{autonomy spectrum} (delegated to self-directed), \keyterm{entity frames} (human to institutional to machine), \keyterm{goal dynamics} (acceptance to adaptation to negotiation), and \keyterm{persistence requirements} provide cross-cutting dimensions that structure disciplinary variation. These dimensions enable more precise discourse than monolithic definitions.

\paragraph{Practical consensus is emerging}
Despite philosophical diversity, AI engineering has converged on operational definitions centered on \keyterm{iterative tool orchestration}. \textcite{willison-2025-agents-definition}'s ``LLM agent runs tools in a loop to achieve a goal'' captures this consensus, which major vendors and frameworks have adopted. This convergence enables empirical evaluation and accountability.

\paragraph{Legal applications require additional constraints}
General agency definitions must be augmented with legal-specific requirements: \keyterm{attribution} to authoritative sources, \keyterm{auditable provenance}, \keyterm{escalation protocols} recognizing human judgment needs, and \keyterm{confidentiality mechanisms} protecting privilege. These requirements do not change what makes something an agent; they define what makes an agent suitable for professional work.
\end{keybox}

\subsection{Contributions of This Work}

\begin{keybox}[title={Contributions of This Work}]
\paragraph{Comprehensive historical documentation}
We analyzed 68+ canonical definitions from 1957 to 2025, providing the most extensive chronological survey of \keyterm{agent concepts} to our knowledge. This documentation stabilizes terminology during rapid technological change.

\paragraph{Cross-disciplinary synthesis}
By examining philosophy, psychology, law, economics, cognitive science, complex systems, computer science, and AI together, we reveal complementary insights and productive tensions. Such synthesis remains rare in the literature.

\paragraph{Analytical framework}
The four dimensions (\keyterm{autonomy}, \keyterm{entity frames}, \keyterm{goal dynamics}, \keyterm{persistence}) provide organizing principles for comparing definitions and evaluating systems. This framework enables more precise discourse than relying on any single disciplinary definition.

\paragraph{Practical evaluation rubric}
The \keyterm{ten-question rubric} (Section~\ref{sec:synthesis}) translates theoretical foundations into practical guidance for evaluating whether systems are agents and whether they suit legal work. This bridges academic concepts and practitioner needs.

\paragraph{Three-level hierarchy}
The distinction among \keyterm{agents} (broadest concept), \keyterm{agentic software} (computational subset), and \keyterm{agentic AI} (AI-powered systems) provides accessible scaffolding for non-specialists while remaining grounded in decades of scholarship.
\end{keybox}

\subsection{Limitations}

\begin{keybox}[title={Limitations}]
\paragraph{Chronological scope}
We began with Anscombe (1957) for pragmatic reasons---earlier work exists but is less directly connected to contemporary debates. Fuller historical treatment would trace agency concepts to ancient philosophy.

\paragraph{Disciplinary coverage}
We covered eight major disciplines but omitted others with relevant perspectives: neuroscience (neural mechanisms of agency), political science (collective action), anthropology (cultural variation in agency concepts), and more. Complete coverage is impossible; we prioritized disciplines most directly relevant to legal AI.

\paragraph{Technical depth}
To maintain accessibility, we simplified complex technical concepts. Readers seeking deeper engagement with \keyterm{BDI architectures}, \keyterm{reinforcement learning}, or \keyterm{multi-agent coordination} should consult specialized literature.

\paragraph{Legal focus}
Our emphasis on legal applications limits generalizability. Medical AI, financial AI, and other professional domains face parallel challenges but with domain-specific requirements. Our framework provides starting points but not complete solutions for those domains.

\paragraph{Rapidly evolving landscape}
We completed this paper in late 2025. By publication, new systems will have emerged, regulatory frameworks will have evolved, and capabilities will have progressed. Our conceptual foundations should remain stable, but specific examples age quickly.
\end{keybox}

\subsection{Future Directions}

\begin{keybox}[title={Research Agenda: Six Critical Directions}]
\paragraph{Expanded evaluation frameworks}
Current benchmarks inadequately assess \keyterm{agentic capabilities}---task completion, iteration quality, escalation appropriateness, attribution fidelity. Developing comprehensive evaluation suites remains urgent.

\paragraph{Liability and accountability frameworks}
Legal scholarship must address \keyterm{responsibility attribution} when high-autonomy agents make errors. Traditional agency law provides foundations but novel questions require theoretical and doctrinal development.

\paragraph{Goal specification methods}
How do humans effectively communicate goals to AI agents? Natural language is ambiguous; formal specifications are burdensome. Research on \keyterm{goal specification interfaces}, contracts, and verification methods would advance practice.

\paragraph{Multi-agent coordination in professional contexts}
As L5 \keyterm{multi-agent systems} emerge, coordination mechanisms from MAS research must be adapted for professional requirements. How do legal agents negotiate task allocation while maintaining privilege protections? How is credit and blame attributed in collaborative work?

\paragraph{Cross-domain synthesis}
Extending this work's approach to medical AI, financial AI, and other professional domains would reveal common patterns and domain-specific requirements, informing policy and technical development.

\paragraph{Longitudinal studies of adoption}
How do legal organizations actually deploy agentic AI? What governance structures emerge? What training proves effective? Empirical studies of real-world adoption would complement theoretical analysis.
\end{keybox}

\subsection{Implications for Practice}

\begin{highlightbox}[colback=bg-note, colframe=border-note]
\textbf{For legal practitioners evaluating AI products:}
\begin{itemize}
\item Apply the \keyterm{ten-question rubric} (Section~\ref{sec:synthesis}) to distinguish genuinely agentic systems from chatbots with legal vocabulary
\item Recognize that higher \keyterm{autonomy} brings both capability and risk---align deployment with capability levels
\item Demand \keyterm{attribution} and \keyterm{provenance} mechanisms; systems lacking these require prohibitive verification effort
\item Treat AI agents as junior associates requiring supervision, not oracles requiring deference
\item Invest in training emphasizing limitations, verification requirements, and appropriate use cases
\end{itemize}
\end{highlightbox}

\begin{highlightbox}[colback=bg-note, colframe=border-note]
\textbf{For developers building legal AI systems:}
\begin{itemize}
\item Design for the ten legal-specific requirements (attribution, provenance, escalation, confidentiality, etc.)
\item Embrace standards like \keyterm{MCP} for interoperability
\item Evaluate systems on \keyterm{task completion} and \keyterm{adaptation}, not just accuracy
\item Provide transparency into agent decision-making for auditability
\item Build \keyterm{escalation protocols} that recognize human judgment needs
\end{itemize}
\end{highlightbox}

\begin{highlightbox}[colback=bg-note, colframe=border-note]
\textbf{For researchers:}
\begin{itemize}
\item Adopt \keyterm{cross-disciplinary perspectives}---no single discipline has monopoly on agency insights
\item Develop evaluation frameworks assessing \keyterm{agentic properties} beyond traditional accuracy metrics
\item Study real-world deployment to understand adoption patterns and failure modes
\item Engage with professional communities to understand domain-specific requirements
\item Contribute to \keyterm{liability} and \keyterm{accountability frameworks} addressing novel questions
\end{itemize}
\end{highlightbox}

\begin{highlightbox}[colback=bg-note, colframe=border-note]
\textbf{For policymakers and regulators:}
\begin{itemize}
\item Regulate based on \keyterm{architectural properties} (autonomy level, capability level) rather than marketing labels
\item Require transparency mechanisms enabling verification of \keyterm{attribution} and \keyterm{provenance}
\item Mandate human oversight aligned with autonomy levels---higher autonomy requires stronger oversight
\item Develop \keyterm{risk-based frameworks} as in EU AI Act, with legal AI likely in high-risk categories
\item Coordinate with professional ethics bodies to align AI governance with professional responsibilities
\end{itemize}
\end{highlightbox}

\subsection{Final Reflections}

We opened by noting that few words have been uttered by so many with so little agreement as ``\keyterm{agent}'' and ``\keyterm{agentic}.'' This paper has not resolved that disagreement---nor should it. The \emph{polysemy reflects genuine diversity} in how disciplines conceptualize goal-directed systems. Philosophy's concern with intentionality, psychology's focus on self-regulation, law's emphasis on fiduciary duty, economics' analysis of incentives, and AI's pragmatic tool-use definitions each serve legitimate purposes.

What we have provided is a \emph{map of this conceptual landscape}: historical evolution revealing how we arrived at current diversity, disciplinary perspectives showing complementary emphases, analytical dimensions enabling structured comparison, and synthesized frameworks supporting practical evaluation. This map does not eliminate disagreement, but it enables more productive discourse.

As \keyterm{agentic AI systems} become more capable and more widely deployed in high-stakes professional domains, the stakes of definitional clarity increase. When a legal AI makes an error, \emph{who is responsible?} When an agent escalates inappropriately, \emph{what went wrong?} When capabilities exceed oversight capacity, \emph{how do we ensure accountability?} These questions cannot be answered without shared vocabulary for discussing autonomy levels, entity frames, goal dynamics, and architectural properties.

The intellectual history traced in this paper---from \textcite{anscombe1957intention}'s \keyterm{practical knowledge} through \textcite{russellnorvig2020aima}'s \keyterm{perception-action loops} to \textcite{willison-2025-agents-definition}'s \keyterm{tools-in-a-loop consensus}---provides stable foundations for navigating rapid change. \emph{The concepts are old; the technologies are new; the challenge is synthesis.} We hope this work contributes to that synthesis, enabling clearer communication, better evaluation, and more responsible deployment of agentic AI systems in law and beyond.

The journey from ``driving cattle'' to ``pleading a case'' (both senses of Latin \textit{ag≈ç}) to ``running tools in a loop'' spans \emph{millennia of human intellectual development and decades of computational innovation}. The journey continues. May this map help navigate the path ahead.

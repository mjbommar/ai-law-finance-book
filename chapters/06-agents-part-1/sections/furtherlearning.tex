\section{Conclusion}
\label{sec:furtherlearning}

This chapter traced how eight disciplines—philosophy, psychology, law, economics, cognitive science, complex systems, computer science, and AI—approach agency from different angles. Rather than forcing consensus, we extracted practical frameworks that respect this diversity while enabling clear evaluation.

\subsection{Key Takeaways}

\paragraph{The three-level hierarchy} An \keyterm{agent} requires three minimal properties (goals, perception, action). An \keyterm{agentic system} adds three more for operational deployment (iteration, adaptation, termination). \keyterm{Agentic AI} implements these six properties through artificial intelligence rather than traditional programming. This hierarchy provides clear criteria for evaluating any system.

\paragraph{The six-question test} Does it have goals? Does it perceive? Does it act? Does it iterate? Does it adapt? Does it stop? Systems meeting all six criteria qualify as agents in professional contexts. This rubric translates theory into practical evaluation.

\paragraph{Four analytical dimensions} The autonomy spectrum (delegated to self-directed), entity frames (human to institutional to machine), goal dynamics (acceptance to negotiation), and persistence requirements structure how disciplines define agency differently. These dimensions enable precise discussion of where definitions agree and diverge.

\paragraph{Disciplinary diversity matters} Eight disciplines—philosophy, psychology, law, economics, cognitive science, complex systems, computer science, and AI—each emphasize different aspects. No single perspective captures the whole. Understanding this diversity prevents talking past each other and enables productive synthesis.

\paragraph{Historical convergence on tools-in-a-loop} Early definitions (1950s-1980s) focused on humans. The 1990s broadened to pure machines. The 2020s LLM era converged on ``tools-in-a-loop'' architectures: \textcite{willison-2025-agents-definition}'s synthesis captures the emerging consensus across research and industry.

\paragraph{Professional applications require additional safeguards} Legal and financial contexts demand attribution to sources, auditable provenance, escalation protocols, and confidentiality mechanisms. These don't change what makes something an agent—they define what makes an agent suitable for high-stakes work.

\subsection{The Framework}

From this disciplinary diversity, we extracted a practical three-level framework. An \keyterm{agent} requires three minimal properties: goals, perception, and action. This baseline applies to humans, organizations, thermostats, and computational systems alike. An \keyterm{agentic system} adds iteration, adaptation, and termination—the six properties needed for reliable operational deployment in professional contexts. \keyterm{Agentic AI} refers to systems implementing these six properties through artificial intelligence rather than traditional programming. This hierarchy provides scaffolding for evaluating real systems against clear criteria.

The six-question evaluation rubric translates theory into practice: Does it have goals? Does it perceive? Does it act? Does it iterate? Does it adapt? Does it stop? Systems meeting all six criteria qualify as agents in professional contexts. Four analytical dimensions—the autonomy spectrum (delegated to self-directed), entity frames (human to machine), goal dynamics (acceptance to negotiation), and persistence requirements—provide organizing principles for comparing definitions and understanding where disagreements arise.

\subsection{Historical Perspective}

The historical evolution we traced reveals both convergence and persistent tensions. Early definitions (1950s-1980s) focused on humans or human-AI relationships, rooted in philosophy, psychology, law, and economics. The 1990s computational revolution broadened entity frames to include pure machines, driven by distributed systems, the internet, and advances in AI. The LLM era (2020s onward) has simultaneously sharpened around ``tools-in-a-loop'' architectures while introducing hybrid framings where humans provide goals and oversight while AI executes multi-step tasks.

\textcite{willison-2025-agents-definition}'s practitioner synthesis—``LLM agent runs tools in a loop to achieve a goal''—captures the emerging consensus that spans research frameworks \parencite{yao2022react}, commercial implementations (LangChain, LlamaIndex, vendor APIs), and operational definitions across the AI engineering community. While not fully standardized, this architectural convergence provides stable foundations for current practice.

\subsection{Professional Application}

For professional applications in law and finance, general agency definitions must be augmented with domain-specific requirements: attribution to authoritative sources, auditable provenance, escalation protocols recognizing human judgment needs, and confidentiality mechanisms protecting privilege. These requirements don't change what makes something an agent; they define what makes an agent suitable for high-stakes professional work. Subsequent chapters address these professional safeguards in detail.

As agentic AI systems become more capable and widely deployed in professional domains, definitional clarity matters. When a legal AI makes an error, who is responsible? When an agent escalates inappropriately, what went wrong? When capabilities exceed oversight capacity, how do we ensure accountability? These questions require shared vocabulary for discussing autonomy levels, entity frames, goal dynamics, and architectural properties.

\subsection{Connections and Further Reading}

This foundational chapter connects to several companion chapters in this textbook. The governance chapter explores professional safeguards—attribution, provenance, escalation, and confidentiality—in depth. The architectures chapter details contemporary patterns like ReAct (reasoning and acting) and Reflexion (self-reflection). The evaluation chapter addresses capability levels and comprehensive benchmarks. The regulation chapter analyzes frameworks like the EU AI Act and NIST guidance. Implementation chapters provide practical guidance for deployment in legal practice and financial services.

For readers seeking deeper engagement with specific disciplinary traditions, we recommend: \textcite{bratman1987intention} for the philosophical BDI foundation; \textcite{bandura1989human} for psychological perspectives on human agency; \textcite{restatement2006agency} for legal foundations; \textcite{jensen1976theory} for economic principal-agent theory; \textcite{russell2010artificial} for comprehensive AI coverage; \textcite{wooldridge2009introduction} for multi-agent systems; and \textcite{xi2023rise} for contemporary LLM-based agents.

\subsection{Final Thoughts}

The intellectual history traced in this chapter—from \textcite{anscombe1957intention}'s practical knowledge through \textcite{russellnorvig2020aima}'s perception-action loops to \textcite{willison-2025-agents-definition}'s tools-in-a-loop consensus—provides stable conceptual foundations for navigating rapid technological change. The concepts are old; the technologies are new; the challenge is synthesis.

The journey from ``driving cattle'' to ``pleading a case'' (both senses of Latin \textit{agō}) to ``running tools in a loop'' spans millennia of human intellectual development and decades of computational innovation. These conceptual foundations continue through the remaining chapters of this textbook and into your professional practice.

% ============================================================================
% 06-memory.tex
% Q5: How Does an Agent Remember Things?
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{How Does an Agent Remember Things?}
\label{sec:agents2-memory}

% ----------------------------------------------------------------------------
% Opening: Q5 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

The previous two sections examined how agents gather information (perception) and effect change (action). However, these capabilities operate in the moment: the agent perceives the current state, reasons about it, and acts. Without memory, every interaction resets. The agent cannot recall prior research, successful strategies, or case history. Memory transforms an agent from a stateless tool into a system that learns and adapts.

Every experienced professional knows that institutional memory distinguishes efficient work from reinventing the wheel. When you start a new securities registration, you do not begin from scratch. You pull prior S-1 filings (IPO registrations), review SEC comment history, and check the precedent database for disclosure language. You do not re-research basic questions. The firm maintains templates that incorporate years of accumulated knowledge.

The same principle applies to portfolio management. When you revisit an equity position, you do not rebuild the investment thesis. You retrieve the research file, review prior models, and update assumptions with new data. Accumulated research enables incremental refinement rather than duplicative work.

Memory in agentic systems serves a parallel function: context retention across sessions and learning from experience. With memory, the agent maintains continuity---building on prior work rather than starting over.

\begin{definitionbox}[title={Agent Memory}]
\keyterm{Agent memory} stores and retrieves information across timescales \parencite{park2023generative,wang2023llmagents}.
\begin{itemize}[nosep]
    \item \textbf{Working Memory:} The documents actively loaded in the agent's context (like papers on a desk).
    \item \textbf{Episodic Memory:} The history of actions and outcomes for a specific matter (like a case file).
    \item \textbf{Semantic Memory:} The general principles and institutional knowledge available for retrieval (like the firm's precedent archive).
\end{itemize}
\end{definitionbox}

% ----------------------------------------------------------------------------
% Memory Types
% ----------------------------------------------------------------------------

\subsection{Memory Types: From Desk to Archive}
\label{sec:agents2-memory-types}

Law firms use layered filing systems, each suited to different timescales. The associate's desk holds active work; the matter file contains engagement history; the precedent database archives institutional knowledge. Each layer trades immediacy for capacity. Agent memory systems follow the same pattern.

\textbf{Working memory} utilizes the \keyterm{context window}---the text currently loaded in the LLM's active attention. Just like desk space, context windows have strict limits. An associate can only have so many documents open at once; an agent can only hold so many \keyterm{tokens} (units of text, roughly 0.75 words) in active context. As of late 2025, leading models handle roughly 200,000 tokens. When the task exceeds this limit, you need other storage systems. In finance, this parallels the active trading screen: live prices and positions are immediate but transient.

\textbf{Episodic memory} corresponds to the matter file. Every memo, correspondence, and research result related to an engagement goes here. The associate does not re-research answered questions; the file provides the history. In agentic systems, episodic memory captures the log of actions and outcomes \parencite{park2023generative}. The agent records: ``I searched for Ninth Circuit venue cases, found three opinions, and drafted the analysis.'' When asked a follow-up, the agent retrieves that prior state. This mirrors the financial research file: you pull prior analysis and update it, rather than starting fresh.

\textbf{Semantic memory} is the firm's precedent database. Institutional knowledge accumulates over decades. When you need a force majeure clause, the database offers fifty examples. Agentic systems implement this through \textbf{Retrieval-Augmented Generation (RAG)}: dynamically fetching relevant information from a large corpus to augment reasoning \parencite{lewis2020rag}. RAG enables agents to access knowledge beyond the context window.

The technology powering RAG is the \keyterm{vector store}, which makes databases searchable by meaning rather than just keyword. Vector stores encode documents as \keyterm{embeddings}---high-dimensional numerical representations of semantic meaning \parencite{reimers2019sbert}. A search for ``breach of fiduciary duty'' finds documents about ``violation of trust obligations'' because their numerical representations are close in vector space.

% ----------------------------------------------------------------------------
% RAG Implementation
% ----------------------------------------------------------------------------

\subsection{Retrieval-Augmented Generation (RAG)}
\label{sec:agents2-rag}

RAG enables agents to access institutional knowledge, equivalent to asking the firm librarian for "our best research on this issue." While traditional keyword search misses concepts phrased differently, semantic search finds conceptually similar content.

The RAG pipeline has four steps:
\begin{enumerate}
    \item \textbf{Chunking:} Breaks documents into semantic units (e.g., paragraphs or sections) while preserving metadata (source, date).
    \item \textbf{Embedding:} Converts each chunk into a vector that encodes its meaning.
    \item \textbf{Retrieval:} Finds chunks similar to the user's query by comparing vectors.
    \item \textbf{Generation:} Injects the retrieved content into the agent's prompt, allowing the LLM to answer using the specific knowledge.
\end{enumerate}

Robust implementations enhance basic RAG with advanced patterns. \textbf{Hybrid retrieval} combines semantic search (vectors) with keyword search (BM25), catching both conceptual matches and exact terms (like specific case citations). \textbf{Query rewriting} transforms vague user questions (``What's the rule?'') into specific search queries based on conversation history. \textbf{Reranking} scores initial results by authority or relevance, ensuring binding precedent ranks above secondary sources. \textbf{Filtered retrieval} constrains results by metadata, such as jurisdiction or date, preventing New York agents from citing California law.

\begin{keybox}[title={Warning: The Hallucination Risk}]
Fabricated citations are a critical failure mode. Studies show that even RAG-enabled tools can hallucinate 17--33\% of the time \parencite{dahl2024hallucinations}. You must implement a strict verification step: before any citation reaches the user, the system must verify that the source exists in the retrieved context.
\end{keybox}

% ----------------------------------------------------------------------------
% Domain-Specific Memory Considerations
% ----------------------------------------------------------------------------

\subsection{Domain-Specific Memory Considerations}
\label{sec:agents2-memory-domain}

Memory for regulated services requires enhancements beyond generic implementations. You must account for authority, jurisdiction, and time.

\textbf{Authority Weighting.} Not all information is equal. Perception systems must rank primary authority (statutes, binding precedent) above secondary sources. When searching ``insider trading liability,'' a Supreme Court opinion outranks a law review article. Financial systems effectively rank SEC no-action letters above client alerts.

\textbf{Jurisdiction Awareness.} Legal information is bounded by jurisdiction. California precedent does not bind Texas courts. Metadata tagging must enable strict filtering. An agent researching Delaware corporate law must not surface New York cases as controlling authority.

\textbf{Temporal Validity.} Law and markets change. Citator integration (like Shepard's) validates that cases remain good law. A 1985 case may be overruled; RAG must surface the current state. In finance, validity varies by context: trading data expires in milliseconds, while industry analysis lasts quarters. Memory systems must tag data with effective dates and trigger refreshes when content becomes stale.

\textbf{Identifier Resolution.} Citations and tickers vary. ``123 F.3d 456'' and ``123 F3d 456'' are the same case. Companies have multiple identifiers: Ticker, CUSIP, ISIN, LEI. Without normalization, retrieval fails to connect related records.

% ----------------------------------------------------------------------------
% Matter and Client Isolation (CRITICAL)
% ----------------------------------------------------------------------------

\subsection{Matter and Client Isolation}
\label{sec:agents2-memory-isolation}

Critically, memory systems must enforce \keyterm{ethical walls}. Information from Matter A cannot leak into Matter B. If an agent uses Matter A's privileged info on adverse Matter B, it risks privilege waiver and malpractice. In finance, this prevents Material Non-Public Information (MNPI) leakage.

Implementing separation requires four controls:
\begin{itemize}
    \item \textbf{Namespaces:} Give each matter an isolated memory partition.
    \item \textbf{Scoped Retrieval:} Queries strictly access only the current matter's namespace.
    \item \textbf{Access Control:} Role-based permissions determine which agents (and humans) can access a namespace.
    \item \textbf{Audit Trails:} Log every read/write with timestamp, identity, and matter ID for compliance review.
\end{itemize}

Secure deletion and retention controls are often required by organizational policy and may be legally required depending on the engagement, jurisdiction, and applicable retention rules. When a matter closes or a client relationship ends, memory should be deleted or archived according to a documented retention schedule, with deletion (when required) implemented in a verifiable way.

% ----------------------------------------------------------------------------
% Evaluating Memory Systems
% ----------------------------------------------------------------------------

\subsection{Evaluating Memory Systems}
\label{sec:agents2-memory-eval}

Testing memory requires specific metrics for professional practice.

\textbf{Retrieval Quality.} Measure \textit{precision} (are retrieved documents relevant?) and \textit{recall} (did we find all relevant documents?). Use "gold standard" research memos as test sets: does the agent find the same authorities the human expert cited?

\textbf{Isolation Integrity.} Verify that cross-matter queries return zero results. Matter A's agent should never retrieve Matter B's documents. Red-team testing should deliberately attempt to breach these walls.

\textbf{Temporal Validity.} Measure freshness. How often does the system surface overruled precedent or stale prices? Track the lag between a regulatory change and its availability in the knowledge base.

\textbf{Scale Performance.} Episodic memory grows rapidly. Ensure retrieval latency remains low even as a litigation matter generates thousands of documents.

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Memory to Planning}
\label{sec:agents2-memory-planning}

Memory provides the context agents need to plan. Without memory, agents repeat failed strategies. Research starts from scratch. Preferences are forgotten.

With memory, agents learn. The agent recalls: ``Last time, broad search terms yielded too much noise. This time, I will use narrow queries.'' Prior work is built upon. User preferences persist.

Memory supports \textbf{Adaptation}---the ``A'' in the GPA+IAT framework---because behavior improves as the system learns from experience.

\Cref{sec:agents2-planning} examines the next question: how does an agent break a big job into steps? Just as the case file enables strategic litigation planning, agent memory enables systematic task decomposition.

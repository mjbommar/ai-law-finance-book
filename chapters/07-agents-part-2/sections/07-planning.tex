% ============================================================================
% 07-planning.tex
% Q6: How Does an Agent Break a Big Job into Steps?
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{How Does an Agent Break a Big Job into Steps?}
\label{sec:agents2-planning}

% ----------------------------------------------------------------------------
% Opening: Q6 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

A litigation partner approaching a new matter does not start by drafting motions. The partner develops a strategy: discovery first (identifying needed facts), then dispositive motions if the law favors the client, followed by settlement discussions or trial preparation. Discovery breaks into phases: initial disclosures, document requests, interrogatories, and depositions. Tasks distribute across the team: a senior associate handles briefing, a junior associate reviews documents, and a paralegal manages scheduling. Throughout, the partner monitors progress against deadlines and adjusts strategy based on new facts.

This is \keyterm{planning}: decomposing complex goals into action sequences. It mirrors the litigation roadmap or deal timeline that guides execution. Without planning, agents react to immediate observations without strategy. With planning, they work systematically toward objectives, adapt when circumstances change, and recognize completion.

\begin{definitionbox}[title={Planning}]
\keyterm{Planning} decomposes complex goals into sequences of actions. It encompasses:
\begin{itemize}[nosep]
\item \textbf{Decomposition}: Breaking large tasks into manageable steps.
\item \textbf{Sequencing}: Ordering steps logically based on dependencies.
\item \textbf{Allocation}: Assigning steps to specific tools or sub-agents.
\item \textbf{Monitoring}: Tracking progress toward the goal.
\item \textbf{Adaptation}: Adjusting the plan when circumstances change.
\end{itemize}

Without planning, an agent resembles an associate running searches without a strategy---busy but not progressing toward a deliverable.
\end{definitionbox}

% ----------------------------------------------------------------------------
% Planning Patterns
% ----------------------------------------------------------------------------

\subsection{Planning Patterns}
\label{sec:agents2-planning-patterns}

Three patterns dominate agent planning, each suited to different task types.

\textbf{ReAct (Reasoning + Acting).} The most fundamental pattern interleaves reasoning with action \parencite{yao2022react}. Consider a partner asking for authority on an unenforceable forum selection clause. The associate reasons: ``Key grounds are unconscionability and public policy. I will start with \textit{Atlantic Marine}.'' They search, observe results, and reason again: ``Unconscionability cases involve consumer contracts, not our commercial context. The public policy line is stronger.'' They search again, refining based on results.

Each cycle has three components:
\begin{itemize}[nosep]
\item \textbf{Thought}: Explicit reasoning about what to do next.
\item \textbf{Action}: A tool call to gather information or effect change.
\item \textbf{Observation}: The tool output that informs the next thought.
\end{itemize}
Reasoning traces make decisions transparent and auditable. ReAct works well for exploratory tasks where you learn as you go---legal research, fact investigation, and market analysis.

\textbf{Plan-Execute.} This pattern separates planning from execution. For a document review task (``Review 50 contracts for choice-of-law provisions''), the associate creates a plan: list the contracts, open each one, extract the provision, and record findings. Then they execute systematically. The plan remains static because the task is well-defined.

Plan-Execute fits established workflows: due diligence checklists, compliance reviews, and document assembly. You create the plan upfront and execute methodically. Research variants like ReWOO \parencite{xu2023rewoo} (separating reasoning from observation) and LLMCompiler \parencite{kim2024llmcompiler} (optimizing execution graphs) enable parallel tool calling. However, the core pattern remains: plan first, then execute.

\textbf{Hierarchical Planning.} Law firms decompose matters into workstreams delegated through layers. A parent agent receives a high-level goal, breaks it into sub-goals, and delegates to specialists. ``Prepare for trial'' becomes:
\begin{itemize}[nosep]
\item Finalize witness list (delegated to Agent A).
\item Prepare exhibits (delegated to Agent B).
\item Draft jury instructions (delegated to Agent C).
\end{itemize}
Each specialist may decompose further. This enables parallelization and specialization, mirroring how litigation teams work. \Cref{sec:agents2-delegation} details these coordination patterns.

These patterns represent a shift from traditional workflow automation. Traditional engines used \textbf{static orchestration}: predefined graphs specifying exact steps and branches (BPM systems). The workflow was designed at build time; the engine merely executed it.

\begin{definitionbox}[title={Static vs.\ Dynamic Orchestration}, breakable=false]
\textbf{Static orchestration} executes predefined workflow graphs. The same input always produces the same execution path. It is predictable and auditable but inflexible.

\vspace{0.5em}
\textbf{Dynamic orchestration} reasons about task decomposition at runtime. The LLM examines the goal, considers available resources, and constructs a plan on the fly. It is adaptive but less predictable.
\end{definitionbox}

LLM-based orchestration is inherently dynamic. ``Prepare for trial'' decomposes differently depending on case complexity. The LLM constructs a delegation structure based on the specific context. This adaptability is both the promise and the challenge.

Static workflows handle anticipated scenarios. Dynamic orchestration handles novel situations. Maintenance costs also differ: static workflows require explicit updates, while dynamic orchestration absorbs changes through prompt updates.

\begin{keybox}[title={Auditability Challenge}, breakable=false]
Static workflows produce predictable execution traces. Dynamic orchestration may produce different decompositions for similar inputs, complicating audit. For regulated applications, you must log the \textit{reasoning} behind orchestration decisions, not just the decisions themselves.
\end{keybox}

Production systems often combine both. High-volume, well-understood processes use static workflows. Complex, novel tasks use dynamic orchestration. The planning patterns described above---ReAct, Plan-Execute, Hierarchical---are forms of dynamic orchestration.

% ----------------------------------------------------------------------------
% Choosing the Right Pattern
% ----------------------------------------------------------------------------

\subsection{Choosing the Right Planning Pattern}
\label{sec:agents2-planner-selection}

Selecting the right pattern depends on task structure and required autonomy.

\begin{table}[htbp]
\centering
\caption{Planning pattern selection guide}
\label{tab:agents2-planner-selection}
\small
\begin{tabular}{p{0.22\textwidth}p{0.14\textwidth}p{0.14\textwidth}p{0.32\textwidth}}
\toprule
\textbf{Task Type} & \textbf{Pattern} & \textbf{Autonomy} & \textbf{Example} \\
\midrule
Well-defined steps, known scope & Plan-Execute & Moderate & Credit review, compliance audit, due diligence checklist \\
\midrule
Exploratory, learns as it goes & ReAct & Higher & Legal research, fact investigation, market analysis \\
\midrule
Complex, parallel workstreams & Hierarchical & Distributed & M\&A transaction, portfolio construction, multi-jurisdiction filing \\
\bottomrule
\end{tabular}
\end{table}

Higher autonomy requires more sophisticated oversight.

Plan-Execute operates with moderate autonomy. The agent works within bounds defined by the plan. Oversight focuses on plan validation. ReAct involves higher autonomy because the agent decides what to search and when to stop. Oversight requires explicit termination mechanisms and confidence thresholds. Hierarchical patterns distribute autonomy. Oversight requires clear delegation contracts and escalation paths. You must match oversight rigor to autonomy level.

% ----------------------------------------------------------------------------
% Understanding the Task
% ----------------------------------------------------------------------------

\subsection{Understanding the Task Before Planning}
\label{sec:agents2-pre-planning}

Before planning, agents must understand the request. \Cref{sec:agents2-intent} covers intent extraction. For planning, the key outputs are task classification, constraints, and success criteria.

Task classification determines the planning pattern: exploratory (ReAct), structured (Plan-Execute), or complex (Hierarchical). Constraints define the bounds: deadlines, budgets, and scope. Success criteria define how the agent recognizes completion.

Effective planning requires clear inputs. Ambiguous goals produce unfocused plans. Unclear success criteria make termination difficult.

% ----------------------------------------------------------------------------
% Budget Architecture
% ----------------------------------------------------------------------------

\subsection{Budget Architecture}
\label{sec:agents2-budgets}

Without resource budgets, agents can run indefinitely. This is the ``runaway associate'' problem: asking for two cases and receiving fifty. We allocate budgets as a planning mechanism to control execution.

Four budget types control consumption:
\begin{itemize}[nosep]
    \item \textbf{Token Budgets:} Limit LLM API consumption to prevent expensive reasoning loops.
    \item \textbf{Time Budgets:} Enforce deadlines by stopping execution after a fixed duration (e.g., 10 minutes).
    \item \textbf{Tool Call Budgets:} Cap external interactions (e.g., max 20 searches).
    \item \textbf{Cost Budgets:} Cap total spending in dollars.
\end{itemize}

Budgets cascade. A session budget constrains the engagement; a task budget allocates resources to items; subtask budgets subdivide further. A research task might receive 30 minutes and 50,000 tokens. Subtasks share this pool rather than receiving unlimited resources.

Token costs compound. A 200-page credit facility requires roughly 80,000 tokens to ingest. Analysis consumes more. A comprehensive review might reach 1,000,000 tokens. You must monitor aggregate costs, not just per-task.

The economics depend on the task. Retrieval-heavy tasks (document review) show clear ROI. Judgment-intensive tasks require extensive human review, potentially reducing ROI. Transparency about AI assistance enables clients to evaluate value \parencite{aba-formal-opinion-512}.

Agents should degrade gracefully when budgets tighten. Tiered outputs provide value at every level. A minimal budget returns the statute. A moderate budget adds holdings. A full budget delivers analysis. Soft limits (80\% of budget) warn the agent to prioritize completion. Hard limits (100\%) terminate execution. A budget-aware agent that delivers partial results is superior to one that fails completely.

% ----------------------------------------------------------------------------
% Knowing When to Stop
% ----------------------------------------------------------------------------

\subsection{Knowing When to Stop}
\label{sec:agents2-termination-preview}

Knowing when to stop is a critical planning capability. We define four stopping conditions:
\begin{enumerate}
    \item \textbf{Success:} The goal is achieved (question answered, document reviewed).
    \item \textbf{Resource Exhaustion:} Budgets are hit. The agent returns partial results or escalates.
    \item \textbf{Confidence Thresholds:} Uncertainty is too high. The task routes to human review.
    \item \textbf{Error Conditions:} Repeated failures indicate a problem retrying won't solve.
\end{enumerate}

You must define explicit stopping rules. Instruct the agent as you would an associate: ``If you find three consistent opinions, stop. If you find nothing after two hours, escalate.''

% ----------------------------------------------------------------------------
% Guardrails and Loop Detection
% ----------------------------------------------------------------------------

\subsection{Guardrails and Loop Detection}
\label{sec:agents2-guardrails}

Agents can get stuck in loops despite budgets. Mechanisms like step limits, reflection checkpoints, and external watchdogs prevent this. \Cref{sec:agents2-loop-detection} examines these in detail.

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Planning to Termination}
\label{sec:agents2-planning-termination}

Planning decomposes work, but every plan must end. The next two questions address the boundaries of autonomous execution.

\Cref{sec:agents2-termination} (Termination) addresses how an agent knows it is done. This requires defining success criteria and budget limits. \Cref{sec:agents2-escalation} (Escalation) addresses how an agent knows when to ask for help. This requires confidence thresholds and authority boundaries.

Without clear termination, agents run forever. Without escalation, they exceed authority. These boundaries define the safe operating envelope for autonomous systems.


% ============================================================================
% 01-introduction.tex
% Introduction and Context
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{Introduction}
\label{sec:agents2-intro}

% ----------------------------------------------------------------------------
% Opening and Context
% ----------------------------------------------------------------------------

Part I answered \textit{What is an agent?}---tracing the concept from cybernetics to modern LLM systems and introducing the GPA+IAT framework (Goal, Perception, Action, Iteration, Adaptation, Termination).

Part II answers: \textit{How do you build one?}

Think about how a law firm or financial institution actually operates. A junior associate or analyst does not work in isolation. They have access to research databases, they maintain case files or deal books that accumulate over time, they break down complex partner assignments or portfolio manager requests into manageable tasks, and they coordinate with other professionals. The associate's effectiveness depends not just on their individual capabilities, but on the infrastructure around them: which systems they can access, what information they can retrieve from past matters, how they decompose ambiguous instructions into concrete work, and how they communicate results back up the chain.

Building an agent system mirrors building a professional organization. You must decide which tools the agent can access---like deciding whether an associate gets a Bloomberg terminal or just basic internet access. You must design memory systems that preserve context across interactions---like maintaining a case file that follows a matter through discovery, motion practice, and trial. You must implement planning mechanisms that break complex goals into steps---like a senior attorney delegating research, drafting, and review tasks. And you must establish protocols for how agents interact with each other and with humans---like the information barriers between practice groups or the escalation procedures when a junior attorney encounters something beyond their authority.

This chapter provides architectural patterns and mental models for designing these systems. We are not teaching you to program agents from scratch. Instead, we are showing you how the components fit together, what trade-offs exist, and how design choices affect capability and risk. Think of this as learning how a firm is organized---which roles exist, what each contributes, and how workflows connect them---even if you are not personally performing every task.

% ----------------------------------------------------------------------------
% Core Concepts: Tools, Memory, Planning
% ----------------------------------------------------------------------------

\begin{definitionbox}[title={\textbf{Tool}}]
A \keyterm{tool} is an interface enabling agents to interact with external systems. Tools are the agent's Westlaw subscription, Bloomberg terminal, EDGAR database access, document management system, and e-filing portal. Without tools, even the most sophisticated model can only reason about what it already knows---like an associate locked in a library with no internet.
\end{definitionbox}

\begin{definitionbox}[title={\textbf{Agent Memory}}]
\keyterm{Agent memory} stores and retrieves information across timescales. Short-term memory is the documents spread across an associate's desk during active work. Long-term memory is the firm's knowledge management system with decades of research memos. Episodic memory is the case file that tracks what happened on this specific matter. Semantic memory is the legal principles every attorney internalizes over their career.
\end{definitionbox}

\begin{definitionbox}[title={\textbf{Planning}}]
\keyterm{Planning} decomposes complex goals into achievable sub-tasks and adapts strategy based on results. When a partner assigns a vague directive like "research our exposure on the employment matter," planning is what transforms that into concrete steps: identify the jurisdiction, search relevant statutes, find case law, synthesize holdings, draft a memo. Without planning, agents thrash between uncoordinated actions like an associate who keeps running searches without a research strategy.
\end{definitionbox}

% ----------------------------------------------------------------------------
% From Framework to Components
% ----------------------------------------------------------------------------

\subsection{From Framework to Components}
\label{sec:agents2-framework-mapping}

Part I introduced the GPA+IAT framework as an abstract characterization of agency---six properties that distinguish agents from simple question-answering systems. Part II grounds that framework in concrete technical components. Here is how conceptual properties map to buildable architecture:

\textbf{Goal} becomes the \keyterm{planning system}. Imagine a litigation partner who assigns a junior associate the goal "prepare for summary judgment." The associate cannot simply execute that instruction directly---they must decompose it into achievable steps: review the complaint, identify each claim, research the legal standard for each, find supporting evidence in discovery, draft argument sections, cite check, format the brief. The planning system does the same work for an agent: it takes an abstract objective and produces a sequence of concrete actions.

\textbf{Perception} becomes \textit{read-only tools and retrieval}. Think of a paralegal gathering documents for a filing. They need access to the court's electronic filing system to check formatting requirements, the firm's document management system to retrieve prior filings, public databases to verify party information. Each system is a tool. The paralegal's ability to perceive the current state of the case---what has been filed, what is missing, what deadlines are approaching---depends entirely on which tools they can access and how effectively they can query them.

\textbf{Action} becomes \textit{write and execute tools}. A junior analyst at an investment bank might prepare a trading recommendation, but only a senior trader can actually execute the trade. Similarly, a portfolio manager at a hedge fund can rebalance positions, but the compliance officer must approve any trades that exceed position limits. That distinction---between analysis and execution---is the difference between read-only tools (perception) and write tools (action). Agents with write access can change the state of the world: file documents with courts, send emails to clients, execute trades, modify databases. Each write operation introduces risk and requires corresponding authorization controls.

\textbf{Iteration} becomes the \keyterm{agent loop}. Consider how discovery actually works: you serve requests, the other side produces documents, you review them and identify gaps, you serve follow-up requests, they produce more documents, you revise your theory of the case. This is iteration---a cycle of perceiving new information, reasoning about what it means, and taking the next action. Agents implement the same loop: invoke a tool to gather information, process the results, decide what to do next, invoke another tool, process those results, continue until the goal is satisfied or a termination condition is met.

\textbf{Adaptation} becomes \textit{memory systems}. A third-year associate handling their tenth employment discrimination case does not start from scratch each time. They remember which defenses succeeded in prior cases, which judges care about particular procedural details, which expert witnesses are credible. This accumulated experience makes them more effective over time. Agent memory systems serve the same function: storing past interactions, successful strategies, and domain knowledge so the agent improves with experience rather than treating every task as novel.

\textbf{Termination} becomes \keyterm{guardrails} and \keyterm{success criteria}. Imagine an associate assigned to "research the issue thoroughly" with no other guidance. When do they stop? After reading ten cases? Fifty? After three hours or three days? Without termination conditions, the associate could research indefinitely. Agents face the same problem, but worse---they can burn through API budgets or wander into irrelevant tangents far faster than humans. Termination logic specifies when to stop: goal achieved, budget exhausted, time limit reached, confidence threshold crossed, or unrecoverable error detected.

Each dimension represents a design decision. You must specify how goals decompose (planning algorithms), which tools the agent accesses (tool inventory and permissions), how memory persists (storage architecture), and what triggers termination (success criteria and guardrails). The remaining sections detail these components, their interactions, and deployment patterns for legal and financial environments.

\begin{keybox}[title={Framework to Implementation}]
The GPA+IAT framework is not just conceptual---each dimension maps to concrete architectural components:
\begin{itemize}
  \item \textbf{Goal} $\rightarrow$ Planning systems that decompose objectives
  \item \textbf{Perception} $\rightarrow$ Read-only tools for information gathering
  \item \textbf{Action} $\rightarrow$ Write tools that change system state
  \item \textbf{Iteration} $\rightarrow$ Agent loops with termination conditions
  \item \textbf{Adaptation} $\rightarrow$ Memory systems that persist context
  \item \textbf{Termination} $\rightarrow$ Guardrails and success criteria
\end{itemize}
Building an agent means making explicit design choices for each component, not just connecting a language model to an API.
\end{keybox}

% ----------------------------------------------------------------------------
% Why Architecture Matters
% ----------------------------------------------------------------------------

\subsection{Why Architecture Matters}
\label{sec:agents2-why-arch}

Building an agent is not an incremental extension of a chatbot. It is architectural, like the difference between hiring a single contract attorney for document review versus designing a litigation team to handle complex multi-district litigation.

Consider what happens when a law firm or corporate legal department staffs a major matter. The partner or general counsel does not just assign one person to "handle it." They assemble a team: senior associates who know the substantive area, junior associates who will do the research and drafting, paralegals who manage documents and scheduling, contract attorneys who review discovery, and specialists like forensic accountants or technical experts. Each role has different access permissions: senior associates can communicate directly with the client or business unit, junior associates can access privileged work product, contract attorneys can only see documents cleared for their review, and outside experts operate under protective orders. The team maintains shared case files so everyone works from the same factual record, but individual attorneys keep their own notes. The partner sets overall strategy, but delegates tactical decisions to senior associates, who further delegate discrete tasks down the chain. The team iterates: discovery reveals new facts, the legal theory evolves, research priorities shift. And the partner decides when to stop: the case settles, the budget is exhausted, or the risk-reward calculation changes.

Agent systems require the same architectural thinking. An agent must:

Execute multiple actions across a task, like gathering statutes from Westlaw, regulations from government websites, and internal policy memos from the firm's knowledge base, then synthesizing them into a coherent analysis. This requires tool integration---ensuring the agent can authenticate to each system, query effectively, and handle different response formats.

Maintain context through memory, like remembering that the client is a financial institution subject to specific regulatory requirements, that prior research eliminated certain arguments as non-viable, and that the partner prefers citations in a particular format. Without memory, every action starts from scratch, forcing users to repeat context in every interaction.

Adapt based on intermediate results, like adjusting research strategy when initial case law searches return nothing relevant. A human attorney encountering dead ends will broaden their search, try different terms, look for analogous situations in other jurisdictions, or consult a more senior attorney. Agents need similar adaptation logic: if a tool call fails, try a different tool; if retrieved documents are not helpful, refine the query; if the plan is not working, revise it.

Collaborate with other agents or humans, like coordinating between a tax specialist and a corporate attorney on an M\&A transaction, a research analyst and a portfolio manager on an investment decision, or escalating to a partner when encountering an issue beyond the associate's authority. Multi-agent systems require protocols for communication, coordination, and conflict resolution. Human-in-the-loop systems require interfaces for review, approval, and intervention.

Operate with varying autonomy, from requiring approval for every research query (fully supervised) to running overnight and producing a draft memo by morning (fully autonomous). The right level of autonomy depends on risk: reading public documents is low-risk and can be autonomous; filing documents with courts is high-risk and typically requires human review; executing trades above certain thresholds might require dual approval.

Each capability introduces complexity and risk. Tools need authentication, authorization, and audit logging---like tracking which attorney accessed which client file and when. Memory must respect privilege boundaries---an agent working on one matter cannot access materials from an unrelated matter, even if both are in the same database. Planning requires termination conditions to prevent runaway costs---like an associate who keeps researching because they have not been told to stop. Protocols must authenticate participants and encrypt communications---like the information barriers that prevent material non-public information from crossing between departments at an investment bank.

For legal and financial applications, agents handle privileged material subject to attorney-client protection, material non-public information that triggers insider trading liability, and personally identifiable information governed by privacy regulations. Architecture must support security, isolation, and auditability from the start. You cannot retrofit privilege protections after an agent has already leaked confidential information across matter boundaries. You cannot add audit logging after regulators ask for records of who accessed what and when. You cannot impose information barriers after the agent has already mixed public and non-public data.

Think of this as building compliance into a financial institution's trading systems. You do not build the trading platform first and then try to add controls for wash sales, position limits, and suspicious activity reporting. You design those controls into the architecture from day one, because the cost of getting it wrong---regulatory sanctions, reputational damage, civil liability---far exceeds the cost of building it correctly in the first place.

\begin{highlightbox}
Agent architecture resembles organizational design more than software engineering. Just as you would not design a law firm or trading desk without considering access controls, escalation procedures, and audit trails, you cannot build a production agent system by simply connecting a language model to APIs. Security, isolation, and auditability must be architectural decisions, not afterthoughts.
\end{highlightbox}

The remaining sections of this chapter examine these components in detail: how tools work and what security controls they require (Section~\ref{sec:agents2-architecture}), how memory systems preserve context while respecting access boundaries (also Section~\ref{sec:agents2-architecture}), how planning algorithms decompose goals and when they terminate (also Section~\ref{sec:agents2-architecture}), how protocols enable safe communication between agents and systems (Section~\ref{sec:agents2-protocols}), and how to evaluate whether an agent actually works (Section~\ref{sec:agents2-evaluation}). Section~\ref{sec:agents2-synthesis} synthesizes these concepts through case studies and deployment patterns. Section~\ref{sec:agents2-further} provides resources for continued learning.

% TODO: Add timeline figure showing November 2024-2025 developments (MCP, A2A, commercial agent frameworks, etc.)
% TODO: Add motivating example of legal AI agent workflow

% ============================================================================
% 04-perception.tex
% Q3: How Does an Agent Find Things Out?
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{How Does an Agent Find Things Out?}
\label{sec:agents2-perception}

% ----------------------------------------------------------------------------
% Opening: Q3 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

The previous section examined how agents understand what they're being asked---extracting goals from instructions, detecting ambiguity, gathering context. But understanding a task is not the same as completing it. An agent that perfectly understands ``Research Ninth Circuit authority on personal jurisdiction'' still needs access to case law databases. An agent that correctly interprets ``Analyze this credit agreement from the lender's perspective'' still needs the credit agreement.

A junior associate's effectiveness depends not just on reasoning ability but on access. The ability to query Westlaw, access Bloomberg terminals, and search the firm's precedent database determines what problems the associate can actually solve. Without access to information sources, even the most capable professional reasons in a vacuum.

Agentic systems face the same constraint. An LLM can reason about legal and financial concepts, but without \textit{perception tools}---interfaces to external information---it cannot access current case law, market prices, client documents, or regulatory filings. Perception tools are the library card, the database subscription, and the research assistant combined: the mechanisms through which agents observe the world.

\begin{definitionbox}[title={Tools and Perception}, breakable=false]
A \keyterm{tool} is a function that allows an agent to interact with external systems. \keyterm{Perception tools} are read-only: they observe without changing the world. The agent queries a database, retrieves a document, or fetches market data, while the external system's state remains unchanged.

\vspace{0.5em}
Perception implements the ``P'' in the GPA framework; it answers the question of what information the agent can access to inform its reasoning.
\end{definitionbox}

In this section, we examine perception: the read-only tools that enable agents to gather information. \Cref{sec:agents2-action} then examines action: the write tools that enable agents to effect change. The distinction matters for governance, because read operations carry different risks than write operations.

% ----------------------------------------------------------------------------
% Perception Tool Categories
% ----------------------------------------------------------------------------

\subsection{Perception Tool Categories}
\label{sec:agents2-perception-categories}

Different tasks require different tools for gathering information, and effective perception depends on having the right tool for the purpose at hand. Perception tools fall into three main categories: information retrieval, document processing, and computation.

Information retrieval tools gather authoritative information from research platforms. Legal research tools include Westlaw, Lexis, Bloomberg Law, PACER for federal court filings \parencite{pacer-system}, state court docket systems, and regulatory databases like EDGAR \parencite{sec-edgar}. An agent with these tools can search case law, retrieve opinions, check citator status, and download filings. Financial research tools include Bloomberg Terminal, Reuters Eikon, FactSet, and proprietary analytics platforms. An agent with these tools can query real-time prices, retrieve fundamentals, access analyst research, and pull historical data. Internal knowledge bases round out the category, including the firm's document management system (iManage, NetDocuments), precedent databases, deal archives, and research memo repositories. An agent with access can retrieve prior work product, find template language, and check how the firm handled similar matters.

Document processing tools transform raw documents into usable information. Text extraction converts PDFs, scanned documents, and images into searchable text. OCR tools handle scanned filings; PDF parsers extract text from native documents; table extractors preserve structure from financial statements. Document classification identifies document types, which is essential in due diligence when an agent processing a data room needs to distinguish contracts from correspondence and financial statements from presentations. Entity extraction pulls parties, dates, amounts, and other structured data from unstructured documents. Extracting the borrower name, facility amount, and maturity date from a credit agreement enables structured analysis that would otherwise require manual review.

Computation tools handle perception tasks that require calculation rather than simple lookup. Deadline calculators determine response dates from rules. Federal Rules require answers within 21 days \parencite{frcp-rule-12}, but calculating from service date, accounting for holidays, and applying local rules requires computation rather than simple retrieval. Citation formatters convert case information into proper Bluebook format, and financial equivalents normalize identifiers (CUSIP, ISIN, ticker) across different systems. Risk metrics calculate exposure, VaR, duration, or other quantitative measures from position data. These computations inform reasoning without changing portfolios.

% ----------------------------------------------------------------------------
% Model Context Protocol (MCP) for Perception
% ----------------------------------------------------------------------------

\subsection{Model Context Protocol (MCP)}
\label{sec:agents2-mcp-perception}

The Model Context Protocol standardizes how agents access tools \parencite{anthropic-mcp}. Before standardization, every database had different commands and output formats: Westlaw worked one way, Lexis another, Bloomberg a third. MCP creates a common interface: learn the protocol once, access any compatible tool.

The architecture has three roles. The MCP Host manages the agent and controls which tools it can access, functioning like the firm's IT system determining database subscriptions. The MCP Client is the agent-side component that discovers and uses tools. The MCP Server exposes capabilities through a standardized interface; the document management system, internal knowledge base, or custom legal research tool each runs as an MCP server.

Communication follows a simple pattern: servers publish manifests declaring capabilities, clients connect through hosts, clients send structured requests, and servers return structured results.

For perception specifically, MCP defines \keyterm{Resources} as read-only data access endpoints. Resources let agents:

\begin{itemize}[nosep]
\item Query case law databases and receive structured results
\item Retrieve documents from management systems
\item Access market data feeds
\item Search internal knowledge bases
\item Fetch regulatory filings
\end{itemize}

Resources are explicitly read-only. They implement perception without enabling action. This separation enables fine-grained access control: an agent might have resource access (read documents) without tool access (file documents).

\begin{keybox}[title={MCP Eliminates the M$\times$N Problem}]
Without MCP, connecting 10 agents to 10 tools requires 100 custom integrations. With MCP, the same setup needs only 20 implementations because each agent and each tool learns the protocol once.

\vspace{0.5em}
In legal practice, one agent queries document management systems, internal knowledge bases, and custom research tools through the same protocol. In financial services, one agent accesses portfolio systems, risk engines, and compliance databases through the same protocol.

\vspace{0.5em}
As of late 2025, over 7,260 MCP servers have been catalogued in community directories, providing ready-made integrations for common tools.
\end{keybox}

% ----------------------------------------------------------------------------
% Memory as Perception
% ----------------------------------------------------------------------------

\subsection{Memory as Perception into Institutional Knowledge}
\label{sec:agents2-memory-perception}

Memory systems (\Cref{sec:agents2-memory}) serve as perception tools into institutional knowledge. When an agent queries the firm's precedent database, it perceives accumulated expertise through several mechanisms.

Retrieval-Augmented Generation, or RAG, enables semantic search over document archives. The agent doesn't just keyword-match; it finds conceptually similar content. A search for ``breach of fiduciary duty'' retrieves documents about ``violation of trust obligations'' even if the exact words differ. Vector stores power this semantic search by encoding documents as high-dimensional embeddings. The technology enables perception into large knowledge bases that would be impractical to load into context.

Prior work product becomes accessible through memory. When starting a new registration statement, the agent can perceive prior S-1 filings, SEC comment histories, and successful disclosure language. This institutional knowledge informs current work.

Memory-as-perception distinguishes experienced agents from novices. The junior associate reasons from first principles; the senior associate draws on pattern recognition from hundreds of matters. Memory gives agents access to accumulated experience.

% ----------------------------------------------------------------------------
% Domain-Specific Perception Requirements
% ----------------------------------------------------------------------------

\subsection{Domain-Specific Perception Requirements}
\label{sec:agents2-perception-domain}

Perception for regulated professional services requires specialized enhancements across three dimensions: authority tracking, jurisdictional awareness, and confidentiality boundaries.

\paragraph{Authority and Provenance}

Not all information is equally authoritative. Perception systems must track provenance to ensure reliable results. Authority weighting ensures that primary authority such as statutes and binding precedent ranks higher than secondary sources. When searching for ``insider trading liability,'' a Supreme Court opinion should outrank a law review note that uses more similar language. Source verification confirms that retrieved information actually came from claimed sources rather than being hallucinated. Perception tools must return verifiable sources that can be independently checked. Currency validation ensures authority is still good law through citator integration that verifies retrieved cases haven't been overruled.

\paragraph{Jurisdiction and Scope}

Legal and regulatory information is bounded by jurisdiction. California precedent doesn't bind Texas courts; SEC rules differ from CFTC rules. Perception must respect jurisdictional boundaries and filter appropriately. Temporal validity also matters because law changes over time. Perception systems must track effective dates, and financial temporal validity varies by context: milliseconds for trading prices, quarters for compliance effective dates. Identifier resolution handles the fact that citations appear in multiple formats (``123 F.3d 456'' and ``123 F3d 456'' are the same case). Financial identifiers proliferate, including ticker symbols, CUSIP numbers, ISIN codes, and Legal Entity Identifiers. Perception must normalize identifiers to enable consistent retrieval.

\paragraph{Matter and Client Isolation}

Most critically, perception must respect confidentiality boundaries. An agent working on Matter A cannot perceive documents from adverse Matter B; ethical walls must be enforced at the perception layer. In financial contexts, an agent advising Client X cannot perceive material non-public information from Client Y's engagement. Every perception must be logged, capturing what was accessed, by which agent, and for which matter. This enables compliance review and breach detection. See \Cref{sec:agents2-memory} for detailed treatment of isolation requirements in memory systems.

% ----------------------------------------------------------------------------
% Tool Design Principles for Perception
% ----------------------------------------------------------------------------

\subsection{Tool Design Principles}
\label{sec:agents2-perception-design}

Good perception tools follow design principles that enable reliable operation:

\paragraph{Single Responsibility}

Each tool should do one thing well. A poorly designed tool bundles multiple functions---searching Westlaw, formatting citations, validating authority, and extracting holdings all in one interface. The untyped return value obscures what callers can expect:

\begin{listingbox}[title={Poor Design: Bundled Functions, Untyped Returns}, listing options={language=Python}]
def legal_research(query: str, format: bool,
                   validate: bool, extract: bool) -> dict:
    """Returns... something. Good luck."""
    ...
\end{listingbox}

When it fails, you can't tell which step failed. A better approach separates tools by function with typed returns, so the agent composes them and failures are isolated:

\begin{listingbox}[title={Better Design: Single Responsibility, Typed Returns}, listing options={language=Python}]
def search_cases(query: str, jurisdiction: str) -> list[Citation]:
    """Returns matching citations from case law database."""

def retrieve_case(citation: Citation) -> CaseText:
    """Fetches full text for a specific citation."""

def shepardize(citation: Citation) -> CitatorResult:
    """Checks validity: good law, distinguished, overruled."""

def format_citation(case: CaseText, style: str) -> str:
    """Converts to Bluebook, ALWD, or other format."""
\end{listingbox}

\paragraph{Graceful Failure}

When things go wrong---and in production, things always go wrong---tools should return informative errors. A poor approach raises generic exceptions that tell you nothing:

\begin{listingbox}[title={Poor: Opaque Exception}, listing options={language=Python}]
def retrieve_case(citation: str) -> dict:
    result = db.query(citation)
    return result["text"]  # raises KeyError if not found
\end{listingbox}

A better approach uses typed result objects that make success and failure explicit:

\begin{listingbox}[title={Better: Typed Result with Structured Errors}, listing options={language=Python}]
class CaseNotFoundError(BaseModel):
    citation: str
    reason: str
    suggestions: list[str]

def retrieve_case(citation: Citation) -> CaseText | CaseNotFoundError:
    """Returns case text or structured error with recovery options."""
    if not (result := db.query(citation)):
        return CaseNotFoundError(
            citation=str(citation),
            reason="Case may not be in database",
            suggestions=["Check citation format", "Try alternative reporter"]
        )
    return CaseText(...)
\end{listingbox}

In legal work, graceful failure is how you avoid malpractice: when you cannot find authority, report that explicitly rather than proceeding silently.

\paragraph{Least Privilege and Rate Limiting}

Perception tools should request only the permissions they need. A legal research tool needs read access to case databases, not write access to the document management system. If a compromised agent gains perception credentials, damage is limited to what those credentials allow. Rate limiting addresses a common failure mode: agents can get stuck in perception loops, searching repeatedly without progress. Tools should track invocation frequency and refuse requests beyond reasonable thresholds. If the agent has searched five times with no results, it should stop and escalate instead of looping indefinitely.

% ----------------------------------------------------------------------------
% Evaluating Perception Capabilities
% ----------------------------------------------------------------------------

\subsection{Evaluating Perception Capabilities}
\label{sec:agents2-perception-eval}

When evaluating agentic systems, assess perception against several criteria that matter for professional practice.

Coverage determines which sources the agent can access. A litigation agent that queries Westlaw but not state-specific databases has incomplete coverage. Map available perception tools against information needs to identify gaps that could limit the agent's effectiveness.

Retrieval quality measures whether the agent finds relevant information. Test with known-good queries where you know what should be retrieved, and measure both precision (relevance of results) and recall (completeness of relevant results).

Authority and provenance verification confirms that the system distinguishes authoritative from secondary sources, that you can trace retrieved information to its source, and that citations are independently verifiable.

Access controls ensure that permissions are appropriate, that the agent can access only what it should, and that confidentiality boundaries are enforced across matter and client lines. Failure handling reveals how the agent behaves when perception fails: whether it retries, tries alternatives, or escalates appropriately rather than crashing or proceeding with incomplete information.

Audit capability confirms that every perception is logged and that you can reconstruct what information the agent accessed during a task for compliance review and post-hoc analysis.

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Perception to Action}
\label{sec:agents2-perception-action}

Perception enables agents to gather information, but agents must also be able to effect change: file documents, send communications, execute trades. The critical distinction is simple but important.

Perception tools are read-only. They observe without changing the world. If a perception tool fails or returns wrong results, no external state has changed; you can retry or try alternatives. Action tools, in contrast, change state. They file documents, send emails, and execute trades. Once executed, some actions cannot be undone. The risks are different, and the governance must be different as well. \Cref{sec:agents2-action} examines action capabilities in detail.

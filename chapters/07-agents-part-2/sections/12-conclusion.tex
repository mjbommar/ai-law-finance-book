% ============================================================================
% 12-conclusion.tex
% Conclusion: From Architecture to Governance
% Part of: Chapter 07 - Agents Part II: How to Design an Agent
% ============================================================================

\section{Conclusion}
\label{sec:agents2-conclusion}

% ----------------------------------------------------------------------------
% Opening
% ----------------------------------------------------------------------------

This chapter opened with a claim: \textbf{agents are not magic; they are architecture}. Eleven sections later, that claim should feel concrete. The ten-question framework from \Cref{sec:agents2-ten-questions} has provided the spine for understanding how agents receive work, understand intent, gather information, take action, maintain context, plan, terminate, escalate, coordinate, and operate under governance.

You now know how work reaches an agent (triggers), how instructions become goals (intent), how agents gather information (perception) and take action (action), how context persists (memory), how complex work decomposes (planning), how agents recognize completion (termination), when they hand off to humans (escalation), how they coordinate (delegation), and what controls keep them safe (governance).

Each capability involves tradeoffs. Richer memory improves context but increases latency. Aggressive escalation improves safety but reduces autonomy. Tighter approval gates reduce risk but slow execution. There are no free lunches, only choices that must be calibrated to your context, risk tolerance, and professional obligations. Additional resources, including protocol specifications, regulatory guidance links, and research references, are available on the book's companion website. \href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}} provides a risk-based calibration approach rather than a one-size-fits-all checklist.

The organizational analogy is not merely pedagogical. Law firms and investment teams are cognitive work systems that have evolved infrastructure for exactly these challenges: distributing work, maintaining context, and ensuring quality. When you evaluate an agentic system, ask the same questions you would ask about a professional team.

% ----------------------------------------------------------------------------
% What You Can Now Do
% ----------------------------------------------------------------------------

\subsection{What This Understanding Enables}
\label{sec:agents2-conclusion-enables}

With architectural literacy, you can evaluate vendor claims. When a vendor says their agent ``handles legal research,'' ask: What triggers it (\Cref{sec:agents2-triggers})? How does it understand the question (\Cref{sec:agents2-intent})? What databases does it access (\Cref{sec:agents2-perception})? How does it know when it is done (\Cref{sec:agents2-termination})? What happens when confidence is low (\Cref{sec:agents2-escalation})? The ten questions from \Cref{sec:agents2-ten-questions} provide your evaluation framework.

You can participate meaningfully in procurement. Assess whether a system meets requirements: Does it enforce matter isolation? Maintain audit trails? Integrate with approval workflows? Escalate appropriately? You have the vocabulary to specify requirements.

You can demand governance artifacts, not promises. Ask vendors to demonstrate action gating, escalation behavior under low confidence, and reconstruction via logs. If a system cannot show you what it accessed, what it did, and why it stopped, it is not deployable in regulated practice.

You can design governance that maps to architecture. Governance is enabled by architecture. If you want audit trails, the system must log reasoning. If you want approval gates, the system must pause before action. If you want confidentiality, the system must isolate context. You can design systems where governance is built in, not bolted on.

Finally, you can communicate with technical teams. Describe requirements precisely: ``I need perception tools for these databases, action tools behind approval gates, escalation triggers for low confidence, and memory isolation between matters.'' Shared vocabulary enables collaboration.

% ----------------------------------------------------------------------------
% Evaluation Checklist
% ----------------------------------------------------------------------------

\subsection{Evaluation Checklist}
\label{sec:agents2-evaluation-checklist}

Table~\ref{tab:agents2-eval-checklist} consolidates evaluation criteria across all ten architectural questions. Use this checklist when assessing vendor systems, designing your own, or conducting due diligence on agentic deployments.

\begin{table}[htbp]
\centering
\caption{Evaluation checklist by architectural component}
\label{tab:agents2-eval-checklist}
\small
\begin{tabular}{ll}
\toprule
\textbf{Component} & \textbf{Key Topics} \\
\midrule
Triggers & Source coverage; latency; failure detection; audit logging \\
Intent & Ambiguity detection; constraint validation; clarification requests \\
Perception & Data source access; access controls; provenance; jurisdictional filtering \\
Action & Approval gates; reversibility classification; circuit breakers \\
Memory & Matter/client isolation; retention policies; state reconstruction; ethical walls \\
Planning & Budget enforcement; pattern selection; plan validation \\
Termination & Success criteria; failure recognition; graceful degradation \\
Escalation & Confidence thresholds; handoff context; routing accuracy \\
Delegation & Agent identity; delegation contracts; cross-agent ethical walls \\
Governance & Logging infrastructure; override mechanisms; state snapshots; least privilege \\
\bottomrule
\end{tabular}
\end{table}

% ----------------------------------------------------------------------------
% Current Limitations
% ----------------------------------------------------------------------------

\subsection{Honest Assessment of Current Capabilities}
\label{sec:agents2-conclusion-limitations}

Architectural understanding requires honest acknowledgment of current limitations.

\textbf{The reliability cliff} (\Cref{sec:agents2-reliability}) remains a significant constraint. Success rates tend to degrade as task complexity and duration increase. Systems that decompose work into smaller steps and checkpoint progress frequently tend to perform more reliably.

\textbf{Judgment limitations} constrain where agents add value. Current models perform better at retrieval and pattern matching than at tasks requiring nuance or handling novel situations. Effective deployments tend to pair agent capabilities with human judgment rather than replacing it entirely.

\textbf{Brittleness} can cause unexpected failures when APIs change or edge cases arise. Monitoring and graceful degradation help mitigate these risks.

\textbf{Compounding errors} affect multi-step workflows. When each step has some probability of error, longer autonomous chains become less reliable. Shorter workflows with human checkpoints often perform better in practice.

% ----------------------------------------------------------------------------
% Closing: The Core Insight Revisited
% ----------------------------------------------------------------------------

\subsection{The Core Insight Revisited}
\label{sec:agents2-conclusion-bridge}

The ten questions framework demystifies agentic systems by mapping them to something you already understand: how professional teams work. Law firms and investment teams are cognitive work systems that receive work through defined channels, interpret ambiguous instructions, gather information from specialized sources, take consequential actions under constraints, maintain institutional memory, decompose complex problems, recognize completion, escalate appropriately, coordinate across specialists, and operate within compliance frameworks. Agentic systems face the same challenges and require the same structural capabilities.

That mapping is the source of your architectural literacy. When evaluating a vendor's agent, you do not need to understand transformer architectures or embedding spaces. You need to ask the questions you would ask about a new team member: How does work reach them? Can they access the right databases? What happens when they are uncertain? Who reviews their output before it goes to clients? The ten questions give you a framework for asking---and a vocabulary for specifying what you need.

Architectural literacy also enables governance. You cannot audit what is not logged, enforce boundaries without isolation, or intervene without override mechanisms. These are not afterthoughts; they are design decisions that must be made at architecture time. The governance surface---the interface through which controls interact with agents---is determined by architectural choices. \href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}}, the next chapter in this series, provides frameworks for calibrating those controls to your specific context, risk tolerance, and professional obligations. But you can only engage with governance frameworks meaningfully if you understand the architecture they govern.

Agents are not magic. They are triggers, intent extraction, perception tools, action controls, memory systems, planning mechanisms, termination conditions, escalation protocols, delegation patterns, and governance surfaces. They are architecture. And architecture, once understood, can be evaluated, specified, deployed, and governed.

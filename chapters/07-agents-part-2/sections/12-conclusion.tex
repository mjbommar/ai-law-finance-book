% ============================================================================
% 12-conclusion.tex
% Conclusion: From Architecture to Governance
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{Conclusion: From Architecture to Governance}
\label{sec:agents2-conclusion}

% ----------------------------------------------------------------------------
% Opening
% ----------------------------------------------------------------------------

This chapter opened with a claim: \textbf{agents are not magic; they are architecture}. Ten sections later, that claim should feel concrete. The ten-question framework from \Cref{sec:agents2-ten-questions} has provided the spine for understanding how agents receive work, understand intent, gather information, take action, maintain context, plan, terminate, escalate, coordinate, and operate under governance.

You now know how work reaches an agent (triggers), how instructions become goals (intent), how agents gather information (perception) and take action (action), how context persists (memory), how complex work decomposes (planning), how agents recognize completion (termination), when they hand off to humans (escalation), how they coordinate (delegation), and what controls keep them safe (governance).

Each capability involves tradeoffs. Richer memory improves context but increases latency. Aggressive escalation improves safety but reduces autonomy. Tighter approval gates reduce risk but slow execution. There are no free lunches, only choices that must be calibrated to your context, risk tolerance, and professional obligations. Additional resources, including protocol specifications, regulatory guidance links, and research references, are available on the book's companion website. Chapter~8 (Agents Part III: Governing Agents) provides a risk-based calibration approach rather than a one-size-fits-all checklist.

The organizational analogy is not merely pedagogical. Law firms and investment teams are cognitive work systems that have evolved infrastructure for exactly these challenges: distributing work, maintaining context, and ensuring quality. When you evaluate an agentic system, ask the same questions you would ask about a professional team.

% ----------------------------------------------------------------------------
% What You Can Now Do
% ----------------------------------------------------------------------------

\subsection{What This Understanding Enables}
\label{sec:agents2-conclusion-enables}

With architectural literacy, you can evaluate vendor claims. When a vendor says their agent ``handles legal research,'' ask: What triggers it (\Cref{sec:agents2-triggers})? How does it understand the question (\Cref{sec:agents2-intent})? What databases does it access (\Cref{sec:agents2-perception})? How does it know when it is done (\Cref{sec:agents2-termination})? What happens when confidence is low (\Cref{sec:agents2-escalation})? The ten questions from \Cref{sec:agents2-ten-questions} provide your evaluation framework.

You can participate meaningfully in procurement. Assess whether a system meets requirements: Does it enforce matter isolation? Maintain audit trails? Integrate with approval workflows? Escalate appropriately? You have the vocabulary to specify requirements.

You can demand governance artifacts, not promises. Ask vendors to demonstrate action gating, escalation behavior under low confidence, and reconstruction via logs. If a system cannot show you what it accessed, what it did, and why it stopped, it is not deployable in regulated practice.

You can design governance that maps to architecture. Governance is enabled by architecture. If you want audit trails, the system must log reasoning. If you want approval gates, the system must pause before action. If you want confidentiality, the system must isolate context. You can design systems where governance is built in, not bolted on.

Finally, you can communicate with technical teams. Describe requirements precisely: ``I need perception tools for these databases, action tools behind approval gates, escalation triggers for low confidence, and memory isolation between matters.'' Shared vocabulary enables collaboration.

% ----------------------------------------------------------------------------
% Evaluation Checklist
% ----------------------------------------------------------------------------

\subsection{Evaluation Checklist}
\label{sec:agents2-evaluation-checklist}

Table~\ref{tab:agents2-eval-checklist} consolidates evaluation criteria across all ten architectural questions. Use this checklist when assessing vendor systems, designing your own, or conducting due diligence on agentic deployments.

\begin{table}[htbp]
\centering
\caption{Evaluation checklist by architectural component}
\label{tab:agents2-eval-checklist}
\small
\begin{tabular}{ll}
\toprule
\textbf{Component} & \textbf{Key Topics} \\
\midrule
Triggers & Source coverage; latency; failure detection; audit logging \\
Intent & Ambiguity detection; constraint validation; clarification requests \\
Perception & Data source access; access controls; provenance; jurisdictional filtering \\
Action & Approval gates; reversibility classification; circuit breakers \\
Memory & Matter/client isolation; retention policies; state reconstruction; ethical walls \\
Planning & Budget enforcement; pattern selection; plan validation \\
Termination & Success criteria; failure recognition; graceful degradation \\
Escalation & Confidence thresholds; handoff context; routing accuracy \\
Delegation & Agent identity; delegation contracts; cross-agent ethical walls \\
Governance & Logging infrastructure; override mechanisms; state snapshots; least privilege \\
\bottomrule
\end{tabular}
\end{table}

% ----------------------------------------------------------------------------
% Current Limitations
% ----------------------------------------------------------------------------

\subsection{Honest Assessment of Current Capabilities}
\label{sec:agents2-conclusion-limitations}

Architectural understanding requires honest acknowledgment of limitations.

\textbf{The reliability cliff} (\Cref{sec:agents2-reliability}) is the most significant constraint. Agents exhibit near-perfect success on short tasks but fail frequently on multi-hour workflows. Design systems that decompose work aggressively and checkpoint progress frequently.

\textbf{Judgment limitations} constrain value. Agents excel at retrieval and pattern matching but struggle with nuance and novelty. The effective deployments pair agent capabilities with human judgment.

\textbf{Brittleness} causes failures due to API changes or edge cases. Build monitoring and graceful degradation into every deployment.

\textbf{Compounding errors} affect multi-step workflows. Error probabilities multiply, so long autonomous chains fail. Shorter workflows with human checkpoints perform better.

% ----------------------------------------------------------------------------
% Bridge to Next Chapter
% ----------------------------------------------------------------------------

\subsection{From Architecture to Governance}
\label{sec:agents2-conclusion-bridge}

This chapter answered: \textit{How do you build an agent?}
The next chapter answers: \textit{How do you govern one?}

As \Cref{sec:agents2-governance} demonstrated, five architectural patterns enable governance: logging across all components, override and circuit breaker mechanisms, state snapshots and checkpoints, least privilege enforcement, and escalation hooks. These patterns form the \textit{governance surface}---the interface through which governance systems interact with agents. If you did not architect for logging, you cannot audit; if you did not architect for isolation, you cannot enforce boundaries; if you did not architect for override, you cannot intervene.

The governance imperative is that agents are not just tools. They interpret goals, select what to perceive, and take actions that can create liability. That shift introduces predictable accountability problems: purpose drift (misaligned goals), perceptual opacity (bad or manipulated inputs), and actuation risk (high-consequence actions). \href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}} provides dimensional calibration for matching controls to risk and presents a five-layer framework that translates these challenges into concrete controls: calibrated autonomy, input and action constraints, auditability, retention, escalation and override mechanisms, and accountability structures.

With the architectural literacy developed in this chapter, you can engage meaningfully with the governance frameworks that follow---specifying requirements precisely, evaluating vendor claims critically, and ensuring that controls are built into systems from the start rather than retrofitted after deployment. Agents are not magic; they are architecture. And architecture, once understood, can be governed.

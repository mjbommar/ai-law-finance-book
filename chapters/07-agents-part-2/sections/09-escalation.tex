% ============================================================================
% 09-escalation.tex
% Q8: How Does an Agent Know When to Ask for Help?
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{How Does an Agent Know When to Ask for Help?}
\label{sec:agents2-escalation}

% ----------------------------------------------------------------------------
% Opening: Q8 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

Sometimes the best thing to know is when you do not know something. A wise junior associates knows when to consult their supervising partner.  In turn, a deputy corporate counsel can intuit that an issue should be escalated to someone more senior within the organization.  Of course, it is a balancing act whereby it is unwise to interrupt the partner or senior lawyer with every question, but they also do not proceed confidently into territory beyond their expertise. In a sense, the most intelligent junior resources recognize authority boundaries: ``I can draft this motion, but I need partner review before filing.'' They recognize competence limits: ``I have researched for two hours and cannot find clear authority---I should ask someone with more experience.'' They recognize high-stakes situations: ``The client is asking about strategy, not just research---this needs partner involvement.''

Agentic systems require the same judgment. An agent that never escalates will eventually exceed its competence, authority, or the bounds of safe autonomous operation. An agent that escalates everything provides no value: it becomes a complicated way to route work to humans. The challenge is drawing the line.

\begin{definitionbox}[title={Escalation}]
	\keyterm{Escalation} transfers control from the agent to a human when autonomous execution should stop. Unlike termination, which ends the task (success or failure), escalation pauses the task and requests human input before continuing.

	This reflects professionalism, not failure. Recognizing when you need help and asking for it is exactly what we expect from junior professionals. Agents should do the same.
\end{definitionbox}

% ----------------------------------------------------------------------------
% When to Escalate: Decision Framework
% ----------------------------------------------------------------------------

\subsection{When to Escalate}
\label{sec:agents2-when-escalate}

Three categories of triggers warrant escalation, each reflecting a different reason why autonomous action should pause \parencite{mosqueira-rey2023hitl,gomez2025taxonomy}.

\textbf{Mandatory triggers} require human involvement regardless of the agent's confidence or the apparent simplicity of the decision. Some situations demand human judgment by their nature, not because the agent is uncertain. When resource limits approach exhaustion, the agent should escalate with a progress summary rather than stopping silently---the human needs to decide whether to allocate additional resources or accept partial results. High-stakes actions like court filings, client communications, and large trades require human approval before execution; these are \textit{approval gates} where the agent prepares but does not act. Actions that would exceed the agent's authorized thresholds---a trade above a certain size, a commitment beyond a certain value---require human sign-off even if the agent is confident the action is correct. And irreversible actions warrant particular caution: once a motion is filed or a trade is executed, the consequences cannot be undone, making pre-execution review essential.

\textbf{Confidence-based triggers} occur when the agent's uncertainty exceeds acceptable thresholds for autonomous action \parencite{madras2018defer,abbasiyadkori2024conformal}. An agent researching a legal question might find genuinely conflicting circuit authority and be unable to determine which rule applies---``I found three circuits supporting one approach and two supporting another, and I cannot determine which controls here.'' Data sources might disagree in ways the agent cannot reconcile: the revenue figure in the 10-K differs from the earnings release, and the agent cannot determine which is correct or whether both are valid in different contexts. Novel situations---unprecedented fact patterns, unusual market conditions, first-impression legal questions---push beyond the agent's training distribution, where its confidence estimates become unreliable. And sometimes ambiguity persists despite the agent's attempts to clarify: the instructions can be read multiple ways, and the agent remains uncertain which interpretation the human intended.

\textbf{Error and anomaly detection} triggers escalation when the agent encounters problems it cannot resolve through retrying or alternative approaches. Repeated failures---a database that times out on three consecutive attempts, an API that returns errors despite varied request formats---indicate systemic problems that further attempts will not solve. Data anomalies, such as financial figures that do not reconcile or filing dates that seem implausible, warrant human investigation rather than silent acceptance or rejection. Constraint violations require immediate escalation: if executing a planned action would breach position limits, exceed authorization thresholds, or violate compliance rules, the agent must stop and confirm rather than proceed. And when a task proves genuinely impossible---requirements conflict, necessary data does not exist, or the goal cannot be achieved as specified---the agent should report this finding rather than struggling indefinitely.

% ----------------------------------------------------------------------------
% How to Escalate: Information Handoff
% ----------------------------------------------------------------------------

\subsection{How to Escalate}
\label{sec:agents2-how-escalate}

Effective escalation provides the human with everything needed to make a decision without starting from scratch. The difference between good and poor escalation is the difference between receiving a well-organized file from a colleague and inheriting an unexplained mess.

A complete handoff weaves together five elements: a \textbf{situation summary} that orients the human quickly; a \textbf{progress report} explaining what has been done and what remains; a \textbf{trigger explanation} clarifying why the agent is escalating \textit{now}; the \textbf{gathered information} presenting relevant findings even if partial; and a \textbf{recommendation} proposing a path forward with supporting reasoning.

Consider a legal research agent investigating the statute of limitations for a Section 10(b) securities fraud claim. After searching Westlaw and Lexis, it finds clear authority on the two-year discovery period but conflicting circuit authority on the trigger event---the Ninth and Second Circuits apply different tests for inquiry notice. The agent cannot determine which test applies to the client's facts. Rather than guessing, it escalates with a summary of the key cases, explains the circuit split, and recommends seeking partner guidance because the question is fact-intensive and requires judgment beyond the agent's competence.

A financial agent faces a different escalation pattern. After generating a trade list to reduce tech exposure from 35\% to 25\%, the agent completes its compliance check and is ready to execute---but the \$500K trade size exceeds the single-approver threshold. The agent escalates with the tax implications (\$45K in short-term gains, \$12K in losses, \$8K net liability), presents options (approve the full list, prioritize tax-loss positions, or execute in tranches), and notes which option serves which priority. The human can approve immediately rather than reconstructing the analysis.

% ----------------------------------------------------------------------------
% Human-in-the-Loop Patterns
% ----------------------------------------------------------------------------

\subsection{Human-in-the-Loop Patterns}
\label{sec:agents2-hitl}

Different tasks and risk profiles call for different patterns of human integration. Five patterns span the spectrum from tight oversight to broad autonomy, and selecting the right pattern is itself a design decision with significant consequences.

\textbf{Approval gates} enforce the strictest oversight by separating preparation from authorization. The agent performs all the work---drafting the motion, assembling the trade list, preparing the client communication---but stops short of execution. A human reviews the prepared output and explicitly authorizes the final action. This pattern is essential for irreversible actions where errors cannot be corrected after the fact: court filings, executed trades, sent communications. The cost is latency and human attention; the benefit is a hard guarantee that no consequential action occurs without human review.

\textbf{Checkpoint reviews} insert human validation at natural milestones within a longer workflow. A research agent might present its initial findings and proposed authorities before beginning to draft a memorandum. A due diligence agent might summarize its document review before moving to the analysis phase. These checkpoints prevent the agent from investing significant effort in a direction the human would have redirected, catching misunderstandings early when course correction is cheap.

\textbf{Confidence-based escalation} ties the level of autonomy to the agent's certainty about its outputs. When confidence is high---the answer is clear, the authorities are consistent, the data is unambiguous---the agent proceeds autonomously. When confidence drops below a threshold, the agent escalates rather than acting on uncertain conclusions. This pattern allows routine cases to flow without human intervention while ensuring that difficult cases receive appropriate attention. The challenge lies in calibrating both the thresholds and the agent's confidence estimates.

\textbf{Human-as-tool} inverts the traditional oversight relationship by treating human expertise as a resource the agent can invoke when needed. Rather than escalating and transferring control, the agent poses a specific question to a human expert, receives the answer, incorporates it into its reasoning, and continues. This pattern works well when the agent needs discrete pieces of human judgment---``Is this clause acceptable under our firm's standards?''---without requiring the human to take over the entire task.

\textbf{Reversibility classification} matches oversight intensity to the stakes of each action. Fully reversible actions---internal drafts, exploratory searches, preliminary analyses---can proceed autonomously because errors can be corrected without consequence. Partially reversible actions warrant checkpoint review. Irreversible actions require approval gates. This framework provides a principled basis for deciding which pattern to apply, grounded in the practical question of what happens if the agent gets it wrong.

\input{figures/fig-oversight-spectrum}

% ----------------------------------------------------------------------------
% Domain-Specific Escalation
% ----------------------------------------------------------------------------

\subsection{Domain-Specific Escalation Requirements}
\label{sec:agents2-escalation-domain}

Beyond general principles, regulated industries impose specific escalation duties grounded in professional responsibility rules and compliance requirements. These are not optional design choices but mandatory constraints that any deployed system must respect.

\paragraph{Legal Practice}

Professional responsibility rules create binding escalation requirements for legal agents \parencite{aba-model-rule-1-1,aba-formal-opinion-512}. The duty of \textit{competence} under ABA Model Rule 1.1 requires escalation whenever a matter exceeds the agent's training or capabilities---an agent cannot simply do its best on an unfamiliar issue but must recognize its limits and involve qualified counsel. \textit{Privilege protection} demands escalation before any action that might expose attorney-client communications or work product; the consequences of inadvertent disclosure are severe enough that uncertainty should trigger human review. Potential \textit{conflicts of interest}---whether between current clients, with former clients, or arising from the firm's other relationships---must be escalated to counsel for proper conflicts analysis rather than resolved by the agent. And the duty of \textit{candor to the tribunal} requires immediate escalation if the agent discovers adverse authority that may require disclosure; this is not a situation where the agent should exercise judgment about materiality.

\paragraph{Financial Services}

Regulatory obligations and fiduciary duties impose parallel requirements on financial agents \parencite{finra-notice-24-09,fed-sr11-7}. \textit{Suitability} obligations require that investment recommendations receive human adviser review before reaching clients, ensuring that a qualified professional has assessed whether the recommendation fits the client's circumstances. Trades approaching \textit{regulatory thresholds}---beneficial ownership reporting triggers, large trader identification requirements, position limits---must be escalated so that compliance personnel can ensure proper filings and approvals. Any encounter with potential \textit{Material Non-Public Information} demands immediate escalation; the agent cannot assess whether information is material or non-public with sufficient reliability, and the consequences of trading on MNPI are catastrophic. And actions that would breach \textit{risk limits}---position concentrations, exposure thresholds, leverage constraints---require escalation for explicit authorization rather than autonomous execution.

% ----------------------------------------------------------------------------
% Evaluating Escalation
% ----------------------------------------------------------------------------

\subsection{Evaluating Escalation Mechanisms}
\label{sec:agents2-escalation-eval}

Escalation evaluation requires six assessments: \textit{coverage} (do all situations that should trigger escalation actually do so?), \textit{calibration} (are thresholds set to balance false positives against missed escalations?), \textit{latency} (does escalation reach humans quickly enough for time-sensitive matters?), \textit{routing} (does it reach the right person with relevant expertise?), \textit{context quality} (can the human decide based on the message alone?), and \textit{response handling} (does the agent correctly incorporate human guidance?). See the consolidated Evaluation Checklist in \Cref{sec:agents2-evaluation-checklist}.

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Escalation to Delegation}
\label{sec:agents2-escalation-delegation}

Escalation moves control \textit{upward} in the hierarchy---from agent to human supervisor, from junior to senior, from execution to oversight. But agents can also move control \textit{sideways} by delegating tasks to peer agents with different capabilities. These horizontal relationships introduce coordination challenges distinct from the vertical relationships of escalation.

\Cref{sec:agents2-delegation} examines this dimension of agent architecture: how does an agent work with other agents? A coordinating agent might delegate research to a specialist with access to legal databases, drafting to a specialist trained on firm precedents, and financial modeling to a specialist with quantitative capabilities. Each specialist retains its own ability to escalate vertically when it encounters situations requiring human judgment, creating a two-dimensional topology where control flows both upward to humans and sideways to specialists. Understanding both dimensions---escalation and delegation---is essential for designing systems that can handle complex professional workflows while maintaining appropriate human oversight throughout.

% ============================================================================
% 08-termination.tex
% Q7: How Does an Agent Know When It's Done?
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{How Does an Agent Know When It's Done?}
\label{sec:agents2-termination}

% ----------------------------------------------------------------------------
% Opening: Q7 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

Every professional learns to recognize completion. The research memo is done when you have found sufficient authority and synthesized it. The due diligence is done when you have reviewed all material documents. The trade is done when the order executes and settles. Knowing when work is complete distinguishes effective professionals from those who over-research or under-deliver.

Agents face the same challenge. Without explicit termination conditions, agents can run indefinitely: searching one more database, trying one more approach, refining one more time. We call this the ``runaway associate'' problem: you ask for two relevant cases, and the associate gives you fifty because they did not know when to stop.

\begin{definitionbox}[title={Termination}]
\keyterm{Termination} conditions define when an agent should stop executing. Three outcomes are possible:
\begin{itemize}[nosep]
    \item \textbf{Success:} The goal is achieved, and the agent delivers the result.
    \item \textbf{Failure:} The goal cannot be achieved; the agent reports why and stops.
    \item \textbf{Escalation:} The agent cannot determine success or failure, transferring the decision to human judgment.
\end{itemize}

Termination implements the ``T'' in the GPA+IAT framework. Without it, agentic systems lack the property that distinguishes systems from runaway processes.
\end{definitionbox}

% ----------------------------------------------------------------------------
% Termination Condition Categories
% ----------------------------------------------------------------------------

\subsection{Termination Condition Categories}
\label{sec:agents2-termination-categories}

Five categories of termination conditions bound agent execution: success conditions, resource budgets, confidence thresholds, error conditions, and escalation triggers.

\textbf{Success conditions} trigger when the goal is achieved.
\begin{itemize}[nosep]
    \item \textbf{Completeness:} Have all checklist items been addressed? (e.g., all 50 contracts reviewed).
    \item \textbf{Quality:} Is the output sufficient? (e.g., conclusions supported by binding authority). This often requires human validation.
    \item \textbf{Convergence:} Has the agent stopped learning? If three consecutive searches yield no new authority, the research is likely saturated.
\end{itemize}

\textbf{Resource budgets} provide hard limits to prevent runaway execution. \Cref{sec:agents2-budgets} details budget architecture; here we focus on termination.
\begin{itemize}[nosep]
    \item \textbf{Token budgets:} Stop after 50,000 tokens to prevent expensive reasoning loops.
    \item \textbf{Time budgets:} Enforce deadlines (e.g., stop after 10 minutes).
    \item \textbf{Iteration budgets:} Cap tool calls (e.g., max 20 searches).
    \item \textbf{Cost budgets:} Halt after spending a fixed dollar amount.
\end{itemize}
Budgets cascade. A task might hit a time limit before exhausting tokens. Budget exhaustion is not necessarily failure; partial results are often valuable.

\textbf{Confidence thresholds} gate actions on certainty. When confidence is high, the agent delivers the answer. When confidence drops below a threshold (e.g., 80\%), the agent stops and escalates. This mirrors associate behavior: ``I'm not confident. Let me ask the partner.'' Calibrating these thresholds is challenging \parencite{kadavath2022calibration}. Agents can be overconfident. Effective calibration requires testing against known outcomes.

\textbf{Error conditions} require agents to recognize failure modes.
\begin{itemize}[nosep]
    \item \textbf{Repeated failures:} If Westlaw times out three times, stop rather than retrying indefinitely.
    \item \textbf{Inconsistent data:} If the 10-K revenue differs from the earnings release, stop and flag for human review.
    \item \textbf{Constraint violations:} If a planned action exceeds position limits, stop immediately.
    \item \textbf{Impossibility:} If requirements conflict, report the impossibility rather than compromising.
\end{itemize}

\textbf{Escalation triggers} require human judgment regardless of success or failure. Novel situations, high-stakes decisions, and actions exceeding authority boundaries must trigger termination and handoff. \Cref{sec:agents2-escalation} examines these patterns.

% ----------------------------------------------------------------------------
% Explicit Success Criteria
% ----------------------------------------------------------------------------

\subsection{Defining Success Criteria}
\label{sec:agents2-success-criteria}

Vague goals produce unclear termination. ``Research the statute of limitations'' is ambiguous. Effective success criteria provide clear signals.

\textbf{Completeness checklists} enumerate deliverables. For a credit agreement review, the checklist requires identifying financial covenants, comparing them to market terms, and summarizing risks. The agent terminates only when all items are complete.

\textbf{Sufficiency thresholds} define ``enough.'' For case research, sufficiency might mean finding three on-point circuit opinions. The agent stops upon reaching this count, without searching every database.

\textbf{Convergence criteria} recognize diminishing returns. If consecutive searches yield no new results, the task is likely done.

\textbf{Deliverable specifications} define output format. ``A two-page memo with executive summary'' tells the agent exactly what success looks like.

Instruct agents as you would an associate: ``If you find clear Ninth Circuit authority, you are done. If circuits split, map the split. If you find nothing after two hours, stop.''

% ----------------------------------------------------------------------------
% Failure Recognition
% ----------------------------------------------------------------------------

\subsection{Recognizing Failure}
\label{sec:agents2-failure-recognition}

Agents must recognize and report failure honestly. Negative results are valuable information. ``I searched all databases and found no authority'' is a valid finding.

\textbf{Diagnostic reporting} explains the failure. Instead of ``Task failed,'' the agent should report: ``I searched Westlaw and Lexis using [queries]. Zero results suggest the issue is novel or terms are wrong. Recommend manual review.'' This is actionable.

\textbf{Partial completion} must be preserved. If an agent analyzed 4 of 10 articles before failure, it should report: ``Articles 1-4 analyzed. Articles 5-10 remain.'' Preserving partial work prevents wasted effort.

\textbf{Root cause identification} aids the human response. Was it a tool failure (transient) or impossible requirements (structural)? The agent's diagnosis informs the next step.

% ----------------------------------------------------------------------------
% Guardrails and Loop Detection
% ----------------------------------------------------------------------------

\subsection{Guardrails and Loop Detection}
\label{sec:agents2-loop-detection}

Agents can get stuck in unproductive loops despite termination conditions. We use three mechanisms to prevent this.

\textbf{Step limits} serve as a final backstop: after $N$ steps, stop and require approval. This prevents unbounded execution.

\textbf{Progress detection} monitors value. If the last five actions produced no new information, the agent is likely stuck. This should trigger reflection or escalation.

\textbf{Reflection steps} build self-assessment. The agent asks: ``Am I making progress? Should I change approach?''

\textbf{External watchdogs} monitor from outside. If the same tool is called repeatedly with identical parameters, the watchdog intervenes. Without loop detection, agents will eventually get stuck in production.

% ----------------------------------------------------------------------------
% The Reliability Cliff
% ----------------------------------------------------------------------------

\subsection{The Reliability Cliff}
\label{sec:agents2-reliability}

Benchmarking reveals a sharp reliability boundary. METR (Model Evaluation and Threat Research) tested agents across standardized tasks.

\begin{keybox}[title={The Four-Minute Cliff}]
METR's 2025 study found that agents achieve \textbf{near-perfect success on tasks under 4 minutes}, but \textbf{under 10\% success on tasks over 4 hours} \parencite{metr-agent-capability-2025}.

\vspace{0.5em}
This gap defines the current boundary for reliable deployment. You must decompose tasks aggressively, keep agent tasks short, and insert human checkpoints. Do not expect autonomous completion of multi-hour workflows.
\end{keybox}

\input{figures/fig-reliability-cliff}

This cliff stems from \textbf{compounding errors}. A 95\% accurate step followed by a 90\% accurate step yields 85\% reliability. Over dozens of steps, failure becomes a statistical certainty. \textbf{Planning fragility} and \textbf{integration brittleness} (API failures) further degrade long-running tasks. Design for this reality: decompose, validate, and assume failure.

% ----------------------------------------------------------------------------
% Graceful Degradation
% ----------------------------------------------------------------------------

\subsection{Graceful Degradation}
\label{sec:agents2-graceful-degradation}

When termination occurs early, agents should degrade gracefully.

\textbf{Tiered outputs} provide value at any budget.
\begin{itemize}[nosep]
    \item \textbf{Low Budget:} Deliver controlling statute and citation.
    \item \textbf{Medium Budget:} Add key holdings.
    \item \textbf{Full Budget:} Deliver comprehensive analysis.
\end{itemize}
Partial results allow the user to decide if further investment is warranted.

\textbf{Progress preservation} saves state. If an agent stops mid-review, the human should be able to resume without restarting.

\textbf{Clear status reporting} is essential: ``Completed 60\% of task. Remaining: Articles 5-8. Findings so far: [summary].'' The agent should recommend next steps: ``Recommend allocating 30 more minutes to complete.'' This enables informed human decision-making.

% ----------------------------------------------------------------------------
% Evaluating Termination
% ----------------------------------------------------------------------------

\subsection{Evaluating Termination Capabilities}
\label{sec:agents2-termination-eval}

Assess termination against six criteria:
\begin{itemize}[nosep]
    \item \textbf{Success Clarity:} Are termination conditions explicit? Can you predict when it stops?
    \item \textbf{Budget Enforcement:} Does the agent actually stop at the limit?
    \item \textbf{Loop Detection:} Does it detect and break infinite loops?
    \item \textbf{Failure Reporting:} Are error messages actionable?
    \item \textbf{Graceful Degradation:} Does it return useful partial results?
    \item \textbf{Escalation Handoff:} Does the human receive sufficient context to take over?
\end{itemize}

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Termination to Escalation}
\label{sec:agents2-termination-escalation}

Termination defines when agents stop. Success means the task is done. Failure means it is impossible. Escalation means the agent needs help.

The third category is critical. An agent finding conflicting authority or exceeding authorization must stop and ask for input. This is not failure; it is safety.

\Cref{sec:agents2-escalation} examines this question: when should an agent stop autonomous operation and ask for help? Termination and escalation together define the boundaries of autonomous execution. Without them, agents run forever or exceed authority.

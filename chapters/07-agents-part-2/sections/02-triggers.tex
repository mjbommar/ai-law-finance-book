% ============================================================================
% 02-triggers.tex
% Q1: How Does an Agent Know When It Has Work to Do?
% Part of: Chapter 07 - Agents Part II: How to Design an Agent
% ============================================================================

\section{How Does an Agent Know When It Has Work to Do?}
\label{sec:agents2-triggers}

% ----------------------------------------------------------------------------
% Opening: Q1 Framing and Organizational Analogy
% ----------------------------------------------------------------------------

Consider again a day in the life of an average attorney. How does work reach their desk?  Typically, a client calls with a question, a court docket updates with a new filing, a calendar reminds them of an upcoming motion, or a junior associate knocks on their door with a question that exceeds their expertise.  Agentic systems operate in the same way. No matter how sophisticated, a system with tools, memory, and planning capabilities remains idle until work ``arrives''; the architectural question is how these triggers and channels are defined and designed.

\begin{definitionbox}[title={Triggers}]
	\keyterm{Triggers} are the events that start agent execution. In practice, a trigger might be a docket alert, a price crossing a threshold, a calendar deadline coming due, or an internal ``I can't proceed safely'' signal from the agent itself. Without a trigger, even a highly capable system sits idle.
\end{definitionbox}

The distinction between triggers and channels matters for system design. A trigger is the \textit{what}: the event that demands attention. A channel is the \textit{how}: the pathway through which that event reaches the agent. The same trigger, such as an approaching deadline, might arrive through different channels depending on context. It could come from a calendar system, an email reminder, or a human prompt asking ``what's due this week?'' Understanding this separation helps you design systems that can receive work from multiple sources while maintaining consistent processing logic.

Triggers also create the audit trail that governance depends on. Every action an agent takes traces back to the trigger that initiated it, and when a regulator asks why the system flagged a transaction, or when a court demands production of the agent's reasoning, you need to show what event started the chain of analysis. Systems that cannot trace actions back to triggers cannot be meaningfully audited, and in highly regulated fields like law and finance, what cannot be audited likely should not be deployed. We formalize this requirement as part of the logging architecture in \Cref{sec:agents2-logging-arch}.

\begin{definitionbox}[title={Channels}]
	\keyterm{Channels} are how triggers reach the agent. In professional practice, four channels cover almost all work intake:

	\vspace{0.5em}
	\textbf{External feeds}: The world pushes work to you (court filings, market data, regulatory updates).

	\vspace{0.3em}
	\textbf{Human prompts}: People request work directly (chat, email, collaboration platforms).

	\vspace{0.3em}
	\textbf{Scheduled jobs}: Time itself triggers execution (deadlines, periodic checks, end-of-day).

	\vspace{0.3em}
	\textbf{Escalation events}: Internal signals that ask for human help (budget exhaustion, low confidence).
\end{definitionbox}

Each channel type serves a different operational need. External feeds enable reactive monitoring, allowing the system to respond to events as they occur in the world. Human prompts enable interactive collaboration, letting professionals direct the system's attention as needs arise. Scheduled jobs enable proactive workflows, ensuring that routine tasks happen reliably without requiring someone to remember to initiate them. And escalation events close the loop on human oversight by ensuring the system asks for help when it reaches its limits, a topic we explore in depth in \Cref{sec:agents2-escalation}.

The underlying point is simple but easy to overlook: before an agentic system can reason or act, it must first notice that work exists. Channels are the sensory apparatus of the system, the means by which it becomes aware of its environment and the tasks waiting to be accomplished. A lawyer cannot respond to a redlined contract they never received, and an agent cannot act on a trigger it never observed.

Triggers and channels are architectural concerns---questions about how work reaches the system, how events are routed, and how actions are logged for audit. But architecture alone does not determine whether an agentic system succeeds in practice. Professionals must actually use the system, and that raises a different set of questions: through what interaction modality do users engage? Is the experience synchronous or asynchronous? Does the system push information or wait to be asked? These are user experience questions, and they center on the concept of \textit{surfaces}.

Consider the difference between a litigator who explores docket alerts through an interactive research session, refining queries as understanding develops, versus one who receives a daily summary email, versus one who gets a polished memo only when something requires attention. The underlying trigger is identical. The channel is the same. What differs is the surface---and surface design is the province of UX professionals, not system architects.

We address surfaces in this section because they complete the picture of the human-agent interface. Triggers, channels, and surfaces together determine whether an agentic system fits naturally into professional workflows or feels like an awkward intrusion. System architects must understand surfaces to design appropriate triggers and channels; UX designers must understand triggers and channels to design effective surfaces. The disciplines are distinct but interdependent. After examining how work arrives through each channel type, we turn to how users experience the system through different surfaces (\Cref{sec:agents2-surfaces}).

\input{figures/fig-trigger-channels}

% ----------------------------------------------------------------------------
% External Feeds
% ----------------------------------------------------------------------------

\subsection{External Feeds: The World Pushes Work to You}
\label{sec:agents2-external-feeds}

External feeds deliver events from systems outside the agentic system's direct control. The external system pushes notifications when events occur, much like receiving service of process rather than checking the courthouse daily to see if you have been sued.

\textbf{Legal and Regulatory Feeds}: Court docket systems and state e-filing platforms can send notifications whenever documents are filed in cases you are monitoring. When an alert arrives, an agentic system can retrieve the filed document, analyze its contents, and trigger the appropriate response, whether that means flagging a motion for attorney review, updating a case timeline, or drafting a preliminary response memo. SEC filing systems offer similar capabilities for corporate disclosures, enabling agentic systems to monitor competitors' filings and flag material changes. Citator services can notify the system whenever cases you care about are cited or overruled, keeping your legal research current without manual checking.

\textbf{Financial Market Feeds}: Financial institutions receive real-time market data through providers like Bloomberg and Reuters. A portfolio management agent can subscribe to price alerts and receive notifications when thresholds are crossed, then evaluate whether rebalancing is warranted and either execute trades within pre-approved limits or escalate to a portfolio manager for approval. News feeds add another layer, delivering headlines, earnings announcements, and analyst ratings that the agent can assess for materiality and surface to managers when developments warrant attention.

\begin{keybox}[title={Speed vs. Reasoning: A Critical Distinction}]
Market data arrives at millisecond granularity. LLM-based reasoning operates at second-to-minute timescales. This mismatch means agentic systems are unsuited for high-frequency trading or latency-sensitive execution, but well suited for strategic decisions, research synthesis, and compliance monitoring. The architecture pattern: fast deterministic systems handle real-time capture and threshold detection; the agentic system processes only after an alert is raised.
\end{keybox}

\textbf{Reliability Matters}: How external feeds connect to agentic systems has real consequences for governance. Some integration approaches prioritize speed but may occasionally miss events; others guarantee delivery and maintain complete logs but add latency. For regulated applications, you generally want the latter: systems that ensure every event is recorded, processed in order, and available for later audit. When evaluating vendor systems, ask whether the integration approach guarantees delivery and maintains audit trails, or whether events can be lost without detection.

% ----------------------------------------------------------------------------
% Human Prompts as Events
% ----------------------------------------------------------------------------

\subsection{Human Prompts as Events}
\label{sec:agents2-human-events}

Human prompts feel different from external feeds because they are interactive. You type something and expect a response. But at the architectural level, a human prompt is just another event type: the user generates an event, the system receives it through a channel, processes it, and responds. Treating prompts this way simplifies design, because all events flow through the same routing and prioritization logic rather than requiring separate handling for interactive versus background work.

\textbf{Chat interfaces} offer the most direct channel for human interaction, and they are where most professionals first encounter agentic systems. A litigation associate researching a motion to dismiss might type ``Find Ninth Circuit cases on personal jurisdiction over foreign corporations with U.S. subsidiaries,'' review the results, and then refine the query: ``Focus on cases after 2018 where the court found jurisdiction.'' On the finance side, a credit analyst evaluating a loan application might ask ``Compare this borrower's debt-to-EBITDA ratio against our portfolio average for manufacturing companies,'' review the comparison, and follow up with ``Show me how it trends over the last three years.'' What makes chat powerful is exactly this kind of iterative refinement. Each message is simply another event, processed through the same loop as everything else, just with tighter expectations for response time.

But that expectation for quick responses creates real design constraints. When you are waiting for an answer, every second of silence feels like something has gone wrong. Systems built for interactive use need to acknowledge requests immediately, show progress as work unfolds, and deliver results incrementally when possible. This might mean streaming partial responses as they are generated, displaying indicators that show which databases the system is searching, or breaking complex research into visible steps. Without this feedback, a blank screen followed by a complete response thirty seconds later leaves you wondering whether the system is working, stuck, or crashed.

\textbf{Email routing} lets agentic systems handle work that arrives through channels people already use. A general counsel might forward a compliance question from a business unit to a monitored inbox, and the system extracts the question, searches relevant guidance, and drafts a response for review. A portfolio manager might forward a client inquiry about sector exposure to a research assistant inbox, receiving back a summary with current allocations and recent changes. The challenge with email is that the requests tend to be unstructured, often buried in forwarded threads with multiple topics and tangential context that the system must parse to find the actual question.

\textbf{Collaboration platforms} like Slack and Teams let agentic systems appear as team members in the workflow. A deal team negotiating an acquisition can @mention the system in their working channel to check whether a proposed indemnification cap falls within market norms, without anyone switching applications or breaking the flow of discussion. An investment committee preparing for a meeting can request a quick portfolio risk summary in their coordination channel. Users can also invoke specific capabilities through commands like \texttt{/research "material adverse change clauses"}. The convenience comes with a security consideration: collaboration platforms log all messages, and channels often include people with different access levels, so systems need to be careful about what information they surface and where.

\textbf{Voice interfaces} are best suited for quick lookups when typing is impractical: checking a position size while walking between meetings, confirming a filing deadline while reviewing documents, or getting a quick summary of overnight market moves during a commute. The tradeoffs are significant, though. Transcription errors can mangle legal and financial terminology, and without a keyboard, verifying identity becomes harder. For anything beyond simple information retrieval, voice interfaces should require explicit confirmation before the system takes action.

These synchronous channels share a common advantage: if the system misunderstands your request, you can clarify immediately. Asynchronous channels like email and background automation do not offer that safety net. When you send a request and walk away, you will not discover a misunderstood instruction until you return to find the wrong output. This is why intent understanding (\Cref{sec:agents2-intent}) and perception design (\Cref{sec:agents2-perception}) matter even more for asynchronous workflows. The system must figure out what you actually want from a single message, gather the right information without guidance, and deliver results that match your expectations on the first attempt. And because no one is watching, asynchronous systems need robust logging and notification so that operators can understand what happened after the fact.

% ----------------------------------------------------------------------------
% Scheduled Jobs
% ----------------------------------------------------------------------------

\subsection{Scheduled Jobs: Time as Trigger}
\label{sec:agents2-scheduled}

Unlike the channels we have discussed so far, some work does not wait for an external event or a human request. End-of-day reconciliation, monthly compliance reporting, quarterly reviews, and annual filings all happen on a calendar. For these recurring tasks, time itself becomes the trigger, and the system must initiate work without anyone asking.

\textbf{Calendar-driven deadlines} govern much of legal and financial practice. Litigators live by deadlines: answer the complaint within 21 days, file motions 30 days before hearings, respond to discovery within 30 days. Missing one can mean default judgment or sanctions. An agentic system can monitor litigation calendars, calculate deadlines while accounting for court holidays and local rules, and escalate as deadlines approach if work remains incomplete. A more sophisticated system might go further, retrieving the complaint a week before the answer is due, extracting the claims, generating a draft answer with standard defenses, and presenting it for attorney review with time to spare. Financial professionals face analogous deadline pressure: quarterly SEC filings, annual audits, covenant compliance certificates due to lenders, and tax submissions that carry real penalties for delay. The same scheduled-trigger architecture that reminds a litigator about an approaching discovery deadline can remind a fund administrator about an investor reporting obligation.

\textbf{Periodic compliance checks} run on a schedule even when nothing externally triggers a review. Consider the investment compliance team at an asset manager: every night, the system checks each portfolio against its investment policy statement, looking for positions that exceed concentration limits, securities that fall outside permitted categories, or exposures that have drifted beyond acceptable ranges. Violations get flagged for review before markets open. Law firms face a parallel challenge with conflicts of interest. A conflicts system can retrieve new docket entries and engagement letters each day, extract party names, and check them against the firm's conflicts database. If the same company name appears on both sides of a matter, the system escalates immediately rather than waiting for someone to notice. These scheduled checks enable continuous monitoring that would be impractical to perform manually across thousands of client accounts or active matters.

\textbf{End-of-day and end-of-period workflows} are critical in both industries. In finance, end-of-day processing is a well-established ritual: when markets close, systems retrieve final prices, mark positions to market, reconcile trades against counterparty confirmations, calculate profit and loss, and generate the risk reports that will be waiting on desks the next morning. If any step fails or produces unexpected results, the system escalates rather than distributing incomplete data. Law firms have their own periodic workflows, though they tend to run on longer cycles. At month-end, a billing system might remind attorneys to enter unbilled time, generate draft invoices based on matter budgets and fee arrangements, and flag anomalies for partner review before bills go to clients. Quarterly, a matter management system might review open matters for staleness and prompt responsible attorneys to update status or close inactive files. The triggers are different, but the architectural pattern is the same: time fires the event, the system performs its work, and humans receive the output or the escalation.

% ----------------------------------------------------------------------------
% Escalation Events (Brief - Full Treatment in Section 09)
% ----------------------------------------------------------------------------

\subsection{Escalation Events: When Agents Reach Their Limits}
\label{sec:agents2-escalation-brief}

The previous three channel types bring work into the system from outside: external feeds push events, humans make requests, and scheduled jobs fire on the clock. Escalation events are different. They originate inside the system itself, when an agent reaches a limit and cannot proceed autonomously. The system generates an event signaling that it needs human intervention, transferring control to a decision-maker at precisely the moment when human judgment matters most.

Four types of escalation triggers appear most frequently in practice.

\textbf{Budget exhaustion} occurs when the system approaches resource limits it has been given. These might be token consumption caps, iteration counts, time limits, or cost thresholds. Imagine a due diligence agent working through a data room with thousands of documents. If it burns through its budget analyzing the first hundred contracts without reaching the financial statements, it needs to stop and ask: should I continue with more resources, or should a human reprioritize what I review first? Without this kind of budget-aware escalation, the system either stops arbitrarily or runs up costs without limit.

\textbf{Low confidence} triggers escalation when uncertainty is too high for autonomous action. A research agent might find conflicting authority on a legal question, with a recent circuit court decision that appears to contradict older Supreme Court precedent. Rather than picking one and hoping for the best, the system should surface the conflict and let an attorney decide how to handle it. Similarly, a credit analysis agent encountering a borrower with an unusual corporate structure might recognize that its standard analysis framework does not apply cleanly and escalate for human review rather than forcing the square peg into a round hole.

\textbf{Approval requirements} force escalation for actions that require explicit human authorization regardless of the system's confidence. Some actions are simply too consequential to delegate fully, even when the system is certain it knows the right answer. Filing court documents, sending communications to clients or counterparties, executing trades above a certain size, or making public disclosures all warrant human sign-off. The system may draft the motion, compose the email, or prepare the trade ticket, but a human must authorize the action itself.

\textbf{Errors and anomalies} require human intervention when something unexpected happens. Tools fail, data sources become unavailable, or results do not make sense. A due diligence agent that finds revenue figures in a company's 10-K that do not match the numbers in its earnings press release should not proceed with potentially inconsistent data. A portfolio monitoring agent that cannot reach the pricing service should escalate rather than working with stale prices. These situations require human judgment to determine whether to wait, retry, use alternative sources, or proceed with acknowledged limitations.

We return to escalation design in depth in \Cref{sec:agents2-escalation}, including how to calibrate when systems should ask for help versus proceed autonomously, and how to design escalation interfaces that give humans the context they need to make good decisions quickly. The organizational structures that support escalation---tiered response models, accountability pathways, and governance reporting---are addressed in \href{https://papers.ssrn.com/abstract=5911464}{\textit{Governing Agents}}.

% ----------------------------------------------------------------------------
% Surfaces: Interaction Modalities
% ----------------------------------------------------------------------------

\subsection{Surfaces: How Users Experience Agentic Systems}
\label{sec:agents2-surfaces}

Triggers and channels are architectural concepts---they answer questions about event routing, message delivery, and system integration. \keyterm{Surfaces} are user experience concepts---they answer questions about interaction modality, workflow integration, and interface design. These are different disciplines asking different questions, even when they address the same system.

We include surfaces in this architectural chapter for two reasons. First, surface choice constrains architectural decisions: a system designed for conversational interaction needs different trigger handling than one designed for background automation. Second, architects and UX designers must communicate: when a UX designer specifies that users need real-time research dialogue, the architect must understand what that implies for channel selection and response latency.

Conversational surfaces deserve special attention because they sit at the intersection of architecture and UX. When a litigator types a research question into a chat window, the interface serves two roles simultaneously: it is the pathway through which the human prompt trigger arrives (an architectural function) and the interaction modality through which the user engages with responses (a UX function). This dual role is unique to conversational surfaces---automation and document surfaces do not receive triggers, they only deliver outputs.

Surface design warrants extended treatment in its own right. Questions of conversational UX, interface affordances, and workflow integration deserve the depth we give them elsewhere in this book. Here, we focus on the essentials that architects need to understand: what surfaces exist, how they differ, and how surface choice shapes system requirements.

Surface choice matters because it shapes workflow integration. An agentic system with identical capabilities will succeed or fail based partly on whether its surface matches how professionals actually work. Usability researcher Jakob Nielsen argues that generative AI represents the first new user interface paradigm in sixty years, marking a shift from \textit{command-based interaction}, where you tell the computer what to do, to \textit{intent-based outcome specification}, where you tell the computer what you want \parencite{nielsen-ai-ui-paradigm}. But intent-based systems still require interfaces, and those interfaces---the surfaces through which users engage---determine whether the system feels natural or intrusive.

\begin{definitionbox}[title={Interaction Surfaces}]
	An \keyterm{interaction surface} is the user experience modality through which humans engage with an agentic system. Where triggers and channels are architectural concepts describing how work reaches the system, surfaces are UX concepts describing how users experience the system. Surfaces vary along four dimensions that UX designers use to match interaction paradigms to user needs: synchronicity, initiative, embodiment, and output format.
\end{definitionbox}

\textbf{Synchronicity} determines when results arrive. Synchronous interactions deliver results while the user waits, as with chat interfaces where you ask a question and watch the response stream in. This suits exploratory work where you refine direction based on what you see. Asynchronous interactions deliver results later through notifications or reports, as with document generation where you specify requirements, do other work, and return when the draft is ready. This suits production tasks where waiting would waste billable time.

\textbf{Initiative} captures who starts the conversation. In pull models, the system waits for the user to initiate. A research assistant that answers questions when asked operates this way, giving the user control over when and whether to engage. In push models, the system reaches out when something needs attention. A docket monitor that alerts you to new filings operates this way, deciding when to interrupt based on relevance and urgency.

\textbf{Embodiment} refers to whether the system is visible in the workflow. Visible systems appear as explicit participants, like a chat avatar or copilot sidebar that makes the agentic system's presence clear. Users know they are interacting with AI and can direct it consciously. Invisible systems operate as infrastructure, like a compliance screening system that flags suspicious transactions in the background. Users experience the outputs without seeing the system that produced them.

\textbf{Output format} determines what the system produces. Conversation turns suit iterative exploration where direction emerges through dialogue, producing chat transcripts from research queries, brainstorming, and strategy discussions. Structured documents suit formal deliverables with defined formats, producing research memos, due diligence reports, and contract summaries ready for distribution. Actions in the world suit automation workflows, where filing a document, sending an alert, or executing a trade produces effects rather than text.

Three primary surfaces dominate current deployments, each suited to different task types and user contexts.

\textbf{Conversational surfaces} present the agentic system as an interactive dialogue partner, best suited for exploratory tasks where users refine direction through iteration---researching unfamiliar areas, exploring scenarios, thinking through strategy. The interaction is synchronous and user-initiated. Limitations include the ``articulation barrier'' (users must express intent in natural language) and lack of visual \keyterm{affordances} (no menus to browse or buttons to discover capabilities).

\textbf{Automation surfaces} present the agentic system as invisible infrastructure that monitors, analyzes, and acts in the background. Users receive outputs only when something relevant happens. Examples include portfolio surveillance that alerts when positions breach limits, docket monitoring that flags new filings in active matters, and compliance systems that screen transactions against sanctions lists. The interaction is asynchronous and system-initiated.

Automation surfaces suit \textit{monitoring tasks} where continuous human attention is impractical. A compliance officer cannot manually review every transaction, and a litigator cannot check every docket daily. The agentic system handles the routine cases, surfacing only exceptions that require human judgment. The user experience is defined by what \textit{does not} happen, since no alert means no problem.

\textbf{Document surfaces} present the agentic system as a drafting assistant that produces structured work products such as research memos, due diligence reports, deposition summaries, and client presentations. The user specifies requirements, the system produces a document, and the user reviews, edits, and distributes. The interaction is asynchronous because the system works while the user does other things, but it remains user-initiated.

Document surfaces suit \textit{production tasks} with defined deliverables. The associate needs a memo for the partner's review, and the analyst needs a report for the investment committee. The output format matters here because you need a polished document that can be filed, sent to clients, or presented to regulators, not a chat transcript.

\begin{keybox}[title={Matching Surface to Task}]
	Surface selection is a design decision, not a technical constraint. When choosing how users will interact with an agentic system, match the surface to the task type.

	\vspace{0.5em}
	\textbf{Exploratory tasks} like research questions, strategy discussions, and ad hoc analysis work best through \textbf{chat surfaces} that support iterative refinement.

	\vspace{0.3em}
	\textbf{Monitoring tasks} like docket surveillance, compliance screening, and portfolio alerts work best through \textbf{automation surfaces} that operate in the background.

	\vspace{0.3em}
	\textbf{Production tasks} like research memos, due diligence reports, and regulatory filings work best through \textbf{document surfaces} that generate formal deliverables.

	\vspace{0.5em}
	Many deployments combine all three. A litigation support system might offer chat for research, automation for alerts, and document generation for motion drafts. The underlying reasoning capabilities remain constant while only the interaction modality changes.

	\vspace{0.5em}
	\textbf{Mismatches waste effort.} Forcing chat onto monitoring tasks demands attention no one can sustain. Forcing documents onto exploratory tasks prevents the iteration that produces good results.
\end{keybox}

The interplay between triggers, channels, and surfaces creates the complete human-agent interface. Table~\ref{tab:agents2-trigger-surface-examples} illustrates how the same trigger arriving through the same channel can manifest through different surfaces depending on workflow context.

\begin{table}[htbp]
	\centering
	\caption{How triggers, channels, and surfaces combine in practice}
	\label{tab:agents2-trigger-surface-examples}
	\small
	\begin{tabular}{p{0.23\textwidth}p{0.15\textwidth}p{0.13\textwidth}p{0.39\textwidth}}
		\toprule
		\textbf{Trigger}          & \textbf{Channel}  & \textbf{Surface}   & \textbf{Workflow}                              \\
		\midrule
		New court filing          & External feed     & Automation         & Background monitoring; alert when needed       \\
		New court filing          & External feed     & Chat               & Interactive research on opposing brief         \\
		New court filing          & External feed     & Document           & Case summary memo for partner                  \\
		\midrule
		Price threshold crossed   & External feed     & Automation         & Background alert to portfolio manager          \\
		Price threshold crossed   & External feed     & Chat               & Interactive rebalancing analysis               \\
		Price threshold crossed   & External feed     & Document           & Trade recommendation for committee             \\
		\midrule
		Research question         & Human prompt      & Chat               & Iterative legal research                       \\
		Report request            & Human prompt      & Document           & Due diligence memo                             \\
		\bottomrule
	\end{tabular}
\end{table}

\textbf{Emerging surfaces} include embedded copilots (agentic capabilities integrated into existing applications via sidebars or inline suggestions), ambient interfaces (voice-based interaction, though currently limited by transcription errors in professional contexts), and agentic APIs (machine-to-machine orchestration where the ``user'' is another system---see \Cref{sec:agents2-delegation}).

Surface design draws on decades of human-computer interaction research. What architects need to understand is that surface selection has architectural consequences: conversational surfaces require low-latency response paths, automation surfaces require robust background processing, and document surfaces require generation pipelines. UX designers choose surfaces based on user needs; architects build the infrastructure those surfaces require.

% ----------------------------------------------------------------------------
% Evaluating Trigger Systems
% ----------------------------------------------------------------------------

\subsection{Evaluating Trigger Systems}
\label{sec:agents2-evaluating-triggers}

When evaluating trigger systems, assess five criteria: \textit{coverage} (all relevant event sources), \textit{latency} (acceptable delay for the use case), \textit{reliability} (failure handling and fallbacks), \textit{priority} (distinguishing urgent from routine), and \textit{auditability} (complete trigger logs). See the consolidated Evaluation Checklist in \Cref{sec:agents2-evaluation-checklist}.

% ----------------------------------------------------------------------------
% Connection to Other Questions
% ----------------------------------------------------------------------------

\subsection{From Triggers to Action}
\label{sec:agents2-triggers-to-action}

This section has examined the human-agent interface from two disciplinary perspectives. From an architectural standpoint, \textit{triggers} are the events that initiate work, and \textit{channels} are the pathways through which those triggers reach the agent. From a user experience standpoint, \textit{surfaces} are the interaction modalities through which users engage with the agent's capabilities. Architects design trigger routing and channel infrastructure; UX designers choose surfaces that match how professionals actually work. The disciplines address different questions but must align for a system to succeed.

Together, triggers, channels, and surfaces determine how an agentic system fits into professional workflows. A well-designed trigger system ensures no relevant event goes unnoticed. Appropriate channel selection balances latency against reliability. Thoughtful surface choices match interaction modality to task type. And all three must support the audit trails that governance requires---every action traceable to the trigger that initiated it, through the channel that delivered it, via the surface through which it was experienced.

But triggering is only the beginning. Once an event arrives, the agentic system must:

\begin{itemize}[nosep]
	\item \textbf{Understand intent}: What is being asked?
	\item \textbf{Perceive information}: What does the system need to know?
	\item \textbf{Take action}: What should the system do?
	\item \textbf{Remember context}: What should persist across sessions?
	\item \textbf{Plan execution}: How should work be decomposed?
	\item \textbf{Recognize completion}: When is the task done?
	\item \textbf{Escalate appropriately}: When should humans intervene?
\end{itemize}

To see how these questions connect, trace a single event through the system. An external feed delivers a court filing notification, and the system routes it based on matter type and urgency. Depending on the configured surface, a litigator might receive a chat prompt inviting interactive research, a background alert waiting in their queue, or a generated memo summarizing the filing's implications. Whatever the surface, the system retrieves case context from memory, downloads the filed document, analyzes its content, and either proceeds autonomously or escalates for human judgment. Each step in this chain---from trigger to channel to surface to action---represents an architectural decision with consequences for what the system can accomplish and how reliably it performs.

With work arriving through triggers and channels, and users engaging through surfaces, the next question becomes: how does the agentic system understand what is actually being asked? \Cref{sec:agents2-intent} takes up this problem of intent.

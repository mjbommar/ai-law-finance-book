% ============================================================================
% 01-introduction.tex
% Introduction and Context
% Part of: Chapter 07 - Agents Part II: How to Build an Agent
% ============================================================================

\section{Introduction}
\label{sec:agents2-intro}

% ----------------------------------------------------------------------------
% Opening and Context
% ----------------------------------------------------------------------------

Part I answered \textit{What is an agent?} by tracing the concept from cybernetics to modern LLM systems and introducing the GPA+IAT framework: Goal, Perception, Action, Iteration, Adaptation, Termination. These six properties distinguish genuine agentic systems from chatbots, simple automation, and marketing hype. An entity that lacks any of these properties, that cannot iterate on feedback, adapt its strategy, or recognize when to stop, is not an agentic system, regardless of what vendors claim.

Part II answers: \textit{How do you build one?}

More precisely: how do you build systems that implement all six properties? The abstract framework becomes concrete architecture. Goal becomes a planning system. Perception becomes tools for reading the environment. Action becomes tools for changing it. Iteration becomes the agent loop. Adaptation becomes memory. Termination becomes guardrails and success criteria. This chapter shows how.

Think about how a law firm or financial institution actually operates. A junior associate or analyst does not work in isolation. They have access to research databases, they maintain case files or deal books that accumulate over time, they break down complex partner assignments or portfolio manager requests into manageable tasks, and they coordinate with other professionals. The associate's effectiveness depends not just on their individual capabilities, but on the infrastructure around them: which systems they can access, what information they can retrieve from past matters, how they decompose ambiguous instructions into concrete work, and how they communicate results back up the chain.

Building an agent system mirrors building a professional organization. You must decide which tools the agent can access, much like deciding whether an associate gets a Bloomberg terminal or just basic internet access. You must design memory systems that preserve context across interactions, much like maintaining a matter file that follows an engagement through discovery, motion practice, and trial. You must implement planning mechanisms that break complex goals into steps, much like a senior attorney delegating research, drafting, and review tasks. And you must establish protocols for how agents interact with each other and with humans, much like the information barriers between practice groups or the escalation procedures when a junior attorney encounters something beyond their authority.

This chapter provides architectural patterns and mental models for designing these systems. We are not teaching you to program agents from scratch. Instead, we are showing you how the components fit together, what trade-offs exist, and how design choices affect capability and risk.

% ----------------------------------------------------------------------------
% Core Concepts: Tools, Memory, Planning
% ----------------------------------------------------------------------------

\begin{definitionbox}[title={\textbf{Tool}}]
A \keyterm{tool} is an interface enabling agents to interact with external systems. Tools are the agent's Westlaw subscription, Bloomberg terminal, EDGAR database access, document management system, and e-filing portal. Without tools, even the most sophisticated model can only reason about what it already knows, like an associate locked in a library with no internet.
\end{definitionbox}

\begin{definitionbox}[title={\textbf{Agent Memory}}]
\keyterm{Agent memory} stores and retrieves information across timescales. Short-term memory is the documents spread across an associate's desk during active work. Long-term memory is the firm's knowledge management system with decades of research memos. Episodic memory is the case file that tracks what happened on this specific matter. Semantic memory is the legal principles every attorney internalizes over their career.
\end{definitionbox}

\begin{definitionbox}[title={\textbf{Planning}}]
\keyterm{Planning} decomposes complex goals into achievable sub-tasks and adapts strategy based on results. When a partner assigns a vague directive like "research our exposure on the employment matter," planning is what transforms that into concrete steps: identify the jurisdiction, search relevant statutes, find case law, synthesize holdings, draft a memo. Without planning, agents thrash between uncoordinated actions like an associate who keeps running searches without a research strategy.
\end{definitionbox}

% ----------------------------------------------------------------------------
% Event-Driven Framing
% ----------------------------------------------------------------------------

\subsection{From Chat to Production: The Event-Driven Agent}
\label{sec:agents2-event-driven}

When a partner asks an associate to ``keep an eye on'' a pending regulatory filing, what does that actually mean? Not sitting at a desk refreshing the SEC's website. It means the associate configures an alert system that monitors EDGAR for the target company's Form 8-K filings and sends a notification when one appears. The associate then reviews the filing, analyzes its implications, updates the case file, and escalates material findings to the partner. That workflow is \keyterm{event-driven}: an external trigger (filing publication) initiates a sequence of perception, analysis, and action steps, bounded by clear termination conditions (analysis complete or escalation required).

Most discussions of AI agents emphasize interactive chat interfaces, where an attorney asks questions and receives answers in a conversation. That mode is valuable for exploration and ideation. But production deployment in legal and financial environments operates differently. These systems respond continuously to external triggers, not human prompts. A contract review system activates when a new draft arrives in the document management system. A portfolio compliance monitor triggers when end-of-day positions exceed mandate limits. A docket tracking system fires when a court clerk uploads a new filing. The architectural patterns, tool requirements, and evaluation methods for event-driven agents differ substantially from chat-based interaction.

\paragraph{Events as Triggers in Legal and Financial Workflows}

Consider the information flows that drive professional work. In legal practice, regulatory filings (SEC EDGAR publications, Federal Register notices) trigger compliance analysis; court docket updates trigger deadline calculations and strategy adjustments; document events (deal room uploads, contract redlines) trigger review workflows; and calendar deadlines trigger resource allocation. Financial institutions operate on similar patterns: market data events (price thresholds, volatility spikes) trigger portfolio rebalancing; position events (reconciliation failures, mandate breaches) trigger compliance reviews; regulatory deadlines trigger reporting workflows; and risk threshold exceedances trigger escalation protocols.

This operational cadence defines professional practice. Agent systems that cannot respond autonomously to such triggers remain research prototypes. The architectural components we examine in Section~\ref{sec:agents2-architecture} must support event-driven activation, and Section~\ref{sec:agents2-triggers} examines trigger channels in detail.

% ----------------------------------------------------------------------------
% From Framework to Components
% ----------------------------------------------------------------------------

\subsection{From Framework to Components}
\label{sec:agents2-framework-mapping}

Part I introduced the GPA+IAT framework as an abstract characterization of agency, identifying six properties that distinguish agents from simple question-answering systems. Part II grounds that framework in concrete technical components. The mapping is direct and we keep the emphasis consistent:

\textbf{Goal} $\rightarrow$ \keyterm{planning system}. A litigation partner who asks for ``prepare for summary judgment'' expects a plan: review the complaint, research standards, collect evidence, draft and cite-check. The planning system performs the same decomposition for an agent.

\textbf{Perception} $\rightarrow$ \keyterm{read-only tools and retrieval}. A paralegal's ability to perceive the state of a matter depends on access to PACER, the document management system, and public records. Agents perceive through the tools they can read from.

\textbf{Action} $\rightarrow$ \keyterm{write and execute tools}. The capacity to act distinguishes agents from passive question-answering systems. When an agent files a court document through an e-filing API, executes a trade via broker integration, or updates a contract management system, it changes the external world in ways that carry both operational and legal consequences. This necessitates a fundamental architectural distinction: write-capable tools, those that create, modify, or delete information in external systems, require stricter authorization, approval workflows, and audit logging than read-only perception tools. The technical implementation of action capabilities directly determines an agent's operational risk profile and its suitability for autonomous versus human-supervised deployment.

\textbf{Iteration} $\rightarrow$ \keyterm{agent loop}. Professional workflows rarely complete in a single pass. Discovery proceeds through iterative cycles: issue document requests, review productions, identify gaps, refine requests, repeat until sufficient evidence emerges or court deadlines intervene. Investment analysis similarly iterates: collect financial data, identify anomalies, request additional disclosures, refine valuation models, reassess assumptions. Agents implement this same pattern through the core perceive--reason--act loop, executing cycles of observation (reading tool outputs and memory), deliberation (planning next steps), and action (invoking tools), continuing until explicit termination conditions signal completion or escalation. The loop structure transforms single-shot inference into genuine task-oriented behavior.

\textbf{Adaptation} $\rightarrow$ \keyterm{memory systems}. A junior associate handling their first securities fraud matter learns from supervising partners, past case files, and firm precedent databases. An experienced portfolio manager draws on years of market cycles, prior investment theses, and accumulated knowledge about industry dynamics. Agent adaptation operates through similar mechanisms: episodic memory preserves task-specific context (the current matter's facts, intermediate results, and reasoning steps), long-term memory maintains reusable knowledge (legal principles, market relationships, successful strategies from past tasks), and working memory enables the agent to track multi-step plans and maintain coherent state across iterations. Without memory, each iteration starts from scratch; with memory, agents build on prior work and refine strategies based on feedback.

\textbf{Termination} $\rightarrow$ \keyterm{guardrails and success criteria}. Unbounded execution generates unbounded costs and risks. When does legal research become excessive? When has a trading algorithm gathered sufficient confirming data? Effective agents require explicit termination mechanisms: positive criteria indicating successful goal achievement (the research memo is complete, the compliance threshold is satisfied), resource limits preventing runaway consumption (maximum tool invocations, API costs, wall-clock time), confidence thresholds below which the agent escalates rather than acts (``I cannot determine privilege status with sufficient certainty''), and safety guardrails that halt execution when potentially harmful conditions emerge (attempting to access restricted data, generating legally problematic content). These stopping rules are not implementation details; they are the boundaries that make autonomous operation acceptable in professional environments.

Each dimension represents a design decision. You must specify how goals decompose (planning algorithms), which tools the agent accesses (tool inventory and permissions), how memory persists (storage architecture), and what triggers termination (success criteria and guardrails). Building an agent means making explicit design choices for each component, not just connecting a language model to an API. The remaining sections detail these components, their interactions, and deployment patterns for professional services.

% ----------------------------------------------------------------------------
% Why Architecture Matters
% ----------------------------------------------------------------------------

\subsection{Why Architecture Matters}
\label{sec:agents2-why-arch}

Building an agent requires architectural thinking analogous to staffing a major matter. When a law firm takes on complex multi-district litigation, partners assemble teams with differentiated roles: senior associates for substantive strategy, junior associates for research and drafting, paralegals for document management, contract attorneys for discovery review, and outside specialists under protective orders. Each role has different access permissions, shared case files maintain common ground, and the partner sets termination conditions (settlement, budget exhaustion, or changed risk calculus).

Agent systems mirror this structure. They execute multi-step tasks requiring tool integration across systems. They maintain context through memory so each interaction builds on prior work. They adapt when initial approaches fail. They collaborate with other agents or escalate to humans when encountering issues beyond their authority. And they operate at varying autonomy levels calibrated to risk: reading public documents can be autonomous, while filing court documents or executing trades typically requires human approval.

Each capability introduces corresponding requirements. Tools need authentication and audit logging. Memory must respect privilege boundaries and information barriers. Planning requires termination conditions to prevent runaway costs. Protocols must authenticate participants and protect confidential communications.

For legal and financial applications, agents handle privileged material, material non-public information, and personally identifiable data. Security, isolation, and auditability must be designed in from the start. Retrofitting privilege protections after a confidentiality breach, or adding audit logging after a regulatory inquiry, is like building a trading platform and then trying to add wash sale controls. The cost of architectural failure in regulated environments exceeds the cost of proper initial design.

\begin{highlightbox}[title={Architecture Enables Governance}]
Chapter 08 examines how to govern agentic systems by establishing controls, assigning accountability, and ensuring compliance. But governance presupposes architecture. You cannot audit what you did not log. You cannot enforce privilege boundaries that were never implemented. You cannot demonstrate bounded operation without termination mechanisms.

The architectural choices in this chapter are not merely technical decisions. They are the \textit{infrastructure} that makes governance possible. When a regulator asks how the compliance agent detected a breach, when opposing counsel demands production of the agent's reasoning, when a client questions why the agent recommended a particular strategy, architecture determines whether you can answer.

Professional duties are non-delegable: attorneys remain liable for AI-assisted work product, fiduciaries remain accountable for AI-informed recommendations. Chapter 08 details those obligations. This chapter gives you the architecture to meet them.
\end{highlightbox}

The remaining sections examine triggers and channels for how work enters the system (Section~\ref{sec:agents2-triggers}), tools, memory, and planning (Section~\ref{sec:agents2-architecture}), communication protocols (Section~\ref{sec:agents2-protocols}), evaluation methods (Section~\ref{sec:agents2-evaluation}), and integrated reference architectures (Section~\ref{sec:agents2-synthesis}).

% TODO: Add timeline figure showing November 2024-2025 developments (MCP, A2A, commercial agent frameworks, etc.)
% TODO: Add motivating example of legal AI agent workflow

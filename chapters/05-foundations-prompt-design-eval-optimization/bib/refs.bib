% Bibliography for Chapter 05: Prompt Design, Evaluation, and Optimization

@article{wei2022chainofthought,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {24824--24837},
  year = {2022},
  url = {https://arxiv.org/abs/2201.11903},
  urldate = {2024-11-15}
}

@article{wang2022selfconsistency,
  author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  journal = {arXiv preprint arXiv:2203.11171},
  year = {2022},
  url = {https://arxiv.org/abs/2203.11171},
  urldate = {2024-11-15}
}

@article{yao2022react,
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
  journal = {arXiv preprint arXiv:2210.03629},
  year = {2022},
  url = {https://arxiv.org/abs/2210.03629},
  urldate = {2024-11-15}
}

@article{yao2023treeofthoughts,
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  year = {2023},
  url = {https://arxiv.org/abs/2305.10601},
  urldate = {2024-11-15}
}

@article{liang2022helm,
  author = {Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  title = {Holistic Evaluation of Language Models},
  journal = {arXiv preprint arXiv:2211.09110},
  year = {2022},
  url = {https://arxiv.org/abs/2211.09110},
  urldate = {2024-11-15}
}

@article{guha2023legalbench,
  author = {Guha, Neel and Nyarko, Julian and Ho, Daniel E. and Ré, Christopher and Chilton, Adam and Chohlas-Wood, Alex and Peters, Austin and Walber, Brandon and Wavering, Brittany and others},
  title = {{LegalBench}: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models},
  journal = {arXiv preprint arXiv:2308.11462},
  year = {2023},
  url = {https://arxiv.org/abs/2308.11462},
  urldate = {2024-11-15}
}

@article{islam2023financebench,
  author = {Islam, Pranab and Kannappan, Anand and Kiber, Daniel and Li, Longfei and Gupta, Tisha and others},
  title = {{FinanceBench}: A New Benchmark for Financial Question Answering},
  journal = {arXiv preprint arXiv:2311.11944},
  year = {2023},
  url = {https://arxiv.org/abs/2311.11944},
  urldate = {2024-11-15}
}

@article{lin2022truthfulqa,
  author = {Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  title = {{TruthfulQA}: Measuring How Models Mimic Human Falsehoods},
  journal = {arXiv preprint arXiv:2109.07958},
  year = {2022},
  url = {https://arxiv.org/abs/2109.07958},
  urldate = {2024-11-15}
}

@article{willard2023outlines,
  author = {Willard, Brandon T. and Louf, Rémi},
  title = {Efficient Guided Generation for Large Language Models},
  journal = {arXiv preprint arXiv:2307.09702},
  year = {2023},
  url = {https://arxiv.org/abs/2307.09702},
  urldate = {2024-11-15}
}

@article{perez2022promptinjection,
  author = {Perez, Fábio and Ribeiro, Ivan},
  title = {Ignore This Title and {HackAPrompt}: Exposing Systemic Vulnerabilities of {LLMs} through a Global Scale Prompt Hacking Competition},
  journal = {arXiv preprint arXiv:2311.16119},
  year = {2022},
  url = {https://arxiv.org/abs/2311.16119},
  urldate = {2024-11-15}
}

@article{ganguli2022redteaming,
  author = {Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  title = {Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned},
  journal = {arXiv preprint arXiv:2209.07858},
  year = {2022},
  url = {https://arxiv.org/abs/2209.07858},
  urldate = {2024-11-15}
}

@article{wei2023jailbroken,
  author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  title = {Jailbroken: How Does {LLM} Safety Training Fail?},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  year = {2023},
  url = {https://arxiv.org/abs/2307.02483},
  urldate = {2024-11-15}
}

@article{hu2021lora,
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  title = {{LoRA}: Low-Rank Adaptation of Large Language Models},
  journal = {arXiv preprint arXiv:2106.09685},
  year = {2021},
  url = {https://arxiv.org/abs/2106.09685},
  urldate = {2024-11-15}
}

@article{ouyang2022instructgpt,
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  title = {Training language models to follow instructions with human feedback},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {27730--27744},
  year = {2022},
  url = {https://arxiv.org/abs/2203.02155},
  urldate = {2024-11-15}
}

@article{bai2022constitutional,
  author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  title = {Constitutional {AI}: Harmlessness from {AI} Feedback},
  journal = {arXiv preprint arXiv:2212.08073},
  year = {2022},
  url = {https://arxiv.org/abs/2212.08073},
  urldate = {2024-11-15}
}

@article{khattab2023dspy,
  author = {Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  title = {{DSPy}: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  journal = {arXiv preprint arXiv:2310.03714},
  year = {2023},
  url = {https://arxiv.org/abs/2310.03714},
  urldate = {2024-11-15}
}
